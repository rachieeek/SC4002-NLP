{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51529dd9",
   "metadata": {},
   "source": [
    "---\n",
    "# SC4002 Natural Language Processing Group Project\n",
    "\n",
    "Group Members:\n",
    "1. Asher Lim Guojun (U2220846H)\n",
    "2. Celeste Ang Jianing (U2222319H)\n",
    "3. Koh Jia Hui Rachel (U2222747H)\n",
    "4. Lim Kiat Sen, Jaron (U2222010K)\n",
    "5. Pang Boslyn (U2221298A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170cd69",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup & Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec801a",
   "metadata": {},
   "source": [
    "Dev notes: I directly installed the model en_core_web_sm 3.7.1 via 'uv add'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "552a94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import torch\n",
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed = 0):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn as nn\n",
    "from itertools import product\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27e0fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 4362\n",
      "Validation examples: 1090\n"
     ]
    }
   ],
   "source": [
    "# Load SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    " # For tokenization\n",
    "TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm',include_lengths = True, pad_token='<pad>')\n",
    "# For multi - class classification labels\n",
    "LABEL = data.LabelField()\n",
    "# Load the TREC dataset\n",
    "train_data , test_data = datasets.TREC.splits(TEXT, LABEL, fine_grained = False)\n",
    "# Split train into train/valid (80/20)\n",
    "train_data, valid_data = train_data.split(\n",
    "    split_ratio=0.8,\n",
    "    random_state=random.seed(42)  # <-- use random.seed here\n",
    ")\n",
    "\n",
    "print(f\"Train examples: {len(train_data)}\")\n",
    "print(f\"Validation examples: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebf6e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['What', 'is', 'the', 'most', 'famous', 'German', 'word', 'in', 'the', 'English', 'language', '?'], 'label': 'ENTY'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469e348",
   "metadata": {},
   "source": [
    "Let's use Glove model for word embeddings.     \n",
    "(Start with GloVe 6B.100d or 6B.300d as it provides a good balance between coverage and performance for TREC's question classification task. If results are underwhelming, experiment with word2vec Google News vectors as an alternative, but empirical results in the literature suggest GloVe performs comparably or slightly better on this specific dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef350631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe, Vectors\n",
    "glove = GloVe(name='6B', dim=100)\n",
    "\n",
    "# Option 1: Use built-in GloVe (torchtext will download automatically)\n",
    "TEXT.build_vocab(train_data, vectors=glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b03cc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc6243",
   "metadata": {},
   "source": [
    "---\n",
    "## Qn 1: Word Embeddings\n",
    "**a) What is the size of the vocabulary formed from your training data according to your tokenization method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd14100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8093\n",
      "# of Labels:  6\n"
     ]
    }
   ],
   "source": [
    "# Get vocabulary size\n",
    "vocab_size = len(TEXT.vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(\"# of Labels: \", len(LABEL.vocab))  # number of distinct labels (topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79928481",
   "metadata": {},
   "source": [
    "**b) We use OOV (out-of-vocabulary) to refer to those words appeared in the training data but\n",
    "not in the Word2vec (or Glove) dictionary. How many OOV words exist in your training data?\n",
    "What is the number of OOV words for each topic category?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33ab0e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of all OOV word occurrences: 202\n",
      "Total number of OOV words in training data: 190\n",
      "Number of OOV words per topic category:\n",
      "Topic DESC: 68 unique OOV words\n",
      "Total occurrence of OOV words:  69\n",
      "--------------------------------------------------\n",
      "Topic ENTY: 47 unique OOV words\n",
      "Total occurrence of OOV words:  52\n",
      "--------------------------------------------------\n",
      "Topic HUM: 39 unique OOV words\n",
      "Total occurrence of OOV words:  40\n",
      "--------------------------------------------------\n",
      "Topic ABBR: 4 unique OOV words\n",
      "Total occurrence of OOV words:  4\n",
      "--------------------------------------------------\n",
      "Topic NUM: 21 unique OOV words\n",
      "Total occurrence of OOV words:  21\n",
      "--------------------------------------------------\n",
      "Topic LOC: 15 unique OOV words\n",
      "Total occurrence of OOV words:  16\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "from collections import defaultdict, Counter\n",
    "# Get only the GloVe vocab (words with pretrained vectors)\n",
    "glove_vocab = set(glove.stoi.keys())\n",
    "\n",
    "oov_words_by_topic = defaultdict(Counter)\n",
    "\n",
    "for example in train_data.examples:\n",
    "    label = example.label\n",
    "    tokens = example.text  # Already tokenized as list of tokens by spacy\n",
    "    for token in tokens:\n",
    "        # Lowercase token to match GloVe casing\n",
    "        token_lower = token.lower()\n",
    "        if token_lower not in glove_vocab:\n",
    "            oov_words_by_topic[label][token_lower] += 1\n",
    "\n",
    "total_oov_words = set()\n",
    "for counter in oov_words_by_topic.values():\n",
    "    total_oov_words.update(counter.keys())\n",
    "\n",
    "total_count = sum(\n",
    "    count\n",
    "    for counter in oov_words_by_topic.values()\n",
    "    for count in counter.values()\n",
    ")\n",
    "print(f\"Total count of all OOV word occurrences: {total_count}\")\n",
    "print(f\"Total number of OOV words in training data: {len(total_oov_words)}\")\n",
    "print(\"Number of OOV words per topic category:\")\n",
    "\n",
    "for topic, counter in oov_words_by_topic.items():\n",
    "    print(f\"Topic {topic}: {len(counter)} unique OOV words\")\n",
    "    print(\"Total occurrence of OOV words: \", sum(counter.values()))\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee5733",
   "metadata": {},
   "source": [
    "**(c) The existence of the OOV words is one of the well-known limitations of Word2vec (or Glove).\n",
    "Without using any transformer-based language models (e.g., BERT, GPT, T5), what do you\n",
    "think is the best strategy to mitigate such limitation? Implement your solution in your source\n",
    "code. Show the corresponding code snippet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf93d4",
   "metadata": {},
   "source": [
    "One way to mitigate the problem of OOV words is to replace them with  \\<unk\\>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c905876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_oov_with_unk(tokens, glove_vocab):\n",
    "    return [token if token.lower() in glove_vocab else '<unk>' for token in tokens]\n",
    "\n",
    "for example in train_data.examples:\n",
    "    tokens = example.text\n",
    "    example.text = replace_oov_with_unk(tokens, glove_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506867f4",
   "metadata": {},
   "source": [
    "Double check that the number of \\<unk\\> replaced the same number of OOV words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7aeb5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_count = 0\n",
    "for example in train_data.examples:\n",
    "    label = example.label\n",
    "    tokens = example.text\n",
    "    for token in tokens:\n",
    "        # Lowercase token to match GloVe casing\n",
    "        token_lower = token.lower()\n",
    "        if token_lower == \"<unk>\":\n",
    "            unk_count += 1\n",
    "unk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1320b",
   "metadata": {},
   "source": [
    "## Rebuild training data vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2491ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, vectors=glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ca6661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated vocabulary size: 7903\n"
     ]
    }
   ],
   "source": [
    "updated_vocab = TEXT.vocab\n",
    "print(f\"Updated vocabulary size: {len(updated_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83c3e8",
   "metadata": {},
   "source": [
    "**d) Select the 20 most frequent words from each topic category in the training set (removing\n",
    "stopwords if necessary). Retrieve their pretrained embeddings (from Word2Vec or GloVe).\n",
    "Project these embeddings into 2D space (using e.g., t-SNE or Principal Component Analysis).\n",
    "Plot the points in a scatter plot, color-coded by their topic category. Attach your plot here.\n",
    "Analyze your findings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2a9f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/asherlim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import torchtext\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Collect tokens by topic, remove stopwords, non-alpha tokens\n",
    "tokens_by_topic = defaultdict(list)\n",
    "for example in train_data.examples:\n",
    "    label = example.label\n",
    "    tokens = example.text\n",
    "    filtered_tokens = [t.lower() for t in tokens if t.isalpha() and t.lower() not in stop_words]\n",
    "    tokens_by_topic[label].extend(filtered_tokens)\n",
    "\n",
    "# Select top 20 frequent words by topic\n",
    "top_words_by_topic = {}\n",
    "for topic, tokens in tokens_by_topic.items():\n",
    "    counter = Counter(tokens)\n",
    "    top_words_by_topic[topic] = [w for w, _ in counter.most_common(20)]\n",
    "\n",
    "# Retrieve pretrained embeddings for these words\n",
    "vectors = TEXT.vocab.vectors\n",
    "vocab_stoi = TEXT.vocab.stoi\n",
    "\n",
    "word_vectors = []\n",
    "labels_for_words = []\n",
    "words_flat = []\n",
    "\n",
    "for topic, words in top_words_by_topic.items():\n",
    "    for word in words:\n",
    "        idx = vocab_stoi.get(word, -1)\n",
    "        if idx >= 0:\n",
    "            vec = vectors[idx].numpy()\n",
    "            word_vectors.append(vec)\n",
    "            labels_for_words.append(topic)\n",
    "            words_flat.append(word)\n",
    "\n",
    "word_vectors = np.array(word_vectors)\n",
    "\n",
    "# t-SNE projection to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "# Plot scatter plot color-coded by topics\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.tab10.colors\n",
    "unique_topics = sorted(top_words_by_topic.keys())\n",
    "color_dict = {topic: colors[i % 10] for i, topic in enumerate(unique_topics)}\n",
    "\n",
    "for topic in unique_topics:\n",
    "    indices = [i for i, t in enumerate(labels_for_words) if t == topic]\n",
    "    plt.scatter(embeddings_2d[indices, 0], embeddings_2d[indices, 1],\n",
    "                c=[color_dict[topic]], label=topic)\n",
    "\n",
    "for i, word in enumerate(words_flat):\n",
    "    plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]), fontsize=8)\n",
    "\n",
    "plt.legend(title='Topic Category')\n",
    "plt.title('t-SNE projection of top 20 frequent words by topic in TREC training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4679759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pack(dataset):\n",
    "    return [\n",
    "        {\"tokens\": list(example.text), \"label\": example.label}\n",
    "        for example in dataset.examples\n",
    "    ]\n",
    "\n",
    "artifacts = {\n",
    "    \"text_field_kwargs\": {\n",
    "        \"tokenize\": \"spacy\",\n",
    "        \"tokenizer_language\": \"en_core_web_sm\",\n",
    "        \"include_lengths\": True,\n",
    "        \"pad_token\": TEXT.pad_token,\n",
    "        \"unk_token\": TEXT.unk_token,\n",
    "    },\n",
    "    \"label_field_kwargs\": {},          # keep for symmetry\n",
    "    \"text_vocab_itos\": list(TEXT.vocab.itos),\n",
    "    \"text_vocab_vectors\": TEXT.vocab.vectors.cpu(),\n",
    "    \"label_vocab_itos\": list(LABEL.vocab.itos),\n",
    "    \"train_examples\": _pack(train_data),\n",
    "    \"valid_examples\": _pack(valid_data),\n",
    "    \"test_examples\": _pack(test_data),\n",
    "    \"batch_size\": 64,\n",
    "}\n",
    "torch.save(artifacts, \"trec_artifacts.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4ac86",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Distinct Topic Clusters: Some topic categories (like “LOC” for locations and “HUM” for human/person entities) show partial clustering, indicating that frequent words in these topics are semantically related in the embedding space.\n",
    "\n",
    "Overlap Between Topics: There is overlap between certain categories, especially between “NUM” (numerical entities), “DESC” (descriptive), and “ENTY” (entities), revealing that these categories share common or semantically similar vocabularies (e.g., “number,” “year,” “name”).\n",
    "\n",
    "Topic-specific Outliers: Certain words such as “baseball” (NUM), “capital” (LOC), “actor” (HUM) are positioned toward the periphery, suggesting that they have more unique, topic-centric semantic content compared to other frequent words.\n",
    "\n",
    "Embedding Quality: The visualization demonstrates that GloVe embeddings capture topical and semantic relationships to a large extent; words with similar meanings or roles often emerge closer together regardless of label.\n",
    "\n",
    "Ambiguity & Polysemy: Some words appear in the vicinity of different clusters or overlap areas (e.g., “mean” in DESC and NUM, “movie” in HUM and ENTY), reflecting ambiguity or multi-topic relevance.\n",
    "\n",
    "Vocabulary Sharing Across Topics: Frequent generic words (“name,” “meaning,” “state,” “form”) are distributed among various topics, supporting the linguistically expected overlap among question categories.\n",
    "\n",
    "Dimensionality Reduction Artifacts: t-SNE is nonlinear and can distort true distances, so while relative local clusters are meaningful, global distances should not be overinterpreted.\n",
    "\n",
    "Label Noise: Some “outliers” may be artifacts of labeling or low sample counts; actual use in downstream classification should consider this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30792392",
   "metadata": {},
   "source": [
    "## End of Qn 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e2a5f",
   "metadata": {},
   "source": [
    "---\n",
    "## Qn 2: Model Training & Evaluation - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cea7f8",
   "metadata": {},
   "source": [
    "**(a) Report the final configuration of your best model, namely: the number of training epochs, learning rate, optimizer, batch size and hidden dimension.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1c7c0",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "Here our approach is to do hyperparameter tuning by trying out different combinations of learning rate, optimizers, batch size and number of hidden dimensions.\n",
    "1. Learning Rate: [0.0001, 0.0005, 0.001, 0.005]\n",
    "2. Optimizers: [SGD, AdaGrad, Adam, RMSprop]\n",
    "3. Batch Size: [32. 64, 128]\n",
    "4. Number of Hidden Dimensions: [64, 128, 256]\n",
    "\n",
    "For the number of training epochs, we implemented early stopping here, and so we will report that as the number obtained for this part.\n",
    "\n",
    "Note: Although we could have done cross validation through methods like GridSearchCV and RandomSearchCV, we had a huge parameter list to search from and doing even 2/3 fold CV would be computationally demanding. We also made this decision after running the initial hyperparam tuning and we decided that the results are decent enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25d4b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Class for Qn 2 - Make them learnable parameters\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, text, label, vocab):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.text[idx].split()\n",
    "        label = self.label[idx]\n",
    "        indices = [self.vocab[token] if token in self.vocab else self.vocab['<unk>'] for token in tokens]\n",
    "\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=TEXT.vocab.stoi['<pad>'])\n",
    "    labels = torch.stack(labels)\n",
    "    return texts_padded, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "023d3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4362\n",
      "4362\n"
     ]
    }
   ],
   "source": [
    "# Create train, valid, test texts and labels\n",
    "train_texts = [\" \".join(example.text) for example in train_data.examples]\n",
    "train_labels = [LABEL.vocab.stoi[example.label] for example in train_data.examples]\n",
    "\n",
    "valid_texts = [\" \".join(example.text) for example in valid_data.examples]\n",
    "valid_labels = [LABEL.vocab.stoi[example.label] for example in valid_data.examples]\n",
    "\n",
    "test_texts = [\" \".join(example.text) for example in test_data.examples]\n",
    "test_labels = [LABEL.vocab.stoi[example.label] for example in test_data.examples]\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = SentenceDataset(train_texts, train_labels, TEXT.vocab.stoi)\n",
    "valid_dataset = SentenceDataset(valid_texts, valid_labels, TEXT.vocab.stoi)\n",
    "test_dataset = SentenceDataset(test_texts, test_labels, TEXT.vocab.stoi)\n",
    "\n",
    "# Check length of train dataset and train data\n",
    "print(len(train_dataset))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2208c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN Classifier, here we do only a single hidden layer to keep it small and simple\n",
    "# We take input word embeddings, pass through RNN, apply dropout, and then a fully connected layer to get logits for 6 classes (as per qn requirement)\n",
    "class ClassifierRNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, dropout=0.0):\n",
    "        super(ClassifierRNN, self).__init__()\n",
    "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 6) # since 6 possible labels\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout(hidden[-1]) # Default is to take last layer's hidden state\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9fcd84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training, evaluation, and testing loops\n",
    "def train_loop(model, loader, optimizer, criterion, grad_clip=False, max_norm=1.0):\n",
    "    model.train()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for texts, labels in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip:\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_correct = total_correct / len(loader.dataset)\n",
    "    return avg_loss, avg_correct\n",
    "\n",
    "def eval_loop(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in loader:\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_correct = total_correct / len(loader.dataset)\n",
    "    return avg_loss, avg_correct\n",
    "\n",
    "def test_loop(model, loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in loader:\n",
    "            outputs = model(texts)\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc = total_correct / len(loader.dataset)\n",
    "    return acc\n",
    "\n",
    "# Early stopper to prevent overfitting as default to determine a suitable num_epochs,\n",
    "# here we use val_acc as the metrics as recommended metrics for training (as per qn requirements)\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.max_validation_acc = float('-inf')\n",
    "\n",
    "    def early_stop(self, validation_acc):\n",
    "        if validation_acc > self.max_validation_acc + self.min_delta:\n",
    "            self.max_validation_acc = validation_acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ea7a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture metrics and print training results per epoch\n",
    "def training_step(model, train_loader, valid_loader, optimizer, criterion, num_epochs, grad_clip=False, max_norm=1.0):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    early_stopper = EarlyStopper(patience=5, min_delta=0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_loop(model, train_loader, optimizer, criterion, grad_clip=grad_clip, max_norm=max_norm)\n",
    "        valid_loss, valid_acc = eval_loop(model, valid_loader, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}\")\n",
    "        print(f\"Valid loss: {valid_loss:.4f}, Valid acc: {valid_acc:.4f}\")\n",
    "\n",
    "        if early_stopper.early_stop(valid_acc):\n",
    "            print(\"Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\")\n",
    "            no_epochs = epoch+1\n",
    "            break\n",
    "\n",
    "        no_epochs = epoch+1\n",
    "\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies, no_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd8b69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get optimal hyperparameters\n",
    "def find_optimal_hyperparams(param_grid, embedding_matrix):\n",
    "    best_valid_acc = 0\n",
    "    best_hyperparams = {}\n",
    "    results = []\n",
    "\n",
    "    combinations_list = list(product(*param_grid.values()))\n",
    "\n",
    "    for params in combinations_list:\n",
    "        lr, optimizer, batch_size, hidden_dim = params\n",
    "        hyperparams = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with hyperparameters: {hyperparams}\")\n",
    "\n",
    "        model = ClassifierRNN(embedding_matrix, hidden_dim, dropout=0)\n",
    "        criterion = nn.CrossEntropyLoss() # Use CE Loss, since multi-class classification\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        optimizer = optimizer(model.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "        _, _, _, valid_accuracies, no_epochs = training_step(model, train_loader, valid_loader, optimizer, criterion, num_epochs=200) # Only take val acc since that is what we want to report\n",
    "\n",
    "        max_acc = max(valid_accuracies)\n",
    "\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'optimizer': optimizer,\n",
    "            'batch_size': batch_size,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'best_valid_acc': max(valid_accuracies),\n",
    "            'epochs ran': no_epochs\n",
    "        })\n",
    "\n",
    "        if max_acc > best_valid_acc:\n",
    "            best_valid_acc = max_acc\n",
    "            best_hyperparams = {\n",
    "                'lr': lr,\n",
    "                'optimizer': optimizer,\n",
    "                'batch_size': batch_size,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'epochs ran': no_epochs\n",
    "            }\n",
    "\n",
    "    print(\"Best Hyperparamters: \", best_hyperparams)\n",
    "    print(\"Best validation accuracy: \", best_valid_acc)\n",
    "\n",
    "    return results, best_hyperparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c5141d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.8521, Train acc: 0.0151\n",
      "Valid loss: 1.8483, Valid acc: 0.0183\n",
      "Epoch 2:\n",
      "Train loss: 1.8500, Train acc: 0.0154\n",
      "Valid loss: 1.8457, Valid acc: 0.0183\n",
      "Epoch 3:\n",
      "Train loss: 1.8480, Train acc: 0.0151\n",
      "Valid loss: 1.8432, Valid acc: 0.0183\n",
      "Epoch 4:\n",
      "Train loss: 1.8447, Train acc: 0.0154\n",
      "Valid loss: 1.8408, Valid acc: 0.0183\n",
      "Epoch 5:\n",
      "Train loss: 1.8428, Train acc: 0.0151\n",
      "Valid loss: 1.8384, Valid acc: 0.0183\n",
      "Epoch 6:\n",
      "Train loss: 1.8413, Train acc: 0.0151\n",
      "Valid loss: 1.8360, Valid acc: 0.0183\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7781, Train acc: 0.2121\n",
      "Valid loss: 1.7750, Valid acc: 0.2303\n",
      "Epoch 2:\n",
      "Train loss: 1.7766, Train acc: 0.2116\n",
      "Valid loss: 1.7733, Valid acc: 0.2321\n",
      "Epoch 3:\n",
      "Train loss: 1.7752, Train acc: 0.2153\n",
      "Valid loss: 1.7717, Valid acc: 0.2339\n",
      "Epoch 4:\n",
      "Train loss: 1.7739, Train acc: 0.2114\n",
      "Valid loss: 1.7701, Valid acc: 0.2385\n",
      "Epoch 5:\n",
      "Train loss: 1.7724, Train acc: 0.2121\n",
      "Valid loss: 1.7686, Valid acc: 0.2394\n",
      "Epoch 6:\n",
      "Train loss: 1.7709, Train acc: 0.2139\n",
      "Valid loss: 1.7670, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.7695, Train acc: 0.2157\n",
      "Valid loss: 1.7655, Valid acc: 0.2440\n",
      "Epoch 8:\n",
      "Train loss: 1.7679, Train acc: 0.2173\n",
      "Valid loss: 1.7640, Valid acc: 0.2450\n",
      "Epoch 9:\n",
      "Train loss: 1.7663, Train acc: 0.2157\n",
      "Valid loss: 1.7625, Valid acc: 0.2477\n",
      "Epoch 10:\n",
      "Train loss: 1.7649, Train acc: 0.2199\n",
      "Valid loss: 1.7611, Valid acc: 0.2495\n",
      "Epoch 11:\n",
      "Train loss: 1.7635, Train acc: 0.2226\n",
      "Valid loss: 1.7597, Valid acc: 0.2486\n",
      "Epoch 12:\n",
      "Train loss: 1.7624, Train acc: 0.2203\n",
      "Valid loss: 1.7582, Valid acc: 0.2477\n",
      "Epoch 13:\n",
      "Train loss: 1.7602, Train acc: 0.2226\n",
      "Valid loss: 1.7568, Valid acc: 0.2486\n",
      "Epoch 14:\n",
      "Train loss: 1.7592, Train acc: 0.2242\n",
      "Valid loss: 1.7554, Valid acc: 0.2486\n",
      "Epoch 15:\n",
      "Train loss: 1.7576, Train acc: 0.2297\n",
      "Valid loss: 1.7541, Valid acc: 0.2505\n",
      "Epoch 16:\n",
      "Train loss: 1.7562, Train acc: 0.2240\n",
      "Valid loss: 1.7527, Valid acc: 0.2541\n",
      "Epoch 17:\n",
      "Train loss: 1.7559, Train acc: 0.2274\n",
      "Valid loss: 1.7514, Valid acc: 0.2505\n",
      "Epoch 18:\n",
      "Train loss: 1.7541, Train acc: 0.2331\n",
      "Valid loss: 1.7501, Valid acc: 0.2596\n",
      "Epoch 19:\n",
      "Train loss: 1.7527, Train acc: 0.2334\n",
      "Valid loss: 1.7488, Valid acc: 0.2587\n",
      "Epoch 20:\n",
      "Train loss: 1.7515, Train acc: 0.2095\n",
      "Valid loss: 1.7475, Valid acc: 0.2110\n",
      "Epoch 21:\n",
      "Train loss: 1.7500, Train acc: 0.2137\n",
      "Valid loss: 1.7462, Valid acc: 0.2138\n",
      "Epoch 22:\n",
      "Train loss: 1.7490, Train acc: 0.2127\n",
      "Valid loss: 1.7449, Valid acc: 0.2193\n",
      "Epoch 23:\n",
      "Train loss: 1.7479, Train acc: 0.2192\n",
      "Valid loss: 1.7437, Valid acc: 0.2183\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7861, Train acc: 0.2139\n",
      "Valid loss: 1.7854, Valid acc: 0.1862\n",
      "Epoch 2:\n",
      "Train loss: 1.7846, Train acc: 0.2157\n",
      "Valid loss: 1.7838, Valid acc: 0.1881\n",
      "Epoch 3:\n",
      "Train loss: 1.7828, Train acc: 0.2150\n",
      "Valid loss: 1.7822, Valid acc: 0.1881\n",
      "Epoch 4:\n",
      "Train loss: 1.7816, Train acc: 0.2146\n",
      "Valid loss: 1.7806, Valid acc: 0.1899\n",
      "Epoch 5:\n",
      "Train loss: 1.7799, Train acc: 0.2164\n",
      "Valid loss: 1.7791, Valid acc: 0.1917\n",
      "Epoch 6:\n",
      "Train loss: 1.7783, Train acc: 0.2182\n",
      "Valid loss: 1.7775, Valid acc: 0.1917\n",
      "Epoch 7:\n",
      "Train loss: 1.7768, Train acc: 0.2162\n",
      "Valid loss: 1.7760, Valid acc: 0.1908\n",
      "Epoch 8:\n",
      "Train loss: 1.7753, Train acc: 0.2182\n",
      "Valid loss: 1.7745, Valid acc: 0.1908\n",
      "Epoch 9:\n",
      "Train loss: 1.7740, Train acc: 0.2146\n",
      "Valid loss: 1.7730, Valid acc: 0.1917\n",
      "Epoch 10:\n",
      "Train loss: 1.7726, Train acc: 0.2144\n",
      "Valid loss: 1.7716, Valid acc: 0.1927\n",
      "Epoch 11:\n",
      "Train loss: 1.7707, Train acc: 0.2185\n",
      "Valid loss: 1.7702, Valid acc: 0.1936\n",
      "Epoch 12:\n",
      "Train loss: 1.7703, Train acc: 0.2127\n",
      "Valid loss: 1.7687, Valid acc: 0.1927\n",
      "Epoch 13:\n",
      "Train loss: 1.7684, Train acc: 0.2178\n",
      "Valid loss: 1.7673, Valid acc: 0.1936\n",
      "Epoch 14:\n",
      "Train loss: 1.7670, Train acc: 0.2208\n",
      "Valid loss: 1.7659, Valid acc: 0.1945\n",
      "Epoch 15:\n",
      "Train loss: 1.7655, Train acc: 0.2189\n",
      "Valid loss: 1.7646, Valid acc: 0.1945\n",
      "Epoch 16:\n",
      "Train loss: 1.7645, Train acc: 0.2187\n",
      "Valid loss: 1.7632, Valid acc: 0.1945\n",
      "Epoch 17:\n",
      "Train loss: 1.7631, Train acc: 0.2212\n",
      "Valid loss: 1.7619, Valid acc: 0.1945\n",
      "Epoch 18:\n",
      "Train loss: 1.7623, Train acc: 0.2134\n",
      "Valid loss: 1.7606, Valid acc: 0.1954\n",
      "Epoch 19:\n",
      "Train loss: 1.7604, Train acc: 0.2176\n",
      "Valid loss: 1.7593, Valid acc: 0.1963\n",
      "Epoch 20:\n",
      "Train loss: 1.7591, Train acc: 0.2192\n",
      "Valid loss: 1.7580, Valid acc: 0.1972\n",
      "Epoch 21:\n",
      "Train loss: 1.7577, Train acc: 0.2182\n",
      "Valid loss: 1.7567, Valid acc: 0.1972\n",
      "Epoch 22:\n",
      "Train loss: 1.7567, Train acc: 0.2208\n",
      "Valid loss: 1.7554, Valid acc: 0.1982\n",
      "Epoch 23:\n",
      "Train loss: 1.7557, Train acc: 0.2166\n",
      "Valid loss: 1.7542, Valid acc: 0.1991\n",
      "Epoch 24:\n",
      "Train loss: 1.7542, Train acc: 0.2238\n",
      "Valid loss: 1.7529, Valid acc: 0.2000\n",
      "Epoch 25:\n",
      "Train loss: 1.7528, Train acc: 0.2224\n",
      "Valid loss: 1.7517, Valid acc: 0.2000\n",
      "Epoch 26:\n",
      "Train loss: 1.7517, Train acc: 0.2208\n",
      "Valid loss: 1.7505, Valid acc: 0.2000\n",
      "Epoch 27:\n",
      "Train loss: 1.7510, Train acc: 0.2203\n",
      "Valid loss: 1.7493, Valid acc: 0.2000\n",
      "Epoch 28:\n",
      "Train loss: 1.7494, Train acc: 0.2217\n",
      "Valid loss: 1.7481, Valid acc: 0.2018\n",
      "Epoch 29:\n",
      "Train loss: 1.7482, Train acc: 0.2203\n",
      "Valid loss: 1.7469, Valid acc: 0.2028\n",
      "Epoch 30:\n",
      "Train loss: 1.7474, Train acc: 0.2194\n",
      "Valid loss: 1.7457, Valid acc: 0.2028\n",
      "Epoch 31:\n",
      "Train loss: 1.7460, Train acc: 0.2233\n",
      "Valid loss: 1.7445, Valid acc: 0.2018\n",
      "Epoch 32:\n",
      "Train loss: 1.7449, Train acc: 0.2258\n",
      "Valid loss: 1.7434, Valid acc: 0.2018\n",
      "Epoch 33:\n",
      "Train loss: 1.7436, Train acc: 0.2224\n",
      "Valid loss: 1.7422, Valid acc: 0.2028\n",
      "Epoch 34:\n",
      "Train loss: 1.7428, Train acc: 0.2233\n",
      "Valid loss: 1.7411, Valid acc: 0.2000\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7916, Train acc: 0.1559\n",
      "Valid loss: 1.7988, Valid acc: 0.1550\n",
      "Epoch 2:\n",
      "Train loss: 1.7909, Train acc: 0.1543\n",
      "Valid loss: 1.7980, Valid acc: 0.1550\n",
      "Epoch 3:\n",
      "Train loss: 1.7907, Train acc: 0.1547\n",
      "Valid loss: 1.7972, Valid acc: 0.1550\n",
      "Epoch 4:\n",
      "Train loss: 1.7892, Train acc: 0.1536\n",
      "Valid loss: 1.7965, Valid acc: 0.1550\n",
      "Epoch 5:\n",
      "Train loss: 1.7888, Train acc: 0.1552\n",
      "Valid loss: 1.7957, Valid acc: 0.1550\n",
      "Epoch 6:\n",
      "Train loss: 1.7883, Train acc: 0.1547\n",
      "Valid loss: 1.7949, Valid acc: 0.1550\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.8042, Train acc: 0.1667\n",
      "Valid loss: 1.8009, Valid acc: 0.1394\n",
      "Epoch 2:\n",
      "Train loss: 1.8036, Train acc: 0.1692\n",
      "Valid loss: 1.7999, Valid acc: 0.1404\n",
      "Epoch 3:\n",
      "Train loss: 1.8022, Train acc: 0.1676\n",
      "Valid loss: 1.7988, Valid acc: 0.1404\n",
      "Epoch 4:\n",
      "Train loss: 1.8014, Train acc: 0.1687\n",
      "Valid loss: 1.7978, Valid acc: 0.1404\n",
      "Epoch 5:\n",
      "Train loss: 1.8001, Train acc: 0.1706\n",
      "Valid loss: 1.7968, Valid acc: 0.1404\n",
      "Epoch 6:\n",
      "Train loss: 1.7997, Train acc: 0.1713\n",
      "Valid loss: 1.7958, Valid acc: 0.1413\n",
      "Epoch 7:\n",
      "Train loss: 1.7985, Train acc: 0.1680\n",
      "Valid loss: 1.7948, Valid acc: 0.1413\n",
      "Epoch 8:\n",
      "Train loss: 1.7971, Train acc: 0.1729\n",
      "Valid loss: 1.7938, Valid acc: 0.1431\n",
      "Epoch 9:\n",
      "Train loss: 1.7970, Train acc: 0.1710\n",
      "Valid loss: 1.7928, Valid acc: 0.1431\n",
      "Epoch 10:\n",
      "Train loss: 1.7956, Train acc: 0.1729\n",
      "Valid loss: 1.7919, Valid acc: 0.1431\n",
      "Epoch 11:\n",
      "Train loss: 1.7945, Train acc: 0.1715\n",
      "Valid loss: 1.7909, Valid acc: 0.1431\n",
      "Epoch 12:\n",
      "Train loss: 1.7945, Train acc: 0.1669\n",
      "Valid loss: 1.7900, Valid acc: 0.1422\n",
      "Epoch 13:\n",
      "Train loss: 1.7932, Train acc: 0.1708\n",
      "Valid loss: 1.7891, Valid acc: 0.1431\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7829, Train acc: 0.2210\n",
      "Valid loss: 1.7901, Valid acc: 0.1963\n",
      "Epoch 2:\n",
      "Train loss: 1.7821, Train acc: 0.2217\n",
      "Valid loss: 1.7893, Valid acc: 0.1963\n",
      "Epoch 3:\n",
      "Train loss: 1.7810, Train acc: 0.2194\n",
      "Valid loss: 1.7885, Valid acc: 0.1954\n",
      "Epoch 4:\n",
      "Train loss: 1.7810, Train acc: 0.2217\n",
      "Valid loss: 1.7876, Valid acc: 0.1972\n",
      "Epoch 5:\n",
      "Train loss: 1.7798, Train acc: 0.2224\n",
      "Valid loss: 1.7868, Valid acc: 0.1972\n",
      "Epoch 6:\n",
      "Train loss: 1.7789, Train acc: 0.2219\n",
      "Valid loss: 1.7860, Valid acc: 0.1982\n",
      "Epoch 7:\n",
      "Train loss: 1.7782, Train acc: 0.2238\n",
      "Valid loss: 1.7852, Valid acc: 0.2009\n",
      "Epoch 8:\n",
      "Train loss: 1.7776, Train acc: 0.2240\n",
      "Valid loss: 1.7844, Valid acc: 0.2009\n",
      "Epoch 9:\n",
      "Train loss: 1.7764, Train acc: 0.2249\n",
      "Valid loss: 1.7836, Valid acc: 0.2018\n",
      "Epoch 10:\n",
      "Train loss: 1.7754, Train acc: 0.2251\n",
      "Valid loss: 1.7828, Valid acc: 0.2028\n",
      "Epoch 11:\n",
      "Train loss: 1.7745, Train acc: 0.2260\n",
      "Valid loss: 1.7820, Valid acc: 0.2028\n",
      "Epoch 12:\n",
      "Train loss: 1.7742, Train acc: 0.2279\n",
      "Valid loss: 1.7813, Valid acc: 0.2028\n",
      "Epoch 13:\n",
      "Train loss: 1.7734, Train acc: 0.2258\n",
      "Valid loss: 1.7805, Valid acc: 0.2037\n",
      "Epoch 14:\n",
      "Train loss: 1.7730, Train acc: 0.2263\n",
      "Valid loss: 1.7797, Valid acc: 0.2046\n",
      "Epoch 15:\n",
      "Train loss: 1.7711, Train acc: 0.2265\n",
      "Valid loss: 1.7789, Valid acc: 0.2046\n",
      "Epoch 16:\n",
      "Train loss: 1.7714, Train acc: 0.2263\n",
      "Valid loss: 1.7782, Valid acc: 0.2046\n",
      "Epoch 17:\n",
      "Train loss: 1.7697, Train acc: 0.2279\n",
      "Valid loss: 1.7774, Valid acc: 0.2046\n",
      "Epoch 18:\n",
      "Train loss: 1.7697, Train acc: 0.2254\n",
      "Valid loss: 1.7767, Valid acc: 0.2046\n",
      "Epoch 19:\n",
      "Train loss: 1.7685, Train acc: 0.2270\n",
      "Valid loss: 1.7760, Valid acc: 0.2037\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7928, Train acc: 0.1534\n",
      "Valid loss: 1.7933, Valid acc: 0.1541\n",
      "Epoch 2:\n",
      "Train loss: 1.7946, Train acc: 0.1534\n",
      "Valid loss: 1.7929, Valid acc: 0.1541\n",
      "Epoch 3:\n",
      "Train loss: 1.7951, Train acc: 0.1525\n",
      "Valid loss: 1.7925, Valid acc: 0.1541\n",
      "Epoch 4:\n",
      "Train loss: 1.7932, Train acc: 0.1531\n",
      "Valid loss: 1.7920, Valid acc: 0.1541\n",
      "Epoch 5:\n",
      "Train loss: 1.7944, Train acc: 0.1534\n",
      "Valid loss: 1.7916, Valid acc: 0.1541\n",
      "Epoch 6:\n",
      "Train loss: 1.7917, Train acc: 0.1545\n",
      "Valid loss: 1.7911, Valid acc: 0.1541\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.8106, Train acc: 0.0195\n",
      "Valid loss: 1.8149, Valid acc: 0.0229\n",
      "Epoch 2:\n",
      "Train loss: 1.8099, Train acc: 0.0193\n",
      "Valid loss: 1.8143, Valid acc: 0.0229\n",
      "Epoch 3:\n",
      "Train loss: 1.8090, Train acc: 0.0197\n",
      "Valid loss: 1.8137, Valid acc: 0.0229\n",
      "Epoch 4:\n",
      "Train loss: 1.8089, Train acc: 0.0195\n",
      "Valid loss: 1.8132, Valid acc: 0.0229\n",
      "Epoch 5:\n",
      "Train loss: 1.8089, Train acc: 0.0199\n",
      "Valid loss: 1.8126, Valid acc: 0.0229\n",
      "Epoch 6:\n",
      "Train loss: 1.8081, Train acc: 0.0202\n",
      "Valid loss: 1.8120, Valid acc: 0.0229\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7877, Train acc: 0.2095\n",
      "Valid loss: 1.7841, Valid acc: 0.2358\n",
      "Epoch 2:\n",
      "Train loss: 1.7886, Train acc: 0.2095\n",
      "Valid loss: 1.7837, Valid acc: 0.2358\n",
      "Epoch 3:\n",
      "Train loss: 1.7883, Train acc: 0.2082\n",
      "Valid loss: 1.7834, Valid acc: 0.2358\n",
      "Epoch 4:\n",
      "Train loss: 1.7894, Train acc: 0.2075\n",
      "Valid loss: 1.7830, Valid acc: 0.2358\n",
      "Epoch 5:\n",
      "Train loss: 1.7879, Train acc: 0.2075\n",
      "Valid loss: 1.7826, Valid acc: 0.2358\n",
      "Epoch 6:\n",
      "Train loss: 1.7876, Train acc: 0.2088\n",
      "Valid loss: 1.7823, Valid acc: 0.2358\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7948, Train acc: 0.1719\n",
      "Valid loss: 1.7962, Valid acc: 0.1688\n",
      "Epoch 2:\n",
      "Train loss: 1.7845, Train acc: 0.1717\n",
      "Valid loss: 1.7885, Valid acc: 0.1697\n",
      "Epoch 3:\n",
      "Train loss: 1.7775, Train acc: 0.1852\n",
      "Valid loss: 1.7824, Valid acc: 0.1991\n",
      "Epoch 4:\n",
      "Train loss: 1.7734, Train acc: 0.2260\n",
      "Valid loss: 1.7772, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.7680, Train acc: 0.2295\n",
      "Valid loss: 1.7724, Valid acc: 0.2064\n",
      "Epoch 6:\n",
      "Train loss: 1.7631, Train acc: 0.2297\n",
      "Valid loss: 1.7679, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.7572, Train acc: 0.2293\n",
      "Valid loss: 1.7636, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.7538, Train acc: 0.2293\n",
      "Valid loss: 1.7595, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.7493, Train acc: 0.2293\n",
      "Valid loss: 1.7555, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.7465, Train acc: 0.2293\n",
      "Valid loss: 1.7516, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7746, Train acc: 0.2295\n",
      "Valid loss: 1.7671, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.7597, Train acc: 0.2293\n",
      "Valid loss: 1.7544, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.7491, Train acc: 0.2293\n",
      "Valid loss: 1.7437, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.7390, Train acc: 0.2293\n",
      "Valid loss: 1.7334, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.7300, Train acc: 0.2293\n",
      "Valid loss: 1.7229, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.7198, Train acc: 0.2293\n",
      "Valid loss: 1.7125, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7662, Train acc: 0.2137\n",
      "Valid loss: 1.7373, Valid acc: 0.2385\n",
      "Epoch 2:\n",
      "Train loss: 1.7137, Train acc: 0.2238\n",
      "Valid loss: 1.6791, Valid acc: 0.2450\n",
      "Epoch 3:\n",
      "Train loss: 1.6690, Train acc: 0.2235\n",
      "Valid loss: 1.6567, Valid acc: 0.2413\n",
      "Epoch 4:\n",
      "Train loss: 1.6562, Train acc: 0.2267\n",
      "Valid loss: 1.6522, Valid acc: 0.2358\n",
      "Epoch 5:\n",
      "Train loss: 1.6523, Train acc: 0.2242\n",
      "Valid loss: 1.6506, Valid acc: 0.2312\n",
      "Epoch 6:\n",
      "Train loss: 1.6510, Train acc: 0.2274\n",
      "Valid loss: 1.6499, Valid acc: 0.2312\n",
      "Epoch 7:\n",
      "Train loss: 1.6507, Train acc: 0.2341\n",
      "Valid loss: 1.6497, Valid acc: 0.2037\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7720, Train acc: 0.2290\n",
      "Valid loss: 1.7623, Valid acc: 0.2477\n",
      "Epoch 2:\n",
      "Train loss: 1.7646, Train acc: 0.2311\n",
      "Valid loss: 1.7580, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.7623, Train acc: 0.2276\n",
      "Valid loss: 1.7546, Valid acc: 0.2468\n",
      "Epoch 4:\n",
      "Train loss: 1.7588, Train acc: 0.2297\n",
      "Valid loss: 1.7519, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.7564, Train acc: 0.2290\n",
      "Valid loss: 1.7494, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.7540, Train acc: 0.2293\n",
      "Valid loss: 1.7472, Valid acc: 0.2468\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7726, Train acc: 0.2001\n",
      "Valid loss: 1.7704, Valid acc: 0.2330\n",
      "Epoch 2:\n",
      "Train loss: 1.7602, Train acc: 0.2070\n",
      "Valid loss: 1.7609, Valid acc: 0.2349\n",
      "Epoch 3:\n",
      "Train loss: 1.7510, Train acc: 0.2100\n",
      "Valid loss: 1.7528, Valid acc: 0.2376\n",
      "Epoch 4:\n",
      "Train loss: 1.7427, Train acc: 0.2121\n",
      "Valid loss: 1.7452, Valid acc: 0.2404\n",
      "Epoch 5:\n",
      "Train loss: 1.7363, Train acc: 0.2157\n",
      "Valid loss: 1.7376, Valid acc: 0.2385\n",
      "Epoch 6:\n",
      "Train loss: 1.7278, Train acc: 0.2194\n",
      "Valid loss: 1.7296, Valid acc: 0.2404\n",
      "Epoch 7:\n",
      "Train loss: 1.7178, Train acc: 0.2400\n",
      "Valid loss: 1.7213, Valid acc: 0.2028\n",
      "Epoch 8:\n",
      "Train loss: 1.7104, Train acc: 0.2283\n",
      "Valid loss: 1.7131, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.7022, Train acc: 0.2293\n",
      "Valid loss: 1.7051, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7750, Train acc: 0.2256\n",
      "Valid loss: 1.7528, Valid acc: 0.2468\n",
      "Epoch 2:\n",
      "Train loss: 1.7448, Train acc: 0.2313\n",
      "Valid loss: 1.7197, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.7032, Train acc: 0.2276\n",
      "Valid loss: 1.6728, Valid acc: 0.2486\n",
      "Epoch 4:\n",
      "Train loss: 1.6688, Train acc: 0.2311\n",
      "Valid loss: 1.6564, Valid acc: 0.2404\n",
      "Epoch 5:\n",
      "Train loss: 1.6582, Train acc: 0.2290\n",
      "Valid loss: 1.6509, Valid acc: 0.2073\n",
      "Epoch 6:\n",
      "Train loss: 1.6542, Train acc: 0.2247\n",
      "Valid loss: 1.6486, Valid acc: 0.2073\n",
      "Epoch 7:\n",
      "Train loss: 1.6499, Train acc: 0.2263\n",
      "Valid loss: 1.6473, Valid acc: 0.2073\n",
      "Epoch 8:\n",
      "Train loss: 1.6493, Train acc: 0.2295\n",
      "Valid loss: 1.6473, Valid acc: 0.2073\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7862, Train acc: 0.2276\n",
      "Valid loss: 1.7824, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.7805, Train acc: 0.2283\n",
      "Valid loss: 1.7788, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.7770, Train acc: 0.2274\n",
      "Valid loss: 1.7760, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.7747, Train acc: 0.2283\n",
      "Valid loss: 1.7737, Valid acc: 0.2459\n",
      "Epoch 5:\n",
      "Train loss: 1.7730, Train acc: 0.2276\n",
      "Valid loss: 1.7717, Valid acc: 0.2459\n",
      "Epoch 6:\n",
      "Train loss: 1.7718, Train acc: 0.2295\n",
      "Valid loss: 1.7698, Valid acc: 0.2459\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7890, Train acc: 0.2251\n",
      "Valid loss: 1.7810, Valid acc: 0.2028\n",
      "Epoch 2:\n",
      "Train loss: 1.7765, Train acc: 0.2267\n",
      "Valid loss: 1.7700, Valid acc: 0.2037\n",
      "Epoch 3:\n",
      "Train loss: 1.7648, Train acc: 0.2283\n",
      "Valid loss: 1.7612, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.7586, Train acc: 0.2283\n",
      "Valid loss: 1.7534, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.7506, Train acc: 0.2283\n",
      "Valid loss: 1.7461, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.7416, Train acc: 0.2286\n",
      "Valid loss: 1.7391, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.7342, Train acc: 0.2293\n",
      "Valid loss: 1.7320, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.7249, Train acc: 0.2290\n",
      "Valid loss: 1.7252, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7814, Train acc: 0.1825\n",
      "Valid loss: 1.7710, Valid acc: 0.2541\n",
      "Epoch 2:\n",
      "Train loss: 1.7626, Train acc: 0.2267\n",
      "Valid loss: 1.7550, Valid acc: 0.2009\n",
      "Epoch 3:\n",
      "Train loss: 1.7495, Train acc: 0.2290\n",
      "Valid loss: 1.7392, Valid acc: 0.2009\n",
      "Epoch 4:\n",
      "Train loss: 1.7286, Train acc: 0.2288\n",
      "Valid loss: 1.7192, Valid acc: 0.2028\n",
      "Epoch 5:\n",
      "Train loss: 1.7071, Train acc: 0.2293\n",
      "Valid loss: 1.6939, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6811, Train acc: 0.2293\n",
      "Valid loss: 1.6733, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7712, Train acc: 0.1710\n",
      "Valid loss: 1.7008, Valid acc: 0.2064\n",
      "Epoch 2:\n",
      "Train loss: 1.6677, Train acc: 0.2249\n",
      "Valid loss: 1.6468, Valid acc: 0.2450\n",
      "Epoch 3:\n",
      "Train loss: 1.6474, Train acc: 0.2352\n",
      "Valid loss: 1.6446, Valid acc: 0.2550\n",
      "Epoch 4:\n",
      "Train loss: 1.6472, Train acc: 0.2338\n",
      "Valid loss: 1.6448, Valid acc: 0.2477\n",
      "Epoch 5:\n",
      "Train loss: 1.6453, Train acc: 0.2238\n",
      "Valid loss: 1.6429, Valid acc: 0.2431\n",
      "Epoch 6:\n",
      "Train loss: 1.6465, Train acc: 0.2258\n",
      "Valid loss: 1.6464, Valid acc: 0.2330\n",
      "Epoch 7:\n",
      "Train loss: 1.6465, Train acc: 0.2215\n",
      "Valid loss: 1.6430, Valid acc: 0.2413\n",
      "Epoch 8:\n",
      "Train loss: 1.6444, Train acc: 0.2313\n",
      "Valid loss: 1.6448, Valid acc: 0.2394\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7061, Train acc: 0.2219\n",
      "Valid loss: 1.6437, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.6493, Train acc: 0.2286\n",
      "Valid loss: 1.6464, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6512, Train acc: 0.2215\n",
      "Valid loss: 1.6455, Valid acc: 0.2495\n",
      "Epoch 4:\n",
      "Train loss: 1.6464, Train acc: 0.2217\n",
      "Valid loss: 1.6428, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6468, Train acc: 0.2302\n",
      "Valid loss: 1.6474, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6460, Train acc: 0.2373\n",
      "Valid loss: 1.6431, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.6438, Train acc: 0.2384\n",
      "Valid loss: 1.6470, Valid acc: 0.2376\n",
      "Epoch 8:\n",
      "Train loss: 1.6391, Train acc: 0.2481\n",
      "Valid loss: 1.6512, Valid acc: 0.2229\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6936, Train acc: 0.2134\n",
      "Valid loss: 1.6527, Valid acc: 0.2073\n",
      "Epoch 2:\n",
      "Train loss: 1.6471, Train acc: 0.2357\n",
      "Valid loss: 1.6530, Valid acc: 0.2495\n",
      "Epoch 3:\n",
      "Train loss: 1.6503, Train acc: 0.2306\n",
      "Valid loss: 1.6487, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6398, Train acc: 0.2462\n",
      "Valid loss: 1.6542, Valid acc: 0.2303\n",
      "Epoch 5:\n",
      "Train loss: 1.6332, Train acc: 0.2696\n",
      "Valid loss: 1.5344, Valid acc: 0.3688\n",
      "Epoch 6:\n",
      "Train loss: 1.4722, Train acc: 0.3847\n",
      "Valid loss: 1.4428, Valid acc: 0.3862\n",
      "Epoch 7:\n",
      "Train loss: 1.4023, Train acc: 0.4042\n",
      "Valid loss: 1.3766, Valid acc: 0.4312\n",
      "Epoch 8:\n",
      "Train loss: 1.2846, Train acc: 0.4505\n",
      "Valid loss: 1.2763, Valid acc: 0.4881\n",
      "Epoch 9:\n",
      "Train loss: 1.1771, Train acc: 0.5062\n",
      "Valid loss: 1.2714, Valid acc: 0.4679\n",
      "Epoch 10:\n",
      "Train loss: 1.1145, Train acc: 0.5452\n",
      "Valid loss: 1.1799, Valid acc: 0.5229\n",
      "Epoch 11:\n",
      "Train loss: 1.0247, Train acc: 0.5938\n",
      "Valid loss: 1.0306, Valid acc: 0.6174\n",
      "Epoch 12:\n",
      "Train loss: 0.9243, Train acc: 0.6470\n",
      "Valid loss: 1.0452, Valid acc: 0.6193\n",
      "Epoch 13:\n",
      "Train loss: 0.8990, Train acc: 0.6508\n",
      "Valid loss: 0.9815, Valid acc: 0.6587\n",
      "Epoch 14:\n",
      "Train loss: 0.8556, Train acc: 0.6738\n",
      "Valid loss: 0.9265, Valid acc: 0.6670\n",
      "Epoch 15:\n",
      "Train loss: 0.8414, Train acc: 0.6956\n",
      "Valid loss: 0.9158, Valid acc: 0.6991\n",
      "Epoch 16:\n",
      "Train loss: 0.8022, Train acc: 0.7031\n",
      "Valid loss: 0.9353, Valid acc: 0.6835\n",
      "Epoch 17:\n",
      "Train loss: 0.7847, Train acc: 0.7189\n",
      "Valid loss: 0.8853, Valid acc: 0.7138\n",
      "Epoch 18:\n",
      "Train loss: 0.7073, Train acc: 0.7570\n",
      "Valid loss: 0.8550, Valid acc: 0.7284\n",
      "Epoch 19:\n",
      "Train loss: 0.6951, Train acc: 0.7788\n",
      "Valid loss: 0.8562, Valid acc: 0.6697\n",
      "Epoch 20:\n",
      "Train loss: 0.6424, Train acc: 0.7983\n",
      "Valid loss: 0.8371, Valid acc: 0.7275\n",
      "Epoch 21:\n",
      "Train loss: 0.6245, Train acc: 0.8106\n",
      "Valid loss: 0.8372, Valid acc: 0.7330\n",
      "Epoch 22:\n",
      "Train loss: 0.5884, Train acc: 0.8221\n",
      "Valid loss: 0.9056, Valid acc: 0.7450\n",
      "Epoch 23:\n",
      "Train loss: 0.5768, Train acc: 0.8267\n",
      "Valid loss: 0.8882, Valid acc: 0.7394\n",
      "Epoch 24:\n",
      "Train loss: 0.5831, Train acc: 0.8246\n",
      "Valid loss: 0.8655, Valid acc: 0.7367\n",
      "Epoch 25:\n",
      "Train loss: 0.5318, Train acc: 0.8457\n",
      "Valid loss: 0.7747, Valid acc: 0.7780\n",
      "Epoch 26:\n",
      "Train loss: 0.4912, Train acc: 0.8661\n",
      "Valid loss: 0.7685, Valid acc: 0.7798\n",
      "Epoch 27:\n",
      "Train loss: 0.5222, Train acc: 0.8608\n",
      "Valid loss: 0.7742, Valid acc: 0.7706\n",
      "Epoch 28:\n",
      "Train loss: 0.4657, Train acc: 0.8762\n",
      "Valid loss: 0.7450, Valid acc: 0.7881\n",
      "Epoch 29:\n",
      "Train loss: 0.4754, Train acc: 0.8680\n",
      "Valid loss: 0.8117, Valid acc: 0.7587\n",
      "Epoch 30:\n",
      "Train loss: 0.4399, Train acc: 0.8845\n",
      "Valid loss: 0.8532, Valid acc: 0.7697\n",
      "Epoch 31:\n",
      "Train loss: 0.4415, Train acc: 0.8874\n",
      "Valid loss: 0.8979, Valid acc: 0.7266\n",
      "Epoch 32:\n",
      "Train loss: 0.4318, Train acc: 0.8911\n",
      "Valid loss: 0.8046, Valid acc: 0.7780\n",
      "Epoch 33:\n",
      "Train loss: 0.4018, Train acc: 0.8968\n",
      "Valid loss: 0.8520, Valid acc: 0.7771\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7674, Train acc: 0.1772\n",
      "Valid loss: 1.7323, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6865, Train acc: 0.2272\n",
      "Valid loss: 1.6538, Valid acc: 0.2101\n",
      "Epoch 3:\n",
      "Train loss: 1.6521, Train acc: 0.2258\n",
      "Valid loss: 1.6465, Valid acc: 0.2468\n",
      "Epoch 4:\n",
      "Train loss: 1.6488, Train acc: 0.2235\n",
      "Valid loss: 1.6488, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6517, Train acc: 0.2215\n",
      "Valid loss: 1.6473, Valid acc: 0.2092\n",
      "Epoch 6:\n",
      "Train loss: 1.6523, Train acc: 0.2315\n",
      "Valid loss: 1.6451, Valid acc: 0.2468\n",
      "Epoch 7:\n",
      "Train loss: 1.6483, Train acc: 0.2263\n",
      "Valid loss: 1.6467, Valid acc: 0.2468\n",
      "Epoch 8:\n",
      "Train loss: 1.6485, Train acc: 0.2288\n",
      "Valid loss: 1.6446, Valid acc: 0.2450\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7497, Train acc: 0.2302\n",
      "Valid loss: 1.6707, Valid acc: 0.2468\n",
      "Epoch 2:\n",
      "Train loss: 1.6576, Train acc: 0.2258\n",
      "Valid loss: 1.6473, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6496, Train acc: 0.2251\n",
      "Valid loss: 1.6497, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6475, Train acc: 0.2302\n",
      "Valid loss: 1.6460, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6527, Train acc: 0.2290\n",
      "Valid loss: 1.6459, Valid acc: 0.2477\n",
      "Epoch 6:\n",
      "Train loss: 1.6470, Train acc: 0.2387\n",
      "Valid loss: 1.6570, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6506, Train acc: 0.2354\n",
      "Valid loss: 1.6431, Valid acc: 0.2459\n",
      "Epoch 8:\n",
      "Train loss: 1.6474, Train acc: 0.2297\n",
      "Valid loss: 1.6443, Valid acc: 0.2413\n",
      "Epoch 9:\n",
      "Train loss: 1.6460, Train acc: 0.2217\n",
      "Valid loss: 1.6475, Valid acc: 0.2394\n",
      "Epoch 10:\n",
      "Train loss: 1.6458, Train acc: 0.2398\n",
      "Valid loss: 1.6460, Valid acc: 0.2486\n",
      "Epoch 11:\n",
      "Train loss: 1.6402, Train acc: 0.2487\n",
      "Valid loss: 1.6588, Valid acc: 0.2321\n",
      "Epoch 12:\n",
      "Train loss: 1.6343, Train acc: 0.2675\n",
      "Valid loss: 1.6418, Valid acc: 0.2706\n",
      "Epoch 13:\n",
      "Train loss: 1.5177, Train acc: 0.3588\n",
      "Valid loss: 1.5009, Valid acc: 0.3844\n",
      "Epoch 14:\n",
      "Train loss: 1.4069, Train acc: 0.4010\n",
      "Valid loss: 1.3907, Valid acc: 0.4073\n",
      "Epoch 15:\n",
      "Train loss: 1.3121, Train acc: 0.4285\n",
      "Valid loss: 1.3617, Valid acc: 0.4202\n",
      "Epoch 16:\n",
      "Train loss: 1.2253, Train acc: 0.4642\n",
      "Valid loss: 1.3154, Valid acc: 0.4615\n",
      "Epoch 17:\n",
      "Train loss: 1.1756, Train acc: 0.4938\n",
      "Valid loss: 1.2429, Valid acc: 0.4853\n",
      "Epoch 18:\n",
      "Train loss: 1.1339, Train acc: 0.5248\n",
      "Valid loss: 1.2175, Valid acc: 0.4780\n",
      "Epoch 19:\n",
      "Train loss: 1.0806, Train acc: 0.5344\n",
      "Valid loss: 1.1364, Valid acc: 0.5147\n",
      "Epoch 20:\n",
      "Train loss: 1.0270, Train acc: 0.5672\n",
      "Valid loss: 1.1277, Valid acc: 0.5495\n",
      "Epoch 21:\n",
      "Train loss: 0.9788, Train acc: 0.6121\n",
      "Valid loss: 1.1049, Valid acc: 0.5697\n",
      "Epoch 22:\n",
      "Train loss: 0.9732, Train acc: 0.6295\n",
      "Valid loss: 1.0736, Valid acc: 0.5587\n",
      "Epoch 23:\n",
      "Train loss: 0.9410, Train acc: 0.6364\n",
      "Valid loss: 1.1525, Valid acc: 0.5404\n",
      "Epoch 24:\n",
      "Train loss: 0.8654, Train acc: 0.6729\n",
      "Valid loss: 1.0603, Valid acc: 0.5945\n",
      "Epoch 25:\n",
      "Train loss: 0.8239, Train acc: 0.7066\n",
      "Valid loss: 1.0030, Valid acc: 0.6119\n",
      "Epoch 26:\n",
      "Train loss: 0.7979, Train acc: 0.7114\n",
      "Valid loss: 0.9383, Valid acc: 0.6450\n",
      "Epoch 27:\n",
      "Train loss: 0.7533, Train acc: 0.7460\n",
      "Valid loss: 1.0588, Valid acc: 0.5982\n",
      "Epoch 28:\n",
      "Train loss: 0.7126, Train acc: 0.7595\n",
      "Valid loss: 0.9158, Valid acc: 0.6697\n",
      "Epoch 29:\n",
      "Train loss: 0.6891, Train acc: 0.7733\n",
      "Valid loss: 0.8807, Valid acc: 0.6761\n",
      "Epoch 30:\n",
      "Train loss: 0.6690, Train acc: 0.7762\n",
      "Valid loss: 1.0069, Valid acc: 0.6275\n",
      "Epoch 31:\n",
      "Train loss: 0.6701, Train acc: 0.7822\n",
      "Valid loss: 0.8649, Valid acc: 0.7028\n",
      "Epoch 32:\n",
      "Train loss: 0.6032, Train acc: 0.8226\n",
      "Valid loss: 0.8819, Valid acc: 0.7092\n",
      "Epoch 33:\n",
      "Train loss: 0.5883, Train acc: 0.8278\n",
      "Valid loss: 0.8750, Valid acc: 0.7303\n",
      "Epoch 34:\n",
      "Train loss: 0.5461, Train acc: 0.8505\n",
      "Valid loss: 0.8122, Valid acc: 0.7367\n",
      "Epoch 35:\n",
      "Train loss: 0.5210, Train acc: 0.8613\n",
      "Valid loss: 0.7917, Valid acc: 0.7578\n",
      "Epoch 36:\n",
      "Train loss: 0.4934, Train acc: 0.8767\n",
      "Valid loss: 0.8177, Valid acc: 0.7358\n",
      "Epoch 37:\n",
      "Train loss: 0.4765, Train acc: 0.8815\n",
      "Valid loss: 0.7776, Valid acc: 0.7606\n",
      "Epoch 38:\n",
      "Train loss: 0.4674, Train acc: 0.8778\n",
      "Valid loss: 0.7697, Valid acc: 0.7725\n",
      "Epoch 39:\n",
      "Train loss: 0.4453, Train acc: 0.8897\n",
      "Valid loss: 0.7612, Valid acc: 0.7697\n",
      "Epoch 40:\n",
      "Train loss: 0.4107, Train acc: 0.9012\n",
      "Valid loss: 0.7875, Valid acc: 0.7688\n",
      "Epoch 41:\n",
      "Train loss: 0.3888, Train acc: 0.9074\n",
      "Valid loss: 0.7626, Valid acc: 0.7725\n",
      "Epoch 42:\n",
      "Train loss: 0.3937, Train acc: 0.9088\n",
      "Valid loss: 0.7773, Valid acc: 0.7725\n",
      "Epoch 43:\n",
      "Train loss: 0.3578, Train acc: 0.9186\n",
      "Valid loss: 0.7784, Valid acc: 0.7752\n",
      "Epoch 44:\n",
      "Train loss: 0.3810, Train acc: 0.9133\n",
      "Valid loss: 0.7964, Valid acc: 0.7752\n",
      "Epoch 45:\n",
      "Train loss: 0.3291, Train acc: 0.9285\n",
      "Valid loss: 0.7850, Valid acc: 0.7798\n",
      "Epoch 46:\n",
      "Train loss: 0.3226, Train acc: 0.9292\n",
      "Valid loss: 0.8236, Valid acc: 0.7670\n",
      "Epoch 47:\n",
      "Train loss: 0.3206, Train acc: 0.9289\n",
      "Valid loss: 0.7634, Valid acc: 0.7881\n",
      "Epoch 48:\n",
      "Train loss: 0.3184, Train acc: 0.9276\n",
      "Valid loss: 0.8576, Valid acc: 0.7716\n",
      "Epoch 49:\n",
      "Train loss: 0.3302, Train acc: 0.9285\n",
      "Valid loss: 0.8043, Valid acc: 0.7706\n",
      "Epoch 50:\n",
      "Train loss: 0.3046, Train acc: 0.9294\n",
      "Valid loss: 0.8392, Valid acc: 0.7670\n",
      "Epoch 51:\n",
      "Train loss: 0.2859, Train acc: 0.9363\n",
      "Valid loss: 0.7922, Valid acc: 0.7908\n",
      "Epoch 52:\n",
      "Train loss: 0.2800, Train acc: 0.9379\n",
      "Valid loss: 0.7758, Valid acc: 0.7899\n",
      "Epoch 53:\n",
      "Train loss: 0.2718, Train acc: 0.9415\n",
      "Valid loss: 0.7751, Valid acc: 0.7936\n",
      "Epoch 54:\n",
      "Train loss: 0.2689, Train acc: 0.9431\n",
      "Valid loss: 0.7978, Valid acc: 0.7798\n",
      "Epoch 55:\n",
      "Train loss: 0.2694, Train acc: 0.9429\n",
      "Valid loss: 0.7844, Valid acc: 0.7872\n",
      "Epoch 56:\n",
      "Train loss: 0.2660, Train acc: 0.9404\n",
      "Valid loss: 0.8026, Valid acc: 0.7972\n",
      "Epoch 57:\n",
      "Train loss: 0.2514, Train acc: 0.9503\n",
      "Valid loss: 0.8102, Valid acc: 0.7963\n",
      "Epoch 58:\n",
      "Train loss: 0.2453, Train acc: 0.9461\n",
      "Valid loss: 0.9058, Valid acc: 0.7642\n",
      "Epoch 59:\n",
      "Train loss: 0.2982, Train acc: 0.9310\n",
      "Valid loss: 0.7889, Valid acc: 0.7954\n",
      "Epoch 60:\n",
      "Train loss: 0.2341, Train acc: 0.9519\n",
      "Valid loss: 0.8290, Valid acc: 0.7862\n",
      "Epoch 61:\n",
      "Train loss: 0.2281, Train acc: 0.9509\n",
      "Valid loss: 0.8255, Valid acc: 0.7917\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6926, Train acc: 0.2263\n",
      "Valid loss: 1.6462, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6477, Train acc: 0.2270\n",
      "Valid loss: 1.6398, Valid acc: 0.2477\n",
      "Epoch 3:\n",
      "Train loss: 1.6506, Train acc: 0.2256\n",
      "Valid loss: 1.6427, Valid acc: 0.2431\n",
      "Epoch 4:\n",
      "Train loss: 1.6492, Train acc: 0.2270\n",
      "Valid loss: 1.6446, Valid acc: 0.2431\n",
      "Epoch 5:\n",
      "Train loss: 1.6450, Train acc: 0.2306\n",
      "Valid loss: 1.6548, Valid acc: 0.2422\n",
      "Epoch 6:\n",
      "Train loss: 1.6473, Train acc: 0.2341\n",
      "Valid loss: 1.6460, Valid acc: 0.2404\n",
      "Epoch 7:\n",
      "Train loss: 1.6449, Train acc: 0.2428\n",
      "Valid loss: 1.6475, Valid acc: 0.2468\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7672, Train acc: 0.2148\n",
      "Valid loss: 1.7597, Valid acc: 0.2376\n",
      "Epoch 2:\n",
      "Train loss: 1.7477, Train acc: 0.2111\n",
      "Valid loss: 1.7390, Valid acc: 0.2404\n",
      "Epoch 3:\n",
      "Train loss: 1.7261, Train acc: 0.2221\n",
      "Valid loss: 1.7102, Valid acc: 0.2000\n",
      "Epoch 4:\n",
      "Train loss: 1.6922, Train acc: 0.2265\n",
      "Valid loss: 1.6752, Valid acc: 0.2037\n",
      "Epoch 5:\n",
      "Train loss: 1.6652, Train acc: 0.2293\n",
      "Valid loss: 1.6589, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6606, Train acc: 0.2226\n",
      "Valid loss: 1.6548, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6552, Train acc: 0.2293\n",
      "Valid loss: 1.6533, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7824, Train acc: 0.2100\n",
      "Valid loss: 1.7591, Valid acc: 0.2037\n",
      "Epoch 2:\n",
      "Train loss: 1.7177, Train acc: 0.2288\n",
      "Valid loss: 1.6708, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6595, Train acc: 0.2242\n",
      "Valid loss: 1.6500, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6508, Train acc: 0.2219\n",
      "Valid loss: 1.6534, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6470, Train acc: 0.2224\n",
      "Valid loss: 1.6515, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6484, Train acc: 0.2267\n",
      "Valid loss: 1.6515, Valid acc: 0.2486\n",
      "Epoch 7:\n",
      "Train loss: 1.6517, Train acc: 0.2155\n",
      "Valid loss: 1.6534, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6487, Train acc: 0.2286\n",
      "Valid loss: 1.6507, Valid acc: 0.2486\n",
      "Epoch 9:\n",
      "Train loss: 1.6485, Train acc: 0.2231\n",
      "Valid loss: 1.6510, Valid acc: 0.2477\n",
      "Epoch 10:\n",
      "Train loss: 1.6493, Train acc: 0.2235\n",
      "Valid loss: 1.6526, Valid acc: 0.2055\n",
      "Epoch 11:\n",
      "Train loss: 1.6464, Train acc: 0.2272\n",
      "Valid loss: 1.6513, Valid acc: 0.2064\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7408, Train acc: 0.1976\n",
      "Valid loss: 1.6739, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6628, Train acc: 0.2221\n",
      "Valid loss: 1.6525, Valid acc: 0.2037\n",
      "Epoch 3:\n",
      "Train loss: 1.6518, Train acc: 0.2240\n",
      "Valid loss: 1.6538, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6470, Train acc: 0.2338\n",
      "Valid loss: 1.6493, Valid acc: 0.2459\n",
      "Epoch 5:\n",
      "Train loss: 1.6525, Train acc: 0.2274\n",
      "Valid loss: 1.6497, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6521, Train acc: 0.2226\n",
      "Valid loss: 1.6553, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.6527, Train acc: 0.2249\n",
      "Valid loss: 1.6503, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6475, Train acc: 0.2235\n",
      "Valid loss: 1.6509, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6462, Train acc: 0.2235\n",
      "Valid loss: 1.6532, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6943, Train acc: 0.2217\n",
      "Valid loss: 1.6510, Valid acc: 0.2349\n",
      "Epoch 2:\n",
      "Train loss: 1.6509, Train acc: 0.2288\n",
      "Valid loss: 1.6511, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6456, Train acc: 0.2297\n",
      "Valid loss: 1.6479, Valid acc: 0.2284\n",
      "Epoch 4:\n",
      "Train loss: 1.6447, Train acc: 0.2311\n",
      "Valid loss: 1.6447, Valid acc: 0.2349\n",
      "Epoch 5:\n",
      "Train loss: 1.6444, Train acc: 0.2249\n",
      "Valid loss: 1.6441, Valid acc: 0.2358\n",
      "Epoch 6:\n",
      "Train loss: 1.6443, Train acc: 0.2348\n",
      "Valid loss: 1.6489, Valid acc: 0.2303\n",
      "Epoch 7:\n",
      "Train loss: 1.6441, Train acc: 0.2396\n",
      "Valid loss: 1.6443, Valid acc: 0.2495\n",
      "Epoch 8:\n",
      "Train loss: 1.6399, Train acc: 0.2398\n",
      "Valid loss: 1.6480, Valid acc: 0.2303\n",
      "Epoch 9:\n",
      "Train loss: 1.6385, Train acc: 0.2492\n",
      "Valid loss: 1.6474, Valid acc: 0.2422\n",
      "Epoch 10:\n",
      "Train loss: 1.6416, Train acc: 0.2549\n",
      "Valid loss: 1.6415, Valid acc: 0.2642\n",
      "Epoch 11:\n",
      "Train loss: 1.6114, Train acc: 0.2905\n",
      "Valid loss: 1.5577, Valid acc: 0.3495\n",
      "Epoch 12:\n",
      "Train loss: 1.4930, Train acc: 0.3796\n",
      "Valid loss: 1.4730, Valid acc: 0.3826\n",
      "Epoch 13:\n",
      "Train loss: 1.4234, Train acc: 0.4110\n",
      "Valid loss: 1.4334, Valid acc: 0.4110\n",
      "Epoch 14:\n",
      "Train loss: 1.3937, Train acc: 0.4207\n",
      "Valid loss: 1.4335, Valid acc: 0.3982\n",
      "Epoch 15:\n",
      "Train loss: 1.3574, Train acc: 0.4248\n",
      "Valid loss: 1.3754, Valid acc: 0.4183\n",
      "Epoch 16:\n",
      "Train loss: 1.3156, Train acc: 0.4482\n",
      "Valid loss: 1.3673, Valid acc: 0.4284\n",
      "Epoch 17:\n",
      "Train loss: 1.2887, Train acc: 0.4521\n",
      "Valid loss: 1.3441, Valid acc: 0.4394\n",
      "Epoch 18:\n",
      "Train loss: 1.2532, Train acc: 0.4684\n",
      "Valid loss: 1.3303, Valid acc: 0.4514\n",
      "Epoch 19:\n",
      "Train loss: 1.2157, Train acc: 0.4773\n",
      "Valid loss: 1.3055, Valid acc: 0.4670\n",
      "Epoch 20:\n",
      "Train loss: 1.1830, Train acc: 0.4993\n",
      "Valid loss: 1.2876, Valid acc: 0.4780\n",
      "Epoch 21:\n",
      "Train loss: 1.1417, Train acc: 0.5080\n",
      "Valid loss: 1.2572, Valid acc: 0.4954\n",
      "Epoch 22:\n",
      "Train loss: 1.1125, Train acc: 0.5147\n",
      "Valid loss: 1.2154, Valid acc: 0.5083\n",
      "Epoch 23:\n",
      "Train loss: 1.0665, Train acc: 0.5358\n",
      "Valid loss: 1.3565, Valid acc: 0.4651\n",
      "Epoch 24:\n",
      "Train loss: 1.0442, Train acc: 0.5413\n",
      "Valid loss: 1.1616, Valid acc: 0.5303\n",
      "Epoch 25:\n",
      "Train loss: 1.0158, Train acc: 0.5520\n",
      "Valid loss: 1.1377, Valid acc: 0.5275\n",
      "Epoch 26:\n",
      "Train loss: 0.9928, Train acc: 0.5851\n",
      "Valid loss: 1.1776, Valid acc: 0.5064\n",
      "Epoch 27:\n",
      "Train loss: 0.9752, Train acc: 0.5885\n",
      "Valid loss: 1.1668, Valid acc: 0.5239\n",
      "Epoch 28:\n",
      "Train loss: 0.9493, Train acc: 0.5949\n",
      "Valid loss: 1.1033, Valid acc: 0.5477\n",
      "Epoch 29:\n",
      "Train loss: 0.9292, Train acc: 0.6110\n",
      "Valid loss: 1.0786, Valid acc: 0.5514\n",
      "Epoch 30:\n",
      "Train loss: 0.9028, Train acc: 0.6206\n",
      "Valid loss: 1.1237, Valid acc: 0.5165\n",
      "Epoch 31:\n",
      "Train loss: 0.8856, Train acc: 0.6334\n",
      "Valid loss: 1.0695, Valid acc: 0.5596\n",
      "Epoch 32:\n",
      "Train loss: 0.8773, Train acc: 0.6476\n",
      "Valid loss: 1.0838, Valid acc: 0.5633\n",
      "Epoch 33:\n",
      "Train loss: 0.8427, Train acc: 0.6593\n",
      "Valid loss: 1.0112, Valid acc: 0.6064\n",
      "Epoch 34:\n",
      "Train loss: 0.8116, Train acc: 0.6713\n",
      "Valid loss: 1.0175, Valid acc: 0.5844\n",
      "Epoch 35:\n",
      "Train loss: 0.7886, Train acc: 0.6896\n",
      "Valid loss: 1.0188, Valid acc: 0.5927\n",
      "Epoch 36:\n",
      "Train loss: 0.7611, Train acc: 0.7017\n",
      "Valid loss: 1.0249, Valid acc: 0.6000\n",
      "Epoch 37:\n",
      "Train loss: 0.7377, Train acc: 0.7146\n",
      "Valid loss: 1.0183, Valid acc: 0.5908\n",
      "Epoch 38:\n",
      "Train loss: 0.7207, Train acc: 0.7116\n",
      "Valid loss: 0.9860, Valid acc: 0.6220\n",
      "Epoch 39:\n",
      "Train loss: 0.6991, Train acc: 0.7180\n",
      "Valid loss: 0.9385, Valid acc: 0.6266\n",
      "Epoch 40:\n",
      "Train loss: 0.6722, Train acc: 0.7359\n",
      "Valid loss: 0.9750, Valid acc: 0.6211\n",
      "Epoch 41:\n",
      "Train loss: 0.6609, Train acc: 0.7393\n",
      "Valid loss: 0.9983, Valid acc: 0.6092\n",
      "Epoch 42:\n",
      "Train loss: 0.6423, Train acc: 0.7460\n",
      "Valid loss: 0.9622, Valid acc: 0.6294\n",
      "Epoch 43:\n",
      "Train loss: 0.6167, Train acc: 0.7499\n",
      "Valid loss: 0.9554, Valid acc: 0.6202\n",
      "Epoch 44:\n",
      "Train loss: 0.6123, Train acc: 0.7533\n",
      "Valid loss: 0.9973, Valid acc: 0.6138\n",
      "Epoch 45:\n",
      "Train loss: 0.5919, Train acc: 0.7577\n",
      "Valid loss: 1.0287, Valid acc: 0.6128\n",
      "Epoch 46:\n",
      "Train loss: 0.5858, Train acc: 0.7636\n",
      "Valid loss: 0.9532, Valid acc: 0.6330\n",
      "Epoch 47:\n",
      "Train loss: 0.5742, Train acc: 0.7639\n",
      "Valid loss: 0.9022, Valid acc: 0.6560\n",
      "Epoch 48:\n",
      "Train loss: 0.5625, Train acc: 0.7689\n",
      "Valid loss: 0.9308, Valid acc: 0.6450\n",
      "Epoch 49:\n",
      "Train loss: 0.5469, Train acc: 0.7714\n",
      "Valid loss: 1.0267, Valid acc: 0.6211\n",
      "Epoch 50:\n",
      "Train loss: 0.5397, Train acc: 0.7749\n",
      "Valid loss: 1.2959, Valid acc: 0.5826\n",
      "Epoch 51:\n",
      "Train loss: 0.5382, Train acc: 0.7724\n",
      "Valid loss: 0.9889, Valid acc: 0.6358\n",
      "Epoch 52:\n",
      "Train loss: 0.5287, Train acc: 0.7808\n",
      "Valid loss: 0.9392, Valid acc: 0.6514\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6666, Train acc: 0.2274\n",
      "Valid loss: 1.6550, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6484, Train acc: 0.2325\n",
      "Valid loss: 1.6511, Valid acc: 0.2431\n",
      "Epoch 3:\n",
      "Train loss: 1.6491, Train acc: 0.2297\n",
      "Valid loss: 1.6509, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6461, Train acc: 0.2446\n",
      "Valid loss: 1.6467, Valid acc: 0.2514\n",
      "Epoch 5:\n",
      "Train loss: 1.6375, Train acc: 0.2540\n",
      "Valid loss: 1.6440, Valid acc: 0.2606\n",
      "Epoch 6:\n",
      "Train loss: 1.6352, Train acc: 0.2648\n",
      "Valid loss: 1.6247, Valid acc: 0.2651\n",
      "Epoch 7:\n",
      "Train loss: 1.5085, Train acc: 0.3732\n",
      "Valid loss: 1.4875, Valid acc: 0.3807\n",
      "Epoch 8:\n",
      "Train loss: 1.4396, Train acc: 0.3980\n",
      "Valid loss: 1.4422, Valid acc: 0.4055\n",
      "Epoch 9:\n",
      "Train loss: 1.3845, Train acc: 0.4127\n",
      "Valid loss: 1.3844, Valid acc: 0.4266\n",
      "Epoch 10:\n",
      "Train loss: 1.3195, Train acc: 0.4321\n",
      "Valid loss: 1.3210, Valid acc: 0.4468\n",
      "Epoch 11:\n",
      "Train loss: 1.2388, Train acc: 0.4773\n",
      "Valid loss: 1.2932, Valid acc: 0.4853\n",
      "Epoch 12:\n",
      "Train loss: 1.1822, Train acc: 0.5110\n",
      "Valid loss: 1.2038, Valid acc: 0.5358\n",
      "Epoch 13:\n",
      "Train loss: 1.1158, Train acc: 0.5486\n",
      "Valid loss: 1.2507, Valid acc: 0.4798\n",
      "Epoch 14:\n",
      "Train loss: 1.0595, Train acc: 0.5800\n",
      "Valid loss: 1.1112, Valid acc: 0.5908\n",
      "Epoch 15:\n",
      "Train loss: 1.0199, Train acc: 0.6052\n",
      "Valid loss: 1.3960, Valid acc: 0.4633\n",
      "Epoch 16:\n",
      "Train loss: 0.9724, Train acc: 0.6265\n",
      "Valid loss: 1.1461, Valid acc: 0.5881\n",
      "Epoch 17:\n",
      "Train loss: 0.9318, Train acc: 0.6385\n",
      "Valid loss: 1.0864, Valid acc: 0.6092\n",
      "Epoch 18:\n",
      "Train loss: 0.8976, Train acc: 0.6515\n",
      "Valid loss: 0.9805, Valid acc: 0.6330\n",
      "Epoch 19:\n",
      "Train loss: 0.8870, Train acc: 0.6598\n",
      "Valid loss: 1.0167, Valid acc: 0.6092\n",
      "Epoch 20:\n",
      "Train loss: 0.8614, Train acc: 0.6763\n",
      "Valid loss: 0.9501, Valid acc: 0.6394\n",
      "Epoch 21:\n",
      "Train loss: 0.8392, Train acc: 0.6777\n",
      "Valid loss: 0.9554, Valid acc: 0.6294\n",
      "Epoch 22:\n",
      "Train loss: 0.8146, Train acc: 0.6818\n",
      "Valid loss: 0.9433, Valid acc: 0.6486\n",
      "Epoch 23:\n",
      "Train loss: 0.7913, Train acc: 0.6923\n",
      "Valid loss: 1.0406, Valid acc: 0.6165\n",
      "Epoch 24:\n",
      "Train loss: 0.7718, Train acc: 0.6937\n",
      "Valid loss: 1.0030, Valid acc: 0.6028\n",
      "Epoch 25:\n",
      "Train loss: 0.7644, Train acc: 0.6992\n",
      "Valid loss: 0.9265, Valid acc: 0.6615\n",
      "Epoch 26:\n",
      "Train loss: 0.7434, Train acc: 0.7077\n",
      "Valid loss: 0.9119, Valid acc: 0.6606\n",
      "Epoch 27:\n",
      "Train loss: 0.7293, Train acc: 0.7180\n",
      "Valid loss: 0.9089, Valid acc: 0.6697\n",
      "Epoch 28:\n",
      "Train loss: 0.7108, Train acc: 0.7290\n",
      "Valid loss: 0.8924, Valid acc: 0.6606\n",
      "Epoch 29:\n",
      "Train loss: 0.6900, Train acc: 0.7435\n",
      "Valid loss: 0.8835, Valid acc: 0.6798\n",
      "Epoch 30:\n",
      "Train loss: 0.7058, Train acc: 0.7446\n",
      "Valid loss: 0.9797, Valid acc: 0.6385\n",
      "Epoch 31:\n",
      "Train loss: 0.6726, Train acc: 0.7515\n",
      "Valid loss: 0.8764, Valid acc: 0.6853\n",
      "Epoch 32:\n",
      "Train loss: 0.6346, Train acc: 0.7696\n",
      "Valid loss: 0.8509, Valid acc: 0.7009\n",
      "Epoch 33:\n",
      "Train loss: 0.6362, Train acc: 0.7829\n",
      "Valid loss: 0.8495, Valid acc: 0.6945\n",
      "Epoch 34:\n",
      "Train loss: 0.6368, Train acc: 0.7909\n",
      "Valid loss: 1.1200, Valid acc: 0.6009\n",
      "Epoch 35:\n",
      "Train loss: 0.5941, Train acc: 0.8097\n",
      "Valid loss: 0.9719, Valid acc: 0.6661\n",
      "Epoch 36:\n",
      "Train loss: 0.5939, Train acc: 0.8090\n",
      "Valid loss: 0.8342, Valid acc: 0.7147\n",
      "Epoch 37:\n",
      "Train loss: 0.5711, Train acc: 0.8221\n",
      "Valid loss: 1.0507, Valid acc: 0.6422\n",
      "Epoch 38:\n",
      "Train loss: 0.5388, Train acc: 0.8379\n",
      "Valid loss: 0.8534, Valid acc: 0.7147\n",
      "Epoch 39:\n",
      "Train loss: 0.5417, Train acc: 0.8384\n",
      "Valid loss: 0.9001, Valid acc: 0.7092\n",
      "Epoch 40:\n",
      "Train loss: 0.5091, Train acc: 0.8471\n",
      "Valid loss: 0.8361, Valid acc: 0.7174\n",
      "Epoch 41:\n",
      "Train loss: 0.5077, Train acc: 0.8487\n",
      "Valid loss: 0.8405, Valid acc: 0.7257\n",
      "Epoch 42:\n",
      "Train loss: 0.4738, Train acc: 0.8636\n",
      "Valid loss: 0.8943, Valid acc: 0.7294\n",
      "Epoch 43:\n",
      "Train loss: 0.4706, Train acc: 0.8643\n",
      "Valid loss: 0.9242, Valid acc: 0.7000\n",
      "Epoch 44:\n",
      "Train loss: 0.4463, Train acc: 0.8778\n",
      "Valid loss: 1.0324, Valid acc: 0.7211\n",
      "Epoch 45:\n",
      "Train loss: 0.4451, Train acc: 0.8721\n",
      "Valid loss: 0.8675, Valid acc: 0.7202\n",
      "Epoch 46:\n",
      "Train loss: 0.4482, Train acc: 0.8705\n",
      "Valid loss: 0.9015, Valid acc: 0.7092\n",
      "Epoch 47:\n",
      "Train loss: 0.4155, Train acc: 0.8810\n",
      "Valid loss: 0.8649, Valid acc: 0.7330\n",
      "Epoch 48:\n",
      "Train loss: 0.4146, Train acc: 0.8835\n",
      "Valid loss: 0.8834, Valid acc: 0.7330\n",
      "Epoch 49:\n",
      "Train loss: 0.4112, Train acc: 0.8906\n",
      "Valid loss: 0.8974, Valid acc: 0.7376\n",
      "Epoch 50:\n",
      "Train loss: 0.4041, Train acc: 0.8893\n",
      "Valid loss: 0.8923, Valid acc: 0.7229\n",
      "Epoch 51:\n",
      "Train loss: 0.3790, Train acc: 0.8968\n",
      "Valid loss: 1.0868, Valid acc: 0.6817\n",
      "Epoch 52:\n",
      "Train loss: 0.3851, Train acc: 0.9000\n",
      "Valid loss: 1.0365, Valid acc: 0.6917\n",
      "Epoch 53:\n",
      "Train loss: 0.3869, Train acc: 0.8936\n",
      "Valid loss: 0.8892, Valid acc: 0.7193\n",
      "Epoch 54:\n",
      "Train loss: 0.3374, Train acc: 0.9074\n",
      "Valid loss: 1.0827, Valid acc: 0.6835\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6599, Train acc: 0.2359\n",
      "Valid loss: 1.6524, Valid acc: 0.2321\n",
      "Epoch 2:\n",
      "Train loss: 1.6448, Train acc: 0.2407\n",
      "Valid loss: 1.6497, Valid acc: 0.2477\n",
      "Epoch 3:\n",
      "Train loss: 1.6293, Train acc: 0.2646\n",
      "Valid loss: 1.5399, Valid acc: 0.3771\n",
      "Epoch 4:\n",
      "Train loss: 1.4685, Train acc: 0.3911\n",
      "Valid loss: 1.4761, Valid acc: 0.3752\n",
      "Epoch 5:\n",
      "Train loss: 1.3759, Train acc: 0.4232\n",
      "Valid loss: 1.3997, Valid acc: 0.4220\n",
      "Epoch 6:\n",
      "Train loss: 1.2766, Train acc: 0.4574\n",
      "Valid loss: 1.4577, Valid acc: 0.3972\n",
      "Epoch 7:\n",
      "Train loss: 1.1937, Train acc: 0.4892\n",
      "Valid loss: 1.2929, Valid acc: 0.4688\n",
      "Epoch 8:\n",
      "Train loss: 1.1493, Train acc: 0.5193\n",
      "Valid loss: 1.1524, Valid acc: 0.5468\n",
      "Epoch 9:\n",
      "Train loss: 1.0976, Train acc: 0.5667\n",
      "Valid loss: 1.1211, Valid acc: 0.6064\n",
      "Epoch 10:\n",
      "Train loss: 1.0095, Train acc: 0.6100\n",
      "Valid loss: 1.0683, Valid acc: 0.5752\n",
      "Epoch 11:\n",
      "Train loss: 0.9826, Train acc: 0.6158\n",
      "Valid loss: 1.0343, Valid acc: 0.5890\n",
      "Epoch 12:\n",
      "Train loss: 0.9232, Train acc: 0.6350\n",
      "Valid loss: 0.9584, Valid acc: 0.6339\n",
      "Epoch 13:\n",
      "Train loss: 0.9182, Train acc: 0.6486\n",
      "Valid loss: 0.9597, Valid acc: 0.6165\n",
      "Epoch 14:\n",
      "Train loss: 0.8831, Train acc: 0.6573\n",
      "Valid loss: 0.9437, Valid acc: 0.6147\n",
      "Epoch 15:\n",
      "Train loss: 0.8539, Train acc: 0.6690\n",
      "Valid loss: 0.8785, Valid acc: 0.6569\n",
      "Epoch 16:\n",
      "Train loss: 0.8415, Train acc: 0.6710\n",
      "Valid loss: 0.8921, Valid acc: 0.6376\n",
      "Epoch 17:\n",
      "Train loss: 0.8199, Train acc: 0.6868\n",
      "Valid loss: 0.8823, Valid acc: 0.6771\n",
      "Epoch 18:\n",
      "Train loss: 0.8135, Train acc: 0.7004\n",
      "Valid loss: 0.8882, Valid acc: 0.6752\n",
      "Epoch 19:\n",
      "Train loss: 0.7900, Train acc: 0.7180\n",
      "Valid loss: 1.0854, Valid acc: 0.6459\n",
      "Epoch 20:\n",
      "Train loss: 0.7569, Train acc: 0.7451\n",
      "Valid loss: 1.0912, Valid acc: 0.6119\n",
      "Epoch 21:\n",
      "Train loss: 0.7419, Train acc: 0.7627\n",
      "Valid loss: 0.8404, Valid acc: 0.7055\n",
      "Epoch 22:\n",
      "Train loss: 0.6969, Train acc: 0.7824\n",
      "Valid loss: 0.9074, Valid acc: 0.7266\n",
      "Epoch 23:\n",
      "Train loss: 0.6751, Train acc: 0.7930\n",
      "Valid loss: 0.9320, Valid acc: 0.7119\n",
      "Epoch 24:\n",
      "Train loss: 0.6480, Train acc: 0.8081\n",
      "Valid loss: 0.7932, Valid acc: 0.7440\n",
      "Epoch 25:\n",
      "Train loss: 0.6147, Train acc: 0.8249\n",
      "Valid loss: 0.9106, Valid acc: 0.7220\n",
      "Epoch 26:\n",
      "Train loss: 0.6762, Train acc: 0.8026\n",
      "Valid loss: 0.9123, Valid acc: 0.7248\n",
      "Epoch 27:\n",
      "Train loss: 0.5867, Train acc: 0.8349\n",
      "Valid loss: 0.8244, Valid acc: 0.7220\n",
      "Epoch 28:\n",
      "Train loss: 0.5668, Train acc: 0.8356\n",
      "Valid loss: 0.7964, Valid acc: 0.7523\n",
      "Epoch 29:\n",
      "Train loss: 0.5576, Train acc: 0.8404\n",
      "Valid loss: 0.7455, Valid acc: 0.7752\n",
      "Epoch 30:\n",
      "Train loss: 0.5495, Train acc: 0.8487\n",
      "Valid loss: 0.8539, Valid acc: 0.7541\n",
      "Epoch 31:\n",
      "Train loss: 0.5250, Train acc: 0.8565\n",
      "Valid loss: 0.7225, Valid acc: 0.7844\n",
      "Epoch 32:\n",
      "Train loss: 0.5389, Train acc: 0.8524\n",
      "Valid loss: 0.7246, Valid acc: 0.7881\n",
      "Epoch 33:\n",
      "Train loss: 0.6561, Train acc: 0.8010\n",
      "Valid loss: 0.7850, Valid acc: 0.7606\n",
      "Epoch 34:\n",
      "Train loss: 0.4917, Train acc: 0.8684\n",
      "Valid loss: 0.9593, Valid acc: 0.7147\n",
      "Epoch 35:\n",
      "Train loss: 0.5011, Train acc: 0.8629\n",
      "Valid loss: 0.7153, Valid acc: 0.7826\n",
      "Epoch 36:\n",
      "Train loss: 0.4701, Train acc: 0.8748\n",
      "Valid loss: 0.7295, Valid acc: 0.7927\n",
      "Epoch 37:\n",
      "Train loss: 0.4836, Train acc: 0.8698\n",
      "Valid loss: 1.0160, Valid acc: 0.6972\n",
      "Epoch 38:\n",
      "Train loss: 0.4681, Train acc: 0.8723\n",
      "Valid loss: 0.9108, Valid acc: 0.7248\n",
      "Epoch 39:\n",
      "Train loss: 0.4468, Train acc: 0.8856\n",
      "Valid loss: 0.9554, Valid acc: 0.7037\n",
      "Epoch 40:\n",
      "Train loss: 0.4303, Train acc: 0.8849\n",
      "Valid loss: 0.6929, Valid acc: 0.8000\n",
      "Epoch 41:\n",
      "Train loss: 0.4274, Train acc: 0.8893\n",
      "Valid loss: 0.6801, Valid acc: 0.8092\n",
      "Epoch 42:\n",
      "Train loss: 0.4221, Train acc: 0.8897\n",
      "Valid loss: 0.8131, Valid acc: 0.7578\n",
      "Epoch 43:\n",
      "Train loss: 0.4257, Train acc: 0.8890\n",
      "Valid loss: 0.7115, Valid acc: 0.8018\n",
      "Epoch 44:\n",
      "Train loss: 0.3822, Train acc: 0.9046\n",
      "Valid loss: 0.7474, Valid acc: 0.7917\n",
      "Epoch 45:\n",
      "Train loss: 0.4222, Train acc: 0.8936\n",
      "Valid loss: 0.7410, Valid acc: 0.7927\n",
      "Epoch 46:\n",
      "Train loss: 0.3802, Train acc: 0.9042\n",
      "Valid loss: 0.7163, Valid acc: 0.8128\n",
      "Epoch 47:\n",
      "Train loss: 0.3767, Train acc: 0.9072\n",
      "Valid loss: 0.7558, Valid acc: 0.8018\n",
      "Epoch 48:\n",
      "Train loss: 0.3906, Train acc: 0.9017\n",
      "Valid loss: 0.8265, Valid acc: 0.7761\n",
      "Epoch 49:\n",
      "Train loss: 0.3753, Train acc: 0.9044\n",
      "Valid loss: 0.7688, Valid acc: 0.7890\n",
      "Epoch 50:\n",
      "Train loss: 0.3627, Train acc: 0.9101\n",
      "Valid loss: 0.7775, Valid acc: 0.8046\n",
      "Epoch 51:\n",
      "Train loss: 0.3890, Train acc: 0.9030\n",
      "Valid loss: 0.7215, Valid acc: 0.8000\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7178, Train acc: 0.2217\n",
      "Valid loss: 1.6605, Valid acc: 0.2064\n",
      "Epoch 2:\n",
      "Train loss: 1.6550, Train acc: 0.2212\n",
      "Valid loss: 1.6475, Valid acc: 0.2440\n",
      "Epoch 3:\n",
      "Train loss: 1.6490, Train acc: 0.2176\n",
      "Valid loss: 1.6441, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6514, Train acc: 0.2231\n",
      "Valid loss: 1.6442, Valid acc: 0.2073\n",
      "Epoch 5:\n",
      "Train loss: 1.6480, Train acc: 0.2173\n",
      "Valid loss: 1.6463, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6497, Train acc: 0.2219\n",
      "Valid loss: 1.6456, Valid acc: 0.2028\n",
      "Epoch 7:\n",
      "Train loss: 1.6483, Train acc: 0.2315\n",
      "Valid loss: 1.6436, Valid acc: 0.2440\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6739, Train acc: 0.2267\n",
      "Valid loss: 1.6415, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6490, Train acc: 0.2290\n",
      "Valid loss: 1.6530, Valid acc: 0.2413\n",
      "Epoch 3:\n",
      "Train loss: 1.6481, Train acc: 0.2384\n",
      "Valid loss: 1.6605, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6465, Train acc: 0.2304\n",
      "Valid loss: 1.6406, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6511, Train acc: 0.2238\n",
      "Valid loss: 1.6356, Valid acc: 0.2569\n",
      "Epoch 6:\n",
      "Train loss: 1.6454, Train acc: 0.2329\n",
      "Valid loss: 1.6425, Valid acc: 0.2440\n",
      "Epoch 7:\n",
      "Train loss: 1.6468, Train acc: 0.2240\n",
      "Valid loss: 1.6469, Valid acc: 0.2642\n",
      "Epoch 8:\n",
      "Train loss: 1.6419, Train acc: 0.2361\n",
      "Valid loss: 1.6474, Valid acc: 0.2248\n",
      "Epoch 9:\n",
      "Train loss: 1.6442, Train acc: 0.2458\n",
      "Valid loss: 1.6456, Valid acc: 0.2688\n",
      "Epoch 10:\n",
      "Train loss: 1.6384, Train acc: 0.2586\n",
      "Valid loss: 1.6343, Valid acc: 0.2624\n",
      "Epoch 11:\n",
      "Train loss: 1.5122, Train acc: 0.3618\n",
      "Valid loss: 1.4791, Valid acc: 0.3771\n",
      "Epoch 12:\n",
      "Train loss: 1.4213, Train acc: 0.3881\n",
      "Valid loss: 1.4893, Valid acc: 0.3670\n",
      "Epoch 13:\n",
      "Train loss: 1.3813, Train acc: 0.4106\n",
      "Valid loss: 1.4241, Valid acc: 0.4018\n",
      "Epoch 14:\n",
      "Train loss: 1.3039, Train acc: 0.4392\n",
      "Valid loss: 1.3392, Valid acc: 0.4312\n",
      "Epoch 15:\n",
      "Train loss: 1.2538, Train acc: 0.4580\n",
      "Valid loss: 1.3640, Valid acc: 0.4275\n",
      "Epoch 16:\n",
      "Train loss: 1.1868, Train acc: 0.4954\n",
      "Valid loss: 1.3512, Valid acc: 0.4220\n",
      "Epoch 17:\n",
      "Train loss: 1.1415, Train acc: 0.5335\n",
      "Valid loss: 1.2293, Valid acc: 0.5220\n",
      "Epoch 18:\n",
      "Train loss: 1.1176, Train acc: 0.5475\n",
      "Valid loss: 1.1926, Valid acc: 0.5404\n",
      "Epoch 19:\n",
      "Train loss: 1.0717, Train acc: 0.5683\n",
      "Valid loss: 1.1921, Valid acc: 0.5183\n",
      "Epoch 20:\n",
      "Train loss: 1.0310, Train acc: 0.5873\n",
      "Valid loss: 1.1135, Valid acc: 0.5771\n",
      "Epoch 21:\n",
      "Train loss: 0.9998, Train acc: 0.6169\n",
      "Valid loss: 1.1271, Valid acc: 0.5706\n",
      "Epoch 22:\n",
      "Train loss: 0.9775, Train acc: 0.6192\n",
      "Valid loss: 1.0461, Valid acc: 0.6119\n",
      "Epoch 23:\n",
      "Train loss: 0.9422, Train acc: 0.6470\n",
      "Valid loss: 1.0802, Valid acc: 0.6083\n",
      "Epoch 24:\n",
      "Train loss: 0.9004, Train acc: 0.6726\n",
      "Valid loss: 1.1693, Valid acc: 0.5587\n",
      "Epoch 25:\n",
      "Train loss: 0.8601, Train acc: 0.6905\n",
      "Valid loss: 0.9955, Valid acc: 0.6550\n",
      "Epoch 26:\n",
      "Train loss: 0.8401, Train acc: 0.7004\n",
      "Valid loss: 1.0240, Valid acc: 0.6385\n",
      "Epoch 27:\n",
      "Train loss: 0.8858, Train acc: 0.6949\n",
      "Valid loss: 1.0612, Valid acc: 0.6294\n",
      "Epoch 28:\n",
      "Train loss: 0.7967, Train acc: 0.7334\n",
      "Valid loss: 0.9213, Valid acc: 0.6908\n",
      "Epoch 29:\n",
      "Train loss: 0.7665, Train acc: 0.7409\n",
      "Valid loss: 1.1493, Valid acc: 0.6183\n",
      "Epoch 30:\n",
      "Train loss: 0.7338, Train acc: 0.7627\n",
      "Valid loss: 1.0689, Valid acc: 0.6413\n",
      "Epoch 31:\n",
      "Train loss: 0.6998, Train acc: 0.7749\n",
      "Valid loss: 0.8646, Valid acc: 0.7183\n",
      "Epoch 32:\n",
      "Train loss: 0.7296, Train acc: 0.7746\n",
      "Valid loss: 0.9531, Valid acc: 0.7119\n",
      "Epoch 33:\n",
      "Train loss: 0.6681, Train acc: 0.7983\n",
      "Valid loss: 1.1422, Valid acc: 0.6046\n",
      "Epoch 34:\n",
      "Train loss: 0.6556, Train acc: 0.7992\n",
      "Valid loss: 0.8630, Valid acc: 0.7450\n",
      "Epoch 35:\n",
      "Train loss: 0.6400, Train acc: 0.8040\n",
      "Valid loss: 0.9236, Valid acc: 0.7211\n",
      "Epoch 36:\n",
      "Train loss: 0.6324, Train acc: 0.8184\n",
      "Valid loss: 1.9133, Valid acc: 0.5165\n",
      "Epoch 37:\n",
      "Train loss: 0.6253, Train acc: 0.8191\n",
      "Valid loss: 0.8619, Valid acc: 0.7339\n",
      "Epoch 38:\n",
      "Train loss: 0.5644, Train acc: 0.8434\n",
      "Valid loss: 0.8379, Valid acc: 0.7367\n",
      "Epoch 39:\n",
      "Train loss: 0.5993, Train acc: 0.8292\n",
      "Valid loss: 0.9093, Valid acc: 0.7321\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6639, Train acc: 0.2286\n",
      "Valid loss: 1.6438, Valid acc: 0.2413\n",
      "Epoch 2:\n",
      "Train loss: 1.6469, Train acc: 0.2240\n",
      "Valid loss: 1.6649, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6504, Train acc: 0.2306\n",
      "Valid loss: 1.6456, Valid acc: 0.2450\n",
      "Epoch 4:\n",
      "Train loss: 1.6427, Train acc: 0.2435\n",
      "Valid loss: 1.6351, Valid acc: 0.2752\n",
      "Epoch 5:\n",
      "Train loss: 1.5773, Train acc: 0.3285\n",
      "Valid loss: 1.5422, Valid acc: 0.3541\n",
      "Epoch 6:\n",
      "Train loss: 1.4672, Train acc: 0.3870\n",
      "Valid loss: 1.4926, Valid acc: 0.4110\n",
      "Epoch 7:\n",
      "Train loss: 1.4332, Train acc: 0.4062\n",
      "Valid loss: 1.4761, Valid acc: 0.3899\n",
      "Epoch 8:\n",
      "Train loss: 1.4063, Train acc: 0.4051\n",
      "Valid loss: 1.4606, Valid acc: 0.3927\n",
      "Epoch 9:\n",
      "Train loss: 1.3764, Train acc: 0.4188\n",
      "Valid loss: 1.5513, Valid acc: 0.3826\n",
      "Epoch 10:\n",
      "Train loss: 1.2836, Train acc: 0.4622\n",
      "Valid loss: 1.3160, Valid acc: 0.4385\n",
      "Epoch 11:\n",
      "Train loss: 1.2377, Train acc: 0.4704\n",
      "Valid loss: 1.2471, Valid acc: 0.4789\n",
      "Epoch 12:\n",
      "Train loss: 1.1886, Train acc: 0.5133\n",
      "Valid loss: 1.3739, Valid acc: 0.4294\n",
      "Epoch 13:\n",
      "Train loss: 1.1482, Train acc: 0.5241\n",
      "Valid loss: 1.2423, Valid acc: 0.4844\n",
      "Epoch 14:\n",
      "Train loss: 1.1099, Train acc: 0.5651\n",
      "Valid loss: 1.1601, Valid acc: 0.5486\n",
      "Epoch 15:\n",
      "Train loss: 1.0741, Train acc: 0.5786\n",
      "Valid loss: 1.1907, Valid acc: 0.5239\n",
      "Epoch 16:\n",
      "Train loss: 1.0506, Train acc: 0.5972\n",
      "Valid loss: 1.2395, Valid acc: 0.5394\n",
      "Epoch 17:\n",
      "Train loss: 1.0226, Train acc: 0.6153\n",
      "Valid loss: 1.1344, Valid acc: 0.5321\n",
      "Epoch 18:\n",
      "Train loss: 0.9632, Train acc: 0.6421\n",
      "Valid loss: 1.0161, Valid acc: 0.6303\n",
      "Epoch 19:\n",
      "Train loss: 0.9289, Train acc: 0.6460\n",
      "Valid loss: 1.0339, Valid acc: 0.5972\n",
      "Epoch 20:\n",
      "Train loss: 0.9127, Train acc: 0.6616\n",
      "Valid loss: 1.1437, Valid acc: 0.5596\n",
      "Epoch 21:\n",
      "Train loss: 0.8812, Train acc: 0.6823\n",
      "Valid loss: 1.0200, Valid acc: 0.6183\n",
      "Epoch 22:\n",
      "Train loss: 0.8651, Train acc: 0.6923\n",
      "Valid loss: 0.9716, Valid acc: 0.6587\n",
      "Epoch 23:\n",
      "Train loss: 0.8809, Train acc: 0.6878\n",
      "Valid loss: 0.9790, Valid acc: 0.6514\n",
      "Epoch 24:\n",
      "Train loss: 0.8245, Train acc: 0.7038\n",
      "Valid loss: 1.0723, Valid acc: 0.6147\n",
      "Epoch 25:\n",
      "Train loss: 0.8000, Train acc: 0.7091\n",
      "Valid loss: 0.9490, Valid acc: 0.6706\n",
      "Epoch 26:\n",
      "Train loss: 0.7983, Train acc: 0.7189\n",
      "Valid loss: 0.9580, Valid acc: 0.6541\n",
      "Epoch 27:\n",
      "Train loss: 0.8104, Train acc: 0.7166\n",
      "Valid loss: 1.0792, Valid acc: 0.6037\n",
      "Epoch 28:\n",
      "Train loss: 0.7428, Train acc: 0.7471\n",
      "Valid loss: 0.9207, Valid acc: 0.6807\n",
      "Epoch 29:\n",
      "Train loss: 0.7137, Train acc: 0.7613\n",
      "Valid loss: 0.8595, Valid acc: 0.7092\n",
      "Epoch 30:\n",
      "Train loss: 0.7266, Train acc: 0.7584\n",
      "Valid loss: 0.9479, Valid acc: 0.6972\n",
      "Epoch 31:\n",
      "Train loss: 0.6977, Train acc: 0.7691\n",
      "Valid loss: 0.8883, Valid acc: 0.7183\n",
      "Epoch 32:\n",
      "Train loss: 0.7006, Train acc: 0.7804\n",
      "Valid loss: 0.9746, Valid acc: 0.6936\n",
      "Epoch 33:\n",
      "Train loss: 0.6603, Train acc: 0.7944\n",
      "Valid loss: 0.8690, Valid acc: 0.6954\n",
      "Epoch 34:\n",
      "Train loss: 0.6890, Train acc: 0.7898\n",
      "Valid loss: 0.8801, Valid acc: 0.6697\n",
      "Epoch 35:\n",
      "Train loss: 0.6460, Train acc: 0.8047\n",
      "Valid loss: 1.0049, Valid acc: 0.6349\n",
      "Epoch 36:\n",
      "Train loss: 0.6433, Train acc: 0.7973\n",
      "Valid loss: 0.8412, Valid acc: 0.7349\n",
      "Epoch 37:\n",
      "Train loss: 0.6179, Train acc: 0.8090\n",
      "Valid loss: 0.8675, Valid acc: 0.7156\n",
      "Epoch 38:\n",
      "Train loss: 0.6284, Train acc: 0.8104\n",
      "Valid loss: 0.8077, Valid acc: 0.7294\n",
      "Epoch 39:\n",
      "Train loss: 0.5915, Train acc: 0.8134\n",
      "Valid loss: 0.8301, Valid acc: 0.7266\n",
      "Epoch 40:\n",
      "Train loss: 0.5679, Train acc: 0.8324\n",
      "Valid loss: 0.8094, Valid acc: 0.7578\n",
      "Epoch 41:\n",
      "Train loss: 0.5721, Train acc: 0.8336\n",
      "Valid loss: 0.7979, Valid acc: 0.7450\n",
      "Epoch 42:\n",
      "Train loss: 0.5658, Train acc: 0.8340\n",
      "Valid loss: 0.8093, Valid acc: 0.7459\n",
      "Epoch 43:\n",
      "Train loss: 0.5739, Train acc: 0.8320\n",
      "Valid loss: 0.9006, Valid acc: 0.7239\n",
      "Epoch 44:\n",
      "Train loss: 0.5796, Train acc: 0.8349\n",
      "Valid loss: 0.8217, Valid acc: 0.7670\n",
      "Epoch 45:\n",
      "Train loss: 0.4959, Train acc: 0.8627\n",
      "Valid loss: 0.9937, Valid acc: 0.7128\n",
      "Epoch 46:\n",
      "Train loss: 0.5191, Train acc: 0.8565\n",
      "Valid loss: 0.8197, Valid acc: 0.7413\n",
      "Epoch 47:\n",
      "Train loss: 0.5034, Train acc: 0.8599\n",
      "Valid loss: 0.8095, Valid acc: 0.7450\n",
      "Epoch 48:\n",
      "Train loss: 0.5030, Train acc: 0.8579\n",
      "Valid loss: 0.8052, Valid acc: 0.7450\n",
      "Epoch 49:\n",
      "Train loss: 0.4975, Train acc: 0.8588\n",
      "Valid loss: 0.9474, Valid acc: 0.7110\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7377, Train acc: 0.2100\n",
      "Valid loss: 1.6742, Valid acc: 0.2376\n",
      "Epoch 2:\n",
      "Train loss: 1.6683, Train acc: 0.2215\n",
      "Valid loss: 1.6597, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6513, Train acc: 0.2276\n",
      "Valid loss: 1.6541, Valid acc: 0.2495\n",
      "Epoch 4:\n",
      "Train loss: 1.6607, Train acc: 0.2293\n",
      "Valid loss: 1.6534, Valid acc: 0.2495\n",
      "Epoch 5:\n",
      "Train loss: 1.6510, Train acc: 0.2267\n",
      "Valid loss: 1.6515, Valid acc: 0.2450\n",
      "Epoch 6:\n",
      "Train loss: 1.6491, Train acc: 0.2231\n",
      "Valid loss: 1.6514, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6469, Train acc: 0.2201\n",
      "Valid loss: 1.6517, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6465, Train acc: 0.2258\n",
      "Valid loss: 1.6517, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6917, Train acc: 0.2313\n",
      "Valid loss: 1.6499, Valid acc: 0.2376\n",
      "Epoch 2:\n",
      "Train loss: 1.6601, Train acc: 0.2189\n",
      "Valid loss: 1.6553, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6483, Train acc: 0.2348\n",
      "Valid loss: 1.6482, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6449, Train acc: 0.2196\n",
      "Valid loss: 1.6580, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6459, Train acc: 0.2276\n",
      "Valid loss: 1.6643, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6519, Train acc: 0.2272\n",
      "Valid loss: 1.6553, Valid acc: 0.2495\n",
      "Epoch 7:\n",
      "Train loss: 1.6541, Train acc: 0.2247\n",
      "Valid loss: 1.6511, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6460, Train acc: 0.2265\n",
      "Valid loss: 1.6589, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6517, Train acc: 0.2238\n",
      "Valid loss: 1.6500, Valid acc: 0.2587\n",
      "Epoch 10:\n",
      "Train loss: 1.6577, Train acc: 0.2311\n",
      "Valid loss: 1.6569, Valid acc: 0.2046\n",
      "Epoch 11:\n",
      "Train loss: 1.6448, Train acc: 0.2238\n",
      "Valid loss: 1.6524, Valid acc: 0.2046\n",
      "Epoch 12:\n",
      "Train loss: 1.6513, Train acc: 0.2302\n",
      "Valid loss: 1.6513, Valid acc: 0.2486\n",
      "Epoch 13:\n",
      "Train loss: 1.6458, Train acc: 0.2357\n",
      "Valid loss: 1.6601, Valid acc: 0.2046\n",
      "Epoch 14:\n",
      "Train loss: 1.6659, Train acc: 0.2279\n",
      "Valid loss: 1.6524, Valid acc: 0.2477\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6650, Train acc: 0.2247\n",
      "Valid loss: 1.6828, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6524, Train acc: 0.2221\n",
      "Valid loss: 1.6762, Valid acc: 0.1523\n",
      "Epoch 3:\n",
      "Train loss: 1.6526, Train acc: 0.2281\n",
      "Valid loss: 1.6649, Valid acc: 0.2450\n",
      "Epoch 4:\n",
      "Train loss: 1.6524, Train acc: 0.2309\n",
      "Valid loss: 1.6535, Valid acc: 0.2385\n",
      "Epoch 5:\n",
      "Train loss: 1.6491, Train acc: 0.2320\n",
      "Valid loss: 1.6555, Valid acc: 0.2450\n",
      "Epoch 6:\n",
      "Train loss: 1.6505, Train acc: 0.2302\n",
      "Valid loss: 1.6557, Valid acc: 0.2394\n",
      "Epoch 7:\n",
      "Train loss: 1.6535, Train acc: 0.2249\n",
      "Valid loss: 1.6552, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6473, Train acc: 0.2249\n",
      "Valid loss: 1.6569, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.8096, Train acc: 0.1680\n",
      "Valid loss: 1.8125, Valid acc: 0.1477\n",
      "Epoch 2:\n",
      "Train loss: 1.8000, Train acc: 0.1692\n",
      "Valid loss: 1.8044, Valid acc: 0.1477\n",
      "Epoch 3:\n",
      "Train loss: 1.7935, Train acc: 0.1671\n",
      "Valid loss: 1.7969, Valid acc: 0.1477\n",
      "Epoch 4:\n",
      "Train loss: 1.7871, Train acc: 0.1694\n",
      "Valid loss: 1.7900, Valid acc: 0.1486\n",
      "Epoch 5:\n",
      "Train loss: 1.7807, Train acc: 0.1685\n",
      "Valid loss: 1.7835, Valid acc: 0.1477\n",
      "Epoch 6:\n",
      "Train loss: 1.7738, Train acc: 0.1694\n",
      "Valid loss: 1.7774, Valid acc: 0.1477\n",
      "Epoch 7:\n",
      "Train loss: 1.7676, Train acc: 0.1710\n",
      "Valid loss: 1.7716, Valid acc: 0.1486\n",
      "Epoch 8:\n",
      "Train loss: 1.7635, Train acc: 0.1713\n",
      "Valid loss: 1.7662, Valid acc: 0.1505\n",
      "Epoch 9:\n",
      "Train loss: 1.7577, Train acc: 0.1713\n",
      "Valid loss: 1.7610, Valid acc: 0.1578\n",
      "Epoch 10:\n",
      "Train loss: 1.7529, Train acc: 0.1724\n",
      "Valid loss: 1.7560, Valid acc: 0.1596\n",
      "Epoch 11:\n",
      "Train loss: 1.7484, Train acc: 0.1875\n",
      "Valid loss: 1.7513, Valid acc: 0.2330\n",
      "Epoch 12:\n",
      "Train loss: 1.7432, Train acc: 0.2208\n",
      "Valid loss: 1.7467, Valid acc: 0.2431\n",
      "Epoch 13:\n",
      "Train loss: 1.7392, Train acc: 0.2244\n",
      "Valid loss: 1.7423, Valid acc: 0.2450\n",
      "Epoch 14:\n",
      "Train loss: 1.7347, Train acc: 0.2270\n",
      "Valid loss: 1.7382, Valid acc: 0.2459\n",
      "Epoch 15:\n",
      "Train loss: 1.7315, Train acc: 0.2272\n",
      "Valid loss: 1.7342, Valid acc: 0.2486\n",
      "Epoch 16:\n",
      "Train loss: 1.7270, Train acc: 0.2279\n",
      "Valid loss: 1.7304, Valid acc: 0.2459\n",
      "Epoch 17:\n",
      "Train loss: 1.7245, Train acc: 0.2254\n",
      "Valid loss: 1.7266, Valid acc: 0.2477\n",
      "Epoch 18:\n",
      "Train loss: 1.7200, Train acc: 0.2286\n",
      "Valid loss: 1.7231, Valid acc: 0.2486\n",
      "Epoch 19:\n",
      "Train loss: 1.7169, Train acc: 0.2267\n",
      "Valid loss: 1.7196, Valid acc: 0.2495\n",
      "Epoch 20:\n",
      "Train loss: 1.7136, Train acc: 0.2276\n",
      "Valid loss: 1.7162, Valid acc: 0.2505\n",
      "Epoch 21:\n",
      "Train loss: 1.7090, Train acc: 0.2309\n",
      "Valid loss: 1.7130, Valid acc: 0.2495\n",
      "Epoch 22:\n",
      "Train loss: 1.7074, Train acc: 0.2288\n",
      "Valid loss: 1.7099, Valid acc: 0.2486\n",
      "Epoch 23:\n",
      "Train loss: 1.7052, Train acc: 0.2272\n",
      "Valid loss: 1.7069, Valid acc: 0.2477\n",
      "Epoch 24:\n",
      "Train loss: 1.7027, Train acc: 0.2279\n",
      "Valid loss: 1.7041, Valid acc: 0.2477\n",
      "Epoch 25:\n",
      "Train loss: 1.6987, Train acc: 0.2309\n",
      "Valid loss: 1.7013, Valid acc: 0.2477\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7732, Train acc: 0.2297\n",
      "Valid loss: 1.7607, Valid acc: 0.2486\n",
      "Epoch 2:\n",
      "Train loss: 1.7686, Train acc: 0.2263\n",
      "Valid loss: 1.7551, Valid acc: 0.2486\n",
      "Epoch 3:\n",
      "Train loss: 1.7622, Train acc: 0.2299\n",
      "Valid loss: 1.7499, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.7574, Train acc: 0.2309\n",
      "Valid loss: 1.7450, Valid acc: 0.2486\n",
      "Epoch 5:\n",
      "Train loss: 1.7525, Train acc: 0.2295\n",
      "Valid loss: 1.7403, Valid acc: 0.2477\n",
      "Epoch 6:\n",
      "Train loss: 1.7473, Train acc: 0.2318\n",
      "Valid loss: 1.7357, Valid acc: 0.2477\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7888, Train acc: 0.2050\n",
      "Valid loss: 1.7842, Valid acc: 0.2394\n",
      "Epoch 2:\n",
      "Train loss: 1.7812, Train acc: 0.2254\n",
      "Valid loss: 1.7764, Valid acc: 0.2422\n",
      "Epoch 3:\n",
      "Train loss: 1.7742, Train acc: 0.2258\n",
      "Valid loss: 1.7692, Valid acc: 0.2431\n",
      "Epoch 4:\n",
      "Train loss: 1.7674, Train acc: 0.2263\n",
      "Valid loss: 1.7625, Valid acc: 0.2422\n",
      "Epoch 5:\n",
      "Train loss: 1.7614, Train acc: 0.2265\n",
      "Valid loss: 1.7562, Valid acc: 0.2422\n",
      "Epoch 6:\n",
      "Train loss: 1.7553, Train acc: 0.2272\n",
      "Valid loss: 1.7503, Valid acc: 0.2431\n",
      "Epoch 7:\n",
      "Train loss: 1.7494, Train acc: 0.2251\n",
      "Valid loss: 1.7446, Valid acc: 0.2440\n",
      "Epoch 8:\n",
      "Train loss: 1.7446, Train acc: 0.2254\n",
      "Valid loss: 1.7392, Valid acc: 0.2450\n",
      "Epoch 9:\n",
      "Train loss: 1.7403, Train acc: 0.2258\n",
      "Valid loss: 1.7341, Valid acc: 0.2440\n",
      "Epoch 10:\n",
      "Train loss: 1.7349, Train acc: 0.2274\n",
      "Valid loss: 1.7292, Valid acc: 0.2440\n",
      "Epoch 11:\n",
      "Train loss: 1.7302, Train acc: 0.2267\n",
      "Valid loss: 1.7245, Valid acc: 0.2431\n",
      "Epoch 12:\n",
      "Train loss: 1.7255, Train acc: 0.2299\n",
      "Valid loss: 1.7201, Valid acc: 0.2431\n",
      "Epoch 13:\n",
      "Train loss: 1.7212, Train acc: 0.2272\n",
      "Valid loss: 1.7157, Valid acc: 0.2459\n",
      "Epoch 14:\n",
      "Train loss: 1.7172, Train acc: 0.2295\n",
      "Valid loss: 1.7115, Valid acc: 0.2459\n",
      "Epoch 15:\n",
      "Train loss: 1.7128, Train acc: 0.2306\n",
      "Valid loss: 1.7073, Valid acc: 0.2450\n",
      "Epoch 16:\n",
      "Train loss: 1.7096, Train acc: 0.2318\n",
      "Valid loss: 1.7035, Valid acc: 0.2459\n",
      "Epoch 17:\n",
      "Train loss: 1.7055, Train acc: 0.2304\n",
      "Valid loss: 1.6997, Valid acc: 0.2450\n",
      "Epoch 18:\n",
      "Train loss: 1.7027, Train acc: 0.2311\n",
      "Valid loss: 1.6961, Valid acc: 0.2468\n",
      "Epoch 19:\n",
      "Train loss: 1.6992, Train acc: 0.2364\n",
      "Valid loss: 1.6926, Valid acc: 0.2468\n",
      "Epoch 20:\n",
      "Train loss: 1.6964, Train acc: 0.2318\n",
      "Valid loss: 1.6893, Valid acc: 0.2486\n",
      "Epoch 21:\n",
      "Train loss: 1.6920, Train acc: 0.2354\n",
      "Valid loss: 1.6861, Valid acc: 0.2486\n",
      "Epoch 22:\n",
      "Train loss: 1.6885, Train acc: 0.2359\n",
      "Valid loss: 1.6830, Valid acc: 0.2486\n",
      "Epoch 23:\n",
      "Train loss: 1.6860, Train acc: 0.2320\n",
      "Valid loss: 1.6800, Valid acc: 0.2486\n",
      "Epoch 24:\n",
      "Train loss: 1.6838, Train acc: 0.2357\n",
      "Valid loss: 1.6772, Valid acc: 0.2477\n",
      "Epoch 25:\n",
      "Train loss: 1.6807, Train acc: 0.2350\n",
      "Valid loss: 1.6746, Valid acc: 0.2468\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7925, Train acc: 0.2272\n",
      "Valid loss: 1.8002, Valid acc: 0.2037\n",
      "Epoch 2:\n",
      "Train loss: 1.7886, Train acc: 0.2267\n",
      "Valid loss: 1.7959, Valid acc: 0.2037\n",
      "Epoch 3:\n",
      "Train loss: 1.7837, Train acc: 0.2258\n",
      "Valid loss: 1.7917, Valid acc: 0.2037\n",
      "Epoch 4:\n",
      "Train loss: 1.7805, Train acc: 0.2274\n",
      "Valid loss: 1.7876, Valid acc: 0.2037\n",
      "Epoch 5:\n",
      "Train loss: 1.7775, Train acc: 0.2279\n",
      "Valid loss: 1.7837, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.7733, Train acc: 0.2290\n",
      "Valid loss: 1.7800, Valid acc: 0.2037\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7784, Train acc: 0.1701\n",
      "Valid loss: 1.7726, Valid acc: 0.1450\n",
      "Epoch 2:\n",
      "Train loss: 1.7748, Train acc: 0.1699\n",
      "Valid loss: 1.7694, Valid acc: 0.1450\n",
      "Epoch 3:\n",
      "Train loss: 1.7720, Train acc: 0.1729\n",
      "Valid loss: 1.7663, Valid acc: 0.1413\n",
      "Epoch 4:\n",
      "Train loss: 1.7683, Train acc: 0.1692\n",
      "Valid loss: 1.7632, Valid acc: 0.1404\n",
      "Epoch 5:\n",
      "Train loss: 1.7659, Train acc: 0.1664\n",
      "Valid loss: 1.7602, Valid acc: 0.1422\n",
      "Epoch 6:\n",
      "Train loss: 1.7625, Train acc: 0.1960\n",
      "Valid loss: 1.7573, Valid acc: 0.2339\n",
      "Epoch 7:\n",
      "Train loss: 1.7592, Train acc: 0.2095\n",
      "Valid loss: 1.7544, Valid acc: 0.2358\n",
      "Epoch 8:\n",
      "Train loss: 1.7575, Train acc: 0.2095\n",
      "Valid loss: 1.7517, Valid acc: 0.2358\n",
      "Epoch 9:\n",
      "Train loss: 1.7541, Train acc: 0.2095\n",
      "Valid loss: 1.7489, Valid acc: 0.2358\n",
      "Epoch 10:\n",
      "Train loss: 1.7514, Train acc: 0.2116\n",
      "Valid loss: 1.7462, Valid acc: 0.2358\n",
      "Epoch 11:\n",
      "Train loss: 1.7497, Train acc: 0.2093\n",
      "Valid loss: 1.7436, Valid acc: 0.2358\n",
      "Epoch 12:\n",
      "Train loss: 1.7465, Train acc: 0.2109\n",
      "Valid loss: 1.7410, Valid acc: 0.2349\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7939, Train acc: 0.1564\n",
      "Valid loss: 1.7859, Valid acc: 0.1596\n",
      "Epoch 2:\n",
      "Train loss: 1.7895, Train acc: 0.1609\n",
      "Valid loss: 1.7811, Valid acc: 0.1881\n",
      "Epoch 3:\n",
      "Train loss: 1.7850, Train acc: 0.2102\n",
      "Valid loss: 1.7766, Valid acc: 0.1945\n",
      "Epoch 4:\n",
      "Train loss: 1.7809, Train acc: 0.2208\n",
      "Valid loss: 1.7723, Valid acc: 0.1972\n",
      "Epoch 5:\n",
      "Train loss: 1.7769, Train acc: 0.2180\n",
      "Valid loss: 1.7681, Valid acc: 0.2009\n",
      "Epoch 6:\n",
      "Train loss: 1.7729, Train acc: 0.2231\n",
      "Valid loss: 1.7641, Valid acc: 0.2018\n",
      "Epoch 7:\n",
      "Train loss: 1.7687, Train acc: 0.2238\n",
      "Valid loss: 1.7603, Valid acc: 0.2018\n",
      "Epoch 8:\n",
      "Train loss: 1.7651, Train acc: 0.2235\n",
      "Valid loss: 1.7565, Valid acc: 0.2018\n",
      "Epoch 9:\n",
      "Train loss: 1.7613, Train acc: 0.2235\n",
      "Valid loss: 1.7529, Valid acc: 0.2028\n",
      "Epoch 10:\n",
      "Train loss: 1.7582, Train acc: 0.2263\n",
      "Valid loss: 1.7494, Valid acc: 0.2028\n",
      "Epoch 11:\n",
      "Train loss: 1.7549, Train acc: 0.2219\n",
      "Valid loss: 1.7459, Valid acc: 0.2028\n",
      "Epoch 12:\n",
      "Train loss: 1.7521, Train acc: 0.2215\n",
      "Valid loss: 1.7427, Valid acc: 0.2028\n",
      "Epoch 13:\n",
      "Train loss: 1.7485, Train acc: 0.2228\n",
      "Valid loss: 1.7394, Valid acc: 0.2028\n",
      "Epoch 14:\n",
      "Train loss: 1.7459, Train acc: 0.2247\n",
      "Valid loss: 1.7363, Valid acc: 0.2028\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.8277, Train acc: 0.0188\n",
      "Valid loss: 1.8317, Valid acc: 0.0202\n",
      "Epoch 2:\n",
      "Train loss: 1.8237, Train acc: 0.0177\n",
      "Valid loss: 1.8295, Valid acc: 0.0202\n",
      "Epoch 3:\n",
      "Train loss: 1.8225, Train acc: 0.0917\n",
      "Valid loss: 1.8272, Valid acc: 0.1367\n",
      "Epoch 4:\n",
      "Train loss: 1.8205, Train acc: 0.1667\n",
      "Valid loss: 1.8251, Valid acc: 0.1440\n",
      "Epoch 5:\n",
      "Train loss: 1.8185, Train acc: 0.1685\n",
      "Valid loss: 1.8229, Valid acc: 0.1431\n",
      "Epoch 6:\n",
      "Train loss: 1.8152, Train acc: 0.1690\n",
      "Valid loss: 1.8208, Valid acc: 0.1440\n",
      "Epoch 7:\n",
      "Train loss: 1.8141, Train acc: 0.1708\n",
      "Valid loss: 1.8187, Valid acc: 0.1450\n",
      "Epoch 8:\n",
      "Train loss: 1.8118, Train acc: 0.1690\n",
      "Valid loss: 1.8167, Valid acc: 0.1450\n",
      "Epoch 9:\n",
      "Train loss: 1.8096, Train acc: 0.1685\n",
      "Valid loss: 1.8147, Valid acc: 0.1450\n",
      "Epoch 10:\n",
      "Train loss: 1.8083, Train acc: 0.1694\n",
      "Valid loss: 1.8127, Valid acc: 0.1450\n",
      "Epoch 11:\n",
      "Train loss: 1.8053, Train acc: 0.1715\n",
      "Valid loss: 1.8108, Valid acc: 0.1450\n",
      "Epoch 12:\n",
      "Train loss: 1.8051, Train acc: 0.1717\n",
      "Valid loss: 1.8089, Valid acc: 0.1450\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7788, Train acc: 0.2235\n",
      "Valid loss: 1.7791, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.7777, Train acc: 0.2251\n",
      "Valid loss: 1.7773, Valid acc: 0.2431\n",
      "Epoch 3:\n",
      "Train loss: 1.7749, Train acc: 0.2238\n",
      "Valid loss: 1.7755, Valid acc: 0.2431\n",
      "Epoch 4:\n",
      "Train loss: 1.7715, Train acc: 0.2247\n",
      "Valid loss: 1.7738, Valid acc: 0.2431\n",
      "Epoch 5:\n",
      "Train loss: 1.7720, Train acc: 0.2244\n",
      "Valid loss: 1.7721, Valid acc: 0.2440\n",
      "Epoch 6:\n",
      "Train loss: 1.7695, Train acc: 0.2254\n",
      "Valid loss: 1.7705, Valid acc: 0.2440\n",
      "Epoch 7:\n",
      "Train loss: 1.7689, Train acc: 0.2235\n",
      "Valid loss: 1.7689, Valid acc: 0.2440\n",
      "Epoch 8:\n",
      "Train loss: 1.7671, Train acc: 0.2258\n",
      "Valid loss: 1.7673, Valid acc: 0.2440\n",
      "Epoch 9:\n",
      "Train loss: 1.7638, Train acc: 0.2267\n",
      "Valid loss: 1.7658, Valid acc: 0.2440\n",
      "Epoch 10:\n",
      "Train loss: 1.7631, Train acc: 0.2258\n",
      "Valid loss: 1.7642, Valid acc: 0.2440\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7867, Train acc: 0.2077\n",
      "Valid loss: 1.7814, Valid acc: 0.2349\n",
      "Epoch 2:\n",
      "Train loss: 1.7835, Train acc: 0.2093\n",
      "Valid loss: 1.7798, Valid acc: 0.2349\n",
      "Epoch 3:\n",
      "Train loss: 1.7831, Train acc: 0.2086\n",
      "Valid loss: 1.7782, Valid acc: 0.2349\n",
      "Epoch 4:\n",
      "Train loss: 1.7811, Train acc: 0.2082\n",
      "Valid loss: 1.7766, Valid acc: 0.2349\n",
      "Epoch 5:\n",
      "Train loss: 1.7803, Train acc: 0.2084\n",
      "Valid loss: 1.7751, Valid acc: 0.2349\n",
      "Epoch 6:\n",
      "Train loss: 1.7777, Train acc: 0.2095\n",
      "Valid loss: 1.7736, Valid acc: 0.2349\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7217, Train acc: 0.2121\n",
      "Valid loss: 1.6868, Valid acc: 0.2413\n",
      "Epoch 2:\n",
      "Train loss: 1.6703, Train acc: 0.2166\n",
      "Valid loss: 1.6666, Valid acc: 0.2413\n",
      "Epoch 3:\n",
      "Train loss: 1.6588, Train acc: 0.2288\n",
      "Valid loss: 1.6603, Valid acc: 0.2422\n",
      "Epoch 4:\n",
      "Train loss: 1.6539, Train acc: 0.2315\n",
      "Valid loss: 1.6571, Valid acc: 0.2413\n",
      "Epoch 5:\n",
      "Train loss: 1.6532, Train acc: 0.2299\n",
      "Valid loss: 1.6551, Valid acc: 0.2413\n",
      "Epoch 6:\n",
      "Train loss: 1.6512, Train acc: 0.2318\n",
      "Valid loss: 1.6540, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.6502, Train acc: 0.2338\n",
      "Valid loss: 1.6532, Valid acc: 0.2413\n",
      "Epoch 8:\n",
      "Train loss: 1.6507, Train acc: 0.2313\n",
      "Valid loss: 1.6529, Valid acc: 0.2413\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7088, Train acc: 0.2274\n",
      "Valid loss: 1.6524, Valid acc: 0.2486\n",
      "Epoch 2:\n",
      "Train loss: 1.6533, Train acc: 0.2290\n",
      "Valid loss: 1.6465, Valid acc: 0.2486\n",
      "Epoch 3:\n",
      "Train loss: 1.6467, Train acc: 0.2375\n",
      "Valid loss: 1.6499, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6468, Train acc: 0.2258\n",
      "Valid loss: 1.6486, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6479, Train acc: 0.2329\n",
      "Valid loss: 1.6490, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6464, Train acc: 0.2231\n",
      "Valid loss: 1.6475, Valid acc: 0.2413\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6633, Train acc: 0.2345\n",
      "Valid loss: 1.6514, Valid acc: 0.2505\n",
      "Epoch 2:\n",
      "Train loss: 1.6480, Train acc: 0.2336\n",
      "Valid loss: 1.6513, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6451, Train acc: 0.2350\n",
      "Valid loss: 1.6521, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6482, Train acc: 0.2251\n",
      "Valid loss: 1.6478, Valid acc: 0.2431\n",
      "Epoch 5:\n",
      "Train loss: 1.6465, Train acc: 0.2318\n",
      "Valid loss: 1.6465, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6447, Train acc: 0.2276\n",
      "Valid loss: 1.6462, Valid acc: 0.2413\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7186, Train acc: 0.2276\n",
      "Valid loss: 1.6819, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6755, Train acc: 0.2288\n",
      "Valid loss: 1.6584, Valid acc: 0.2055\n",
      "Epoch 3:\n",
      "Train loss: 1.6650, Train acc: 0.2281\n",
      "Valid loss: 1.6515, Valid acc: 0.2073\n",
      "Epoch 4:\n",
      "Train loss: 1.6584, Train acc: 0.2276\n",
      "Valid loss: 1.6470, Valid acc: 0.2073\n",
      "Epoch 5:\n",
      "Train loss: 1.6532, Train acc: 0.2290\n",
      "Valid loss: 1.6446, Valid acc: 0.2083\n",
      "Epoch 6:\n",
      "Train loss: 1.6526, Train acc: 0.2288\n",
      "Valid loss: 1.6436, Valid acc: 0.2083\n",
      "Epoch 7:\n",
      "Train loss: 1.6510, Train acc: 0.2256\n",
      "Valid loss: 1.6435, Valid acc: 0.2083\n",
      "Epoch 8:\n",
      "Train loss: 1.6503, Train acc: 0.2272\n",
      "Valid loss: 1.6435, Valid acc: 0.2083\n",
      "Epoch 9:\n",
      "Train loss: 1.6499, Train acc: 0.2290\n",
      "Valid loss: 1.6432, Valid acc: 0.2083\n",
      "Epoch 10:\n",
      "Train loss: 1.6502, Train acc: 0.2254\n",
      "Valid loss: 1.6425, Valid acc: 0.2083\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7094, Train acc: 0.2226\n",
      "Valid loss: 1.6565, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.6529, Train acc: 0.2283\n",
      "Valid loss: 1.6495, Valid acc: 0.2055\n",
      "Epoch 3:\n",
      "Train loss: 1.6502, Train acc: 0.2254\n",
      "Valid loss: 1.6472, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6478, Train acc: 0.2320\n",
      "Valid loss: 1.6493, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6478, Train acc: 0.2283\n",
      "Valid loss: 1.6464, Valid acc: 0.2450\n",
      "Epoch 6:\n",
      "Train loss: 1.6452, Train acc: 0.2331\n",
      "Valid loss: 1.6496, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6504, Train acc: 0.2238\n",
      "Valid loss: 1.6486, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6467, Train acc: 0.2240\n",
      "Valid loss: 1.6481, Valid acc: 0.2440\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6681, Train acc: 0.2290\n",
      "Valid loss: 1.6333, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.6484, Train acc: 0.2322\n",
      "Valid loss: 1.6430, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6467, Train acc: 0.2263\n",
      "Valid loss: 1.6463, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6492, Train acc: 0.2260\n",
      "Valid loss: 1.6396, Valid acc: 0.2477\n",
      "Epoch 5:\n",
      "Train loss: 1.6463, Train acc: 0.2343\n",
      "Valid loss: 1.6433, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6464, Train acc: 0.2276\n",
      "Valid loss: 1.6416, Valid acc: 0.2422\n",
      "Epoch 7:\n",
      "Train loss: 1.6456, Train acc: 0.2281\n",
      "Valid loss: 1.6486, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6463, Train acc: 0.2318\n",
      "Valid loss: 1.6450, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6445, Train acc: 0.2309\n",
      "Valid loss: 1.6447, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7430, Train acc: 0.2091\n",
      "Valid loss: 1.7253, Valid acc: 0.2358\n",
      "Epoch 2:\n",
      "Train loss: 1.7178, Train acc: 0.2171\n",
      "Valid loss: 1.7035, Valid acc: 0.2028\n",
      "Epoch 3:\n",
      "Train loss: 1.6933, Train acc: 0.2265\n",
      "Valid loss: 1.6834, Valid acc: 0.2037\n",
      "Epoch 4:\n",
      "Train loss: 1.6807, Train acc: 0.2297\n",
      "Valid loss: 1.6711, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6687, Train acc: 0.2290\n",
      "Valid loss: 1.6637, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6588, Train acc: 0.2283\n",
      "Valid loss: 1.6602, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7395, Train acc: 0.2116\n",
      "Valid loss: 1.6766, Valid acc: 0.2468\n",
      "Epoch 2:\n",
      "Train loss: 1.6580, Train acc: 0.2302\n",
      "Valid loss: 1.6539, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6559, Train acc: 0.2224\n",
      "Valid loss: 1.6522, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6491, Train acc: 0.2297\n",
      "Valid loss: 1.6535, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6513, Train acc: 0.2153\n",
      "Valid loss: 1.6519, Valid acc: 0.2495\n",
      "Epoch 6:\n",
      "Train loss: 1.6460, Train acc: 0.2201\n",
      "Valid loss: 1.6514, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6483, Train acc: 0.2299\n",
      "Valid loss: 1.6510, Valid acc: 0.2495\n",
      "Epoch 8:\n",
      "Train loss: 1.6474, Train acc: 0.2233\n",
      "Valid loss: 1.6505, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6447, Train acc: 0.2293\n",
      "Valid loss: 1.6509, Valid acc: 0.2486\n",
      "Epoch 10:\n",
      "Train loss: 1.6489, Train acc: 0.2329\n",
      "Valid loss: 1.6510, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6879, Train acc: 0.2235\n",
      "Valid loss: 1.6567, Valid acc: 0.2385\n",
      "Epoch 2:\n",
      "Train loss: 1.6516, Train acc: 0.2348\n",
      "Valid loss: 1.6520, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6491, Train acc: 0.2270\n",
      "Valid loss: 1.6507, Valid acc: 0.2413\n",
      "Epoch 4:\n",
      "Train loss: 1.6616, Train acc: 0.2187\n",
      "Valid loss: 1.6538, Valid acc: 0.2138\n",
      "Epoch 5:\n",
      "Train loss: 1.6480, Train acc: 0.2345\n",
      "Valid loss: 1.6500, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.6538, Train acc: 0.2251\n",
      "Valid loss: 1.6525, Valid acc: 0.2945\n",
      "Epoch 7:\n",
      "Train loss: 1.6472, Train acc: 0.2210\n",
      "Valid loss: 1.6538, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6510, Train acc: 0.2270\n",
      "Valid loss: 1.6549, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6480, Train acc: 0.2265\n",
      "Valid loss: 1.6568, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.6516, Train acc: 0.2293\n",
      "Valid loss: 1.6524, Valid acc: 0.2495\n",
      "Epoch 11:\n",
      "Train loss: 1.6522, Train acc: 0.2304\n",
      "Valid loss: 1.6540, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6753, Train acc: 0.2199\n",
      "Valid loss: 1.6502, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6506, Train acc: 0.2299\n",
      "Valid loss: 1.6478, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6496, Train acc: 0.2327\n",
      "Valid loss: 1.6422, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6485, Train acc: 0.2295\n",
      "Valid loss: 1.6493, Valid acc: 0.2587\n",
      "Epoch 5:\n",
      "Train loss: 1.6422, Train acc: 0.2444\n",
      "Valid loss: 1.6515, Valid acc: 0.2330\n",
      "Epoch 6:\n",
      "Train loss: 1.6446, Train acc: 0.2664\n",
      "Valid loss: 1.6504, Valid acc: 0.2505\n",
      "Epoch 7:\n",
      "Train loss: 1.6493, Train acc: 0.2350\n",
      "Valid loss: 1.6465, Valid acc: 0.2505\n",
      "Epoch 8:\n",
      "Train loss: 1.6509, Train acc: 0.2178\n",
      "Valid loss: 1.6466, Valid acc: 0.2404\n",
      "Epoch 9:\n",
      "Train loss: 1.6436, Train acc: 0.2359\n",
      "Valid loss: 1.6375, Valid acc: 0.2651\n",
      "Epoch 10:\n",
      "Train loss: 1.5564, Train acc: 0.3349\n",
      "Valid loss: 1.4996, Valid acc: 0.3706\n",
      "Epoch 11:\n",
      "Train loss: 1.3661, Train acc: 0.4374\n",
      "Valid loss: 1.3732, Valid acc: 0.4294\n",
      "Epoch 12:\n",
      "Train loss: 1.2460, Train acc: 0.4966\n",
      "Valid loss: 1.3681, Valid acc: 0.4578\n",
      "Epoch 13:\n",
      "Train loss: 1.1913, Train acc: 0.5101\n",
      "Valid loss: 1.4821, Valid acc: 0.4110\n",
      "Epoch 14:\n",
      "Train loss: 1.1443, Train acc: 0.5222\n",
      "Valid loss: 1.3174, Valid acc: 0.4550\n",
      "Epoch 15:\n",
      "Train loss: 1.0625, Train acc: 0.5504\n",
      "Valid loss: 1.2737, Valid acc: 0.4761\n",
      "Epoch 16:\n",
      "Train loss: 1.0123, Train acc: 0.5573\n",
      "Valid loss: 1.3228, Valid acc: 0.4761\n",
      "Epoch 17:\n",
      "Train loss: 0.9644, Train acc: 0.5777\n",
      "Valid loss: 1.2590, Valid acc: 0.4963\n",
      "Epoch 18:\n",
      "Train loss: 0.9481, Train acc: 0.5823\n",
      "Valid loss: 1.3505, Valid acc: 0.4697\n",
      "Epoch 19:\n",
      "Train loss: 0.9081, Train acc: 0.5894\n",
      "Valid loss: 1.2760, Valid acc: 0.4936\n",
      "Epoch 20:\n",
      "Train loss: 0.8613, Train acc: 0.6103\n",
      "Valid loss: 1.3045, Valid acc: 0.4917\n",
      "Epoch 21:\n",
      "Train loss: 0.8357, Train acc: 0.6160\n",
      "Valid loss: 1.2982, Valid acc: 0.5064\n",
      "Epoch 22:\n",
      "Train loss: 0.8114, Train acc: 0.6215\n",
      "Valid loss: 1.1861, Valid acc: 0.5193\n",
      "Epoch 23:\n",
      "Train loss: 0.7531, Train acc: 0.6616\n",
      "Valid loss: 1.1518, Valid acc: 0.5789\n",
      "Epoch 24:\n",
      "Train loss: 0.7157, Train acc: 0.7084\n",
      "Valid loss: 1.0995, Valid acc: 0.5908\n",
      "Epoch 25:\n",
      "Train loss: 0.7526, Train acc: 0.6946\n",
      "Valid loss: 1.1392, Valid acc: 0.5917\n",
      "Epoch 26:\n",
      "Train loss: 0.7491, Train acc: 0.7061\n",
      "Valid loss: 1.1714, Valid acc: 0.6092\n",
      "Epoch 27:\n",
      "Train loss: 1.4108, Train acc: 0.4195\n",
      "Valid loss: 2.0525, Valid acc: 0.3083\n",
      "Epoch 28:\n",
      "Train loss: 1.3784, Train acc: 0.4409\n",
      "Valid loss: 1.3551, Valid acc: 0.4321\n",
      "Epoch 29:\n",
      "Train loss: 1.2442, Train acc: 0.4853\n",
      "Valid loss: 1.2888, Valid acc: 0.4633\n",
      "Epoch 30:\n",
      "Train loss: 1.2133, Train acc: 0.4828\n",
      "Valid loss: 1.3551, Valid acc: 0.3780\n",
      "Epoch 31:\n",
      "Train loss: 1.3320, Train acc: 0.4088\n",
      "Valid loss: 1.3425, Valid acc: 0.4193\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6677, Train acc: 0.2286\n",
      "Valid loss: 1.6492, Valid acc: 0.2495\n",
      "Epoch 2:\n",
      "Train loss: 1.6497, Train acc: 0.2203\n",
      "Valid loss: 1.6562, Valid acc: 0.2321\n",
      "Epoch 3:\n",
      "Train loss: 1.6250, Train acc: 0.2600\n",
      "Valid loss: 1.4996, Valid acc: 0.3587\n",
      "Epoch 4:\n",
      "Train loss: 1.5052, Train acc: 0.3356\n",
      "Valid loss: 1.4762, Valid acc: 0.3596\n",
      "Epoch 5:\n",
      "Train loss: 1.4521, Train acc: 0.3391\n",
      "Valid loss: 1.4783, Valid acc: 0.3450\n",
      "Epoch 6:\n",
      "Train loss: 1.4576, Train acc: 0.3482\n",
      "Valid loss: 1.4692, Valid acc: 0.3514\n",
      "Epoch 7:\n",
      "Train loss: 1.4699, Train acc: 0.3684\n",
      "Valid loss: 1.4926, Valid acc: 0.3798\n",
      "Epoch 8:\n",
      "Train loss: 1.4992, Train acc: 0.3526\n",
      "Valid loss: 1.4606, Valid acc: 0.3899\n",
      "Epoch 9:\n",
      "Train loss: 1.4307, Train acc: 0.3886\n",
      "Valid loss: 1.4479, Valid acc: 0.3908\n",
      "Epoch 10:\n",
      "Train loss: 1.4303, Train acc: 0.3952\n",
      "Valid loss: 1.4950, Valid acc: 0.3890\n",
      "Epoch 11:\n",
      "Train loss: 1.5291, Train acc: 0.3299\n",
      "Valid loss: 1.5236, Valid acc: 0.2945\n",
      "Epoch 12:\n",
      "Train loss: 1.5255, Train acc: 0.3258\n",
      "Valid loss: 1.5227, Valid acc: 0.3174\n",
      "Epoch 13:\n",
      "Train loss: 1.4947, Train acc: 0.3647\n",
      "Valid loss: 1.5509, Valid acc: 0.3477\n",
      "Epoch 14:\n",
      "Train loss: 1.5279, Train acc: 0.3345\n",
      "Valid loss: 1.4825, Valid acc: 0.3486\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6616, Train acc: 0.2325\n",
      "Valid loss: 1.6538, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6478, Train acc: 0.2387\n",
      "Valid loss: 1.6621, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6466, Train acc: 0.2393\n",
      "Valid loss: 1.6518, Valid acc: 0.2642\n",
      "Epoch 4:\n",
      "Train loss: 1.6476, Train acc: 0.2570\n",
      "Valid loss: 1.6586, Valid acc: 0.2450\n",
      "Epoch 5:\n",
      "Train loss: 1.6576, Train acc: 0.2249\n",
      "Valid loss: 1.6518, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6461, Train acc: 0.2304\n",
      "Valid loss: 1.6408, Valid acc: 0.2716\n",
      "Epoch 7:\n",
      "Train loss: 1.6306, Train acc: 0.2724\n",
      "Valid loss: 1.6635, Valid acc: 0.2349\n",
      "Epoch 8:\n",
      "Train loss: 1.6687, Train acc: 0.2192\n",
      "Valid loss: 1.6625, Valid acc: 0.2037\n",
      "Epoch 9:\n",
      "Train loss: 1.6585, Train acc: 0.2171\n",
      "Valid loss: 1.6647, Valid acc: 0.2495\n",
      "Epoch 10:\n",
      "Train loss: 1.6558, Train acc: 0.2242\n",
      "Valid loss: 1.6493, Valid acc: 0.2486\n",
      "Epoch 11:\n",
      "Train loss: 1.6495, Train acc: 0.2368\n",
      "Valid loss: 1.6627, Valid acc: 0.2037\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6965, Train acc: 0.2084\n",
      "Valid loss: 1.6421, Valid acc: 0.2055\n",
      "Epoch 2:\n",
      "Train loss: 1.6526, Train acc: 0.2201\n",
      "Valid loss: 1.6466, Valid acc: 0.2064\n",
      "Epoch 3:\n",
      "Train loss: 1.6533, Train acc: 0.2215\n",
      "Valid loss: 1.6386, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6507, Train acc: 0.2302\n",
      "Valid loss: 1.6454, Valid acc: 0.2440\n",
      "Epoch 5:\n",
      "Train loss: 1.6485, Train acc: 0.2283\n",
      "Valid loss: 1.6494, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6465, Train acc: 0.2244\n",
      "Valid loss: 1.6450, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6461, Train acc: 0.2306\n",
      "Valid loss: 1.6419, Valid acc: 0.2431\n",
      "Epoch 8:\n",
      "Train loss: 1.6502, Train acc: 0.2251\n",
      "Valid loss: 1.6373, Valid acc: 0.2413\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6772, Train acc: 0.2240\n",
      "Valid loss: 1.6372, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6518, Train acc: 0.2260\n",
      "Valid loss: 1.6398, Valid acc: 0.2440\n",
      "Epoch 3:\n",
      "Train loss: 1.6520, Train acc: 0.2283\n",
      "Valid loss: 1.6413, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6471, Train acc: 0.2254\n",
      "Valid loss: 1.6535, Valid acc: 0.2587\n",
      "Epoch 5:\n",
      "Train loss: 1.6123, Train acc: 0.2776\n",
      "Valid loss: 1.5392, Valid acc: 0.3165\n",
      "Epoch 6:\n",
      "Train loss: 1.6195, Train acc: 0.2895\n",
      "Valid loss: 1.6609, Valid acc: 0.2450\n",
      "Epoch 7:\n",
      "Train loss: 1.6579, Train acc: 0.2199\n",
      "Valid loss: 1.6550, Valid acc: 0.2037\n",
      "Epoch 8:\n",
      "Train loss: 1.6508, Train acc: 0.2180\n",
      "Valid loss: 1.6509, Valid acc: 0.2459\n",
      "Epoch 9:\n",
      "Train loss: 1.6529, Train acc: 0.2171\n",
      "Valid loss: 1.6455, Valid acc: 0.2422\n",
      "Epoch 10:\n",
      "Train loss: 1.6539, Train acc: 0.2171\n",
      "Valid loss: 1.6496, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6762, Train acc: 0.2221\n",
      "Valid loss: 1.6321, Valid acc: 0.2422\n",
      "Epoch 2:\n",
      "Train loss: 1.6523, Train acc: 0.2249\n",
      "Valid loss: 1.6474, Valid acc: 0.2431\n",
      "Epoch 3:\n",
      "Train loss: 1.6545, Train acc: 0.2290\n",
      "Valid loss: 1.6387, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6502, Train acc: 0.2276\n",
      "Valid loss: 1.6369, Valid acc: 0.2440\n",
      "Epoch 5:\n",
      "Train loss: 1.6545, Train acc: 0.2295\n",
      "Valid loss: 1.6526, Valid acc: 0.2064\n",
      "Epoch 6:\n",
      "Train loss: 1.6411, Train acc: 0.2451\n",
      "Valid loss: 1.5702, Valid acc: 0.3092\n",
      "Epoch 7:\n",
      "Train loss: 1.5422, Train acc: 0.3485\n",
      "Valid loss: 1.5608, Valid acc: 0.3596\n",
      "Epoch 8:\n",
      "Train loss: 1.5122, Train acc: 0.3723\n",
      "Valid loss: 1.5737, Valid acc: 0.3073\n",
      "Epoch 9:\n",
      "Train loss: 1.5414, Train acc: 0.3051\n",
      "Valid loss: 1.5191, Valid acc: 0.3275\n",
      "Epoch 10:\n",
      "Train loss: 1.5194, Train acc: 0.3535\n",
      "Valid loss: 1.5589, Valid acc: 0.3376\n",
      "Epoch 11:\n",
      "Train loss: 1.5065, Train acc: 0.3524\n",
      "Valid loss: 1.5371, Valid acc: 0.3394\n",
      "Epoch 12:\n",
      "Train loss: 1.5003, Train acc: 0.3576\n",
      "Valid loss: 1.5237, Valid acc: 0.3734\n",
      "Epoch 13:\n",
      "Train loss: 1.4915, Train acc: 0.3622\n",
      "Valid loss: 1.5121, Valid acc: 0.3706\n",
      "Epoch 14:\n",
      "Train loss: 1.4946, Train acc: 0.3725\n",
      "Valid loss: 1.5259, Valid acc: 0.3266\n",
      "Epoch 15:\n",
      "Train loss: 1.5025, Train acc: 0.3560\n",
      "Valid loss: 1.5182, Valid acc: 0.3670\n",
      "Epoch 16:\n",
      "Train loss: 1.4907, Train acc: 0.3631\n",
      "Valid loss: 1.5226, Valid acc: 0.3651\n",
      "Epoch 17:\n",
      "Train loss: 1.4941, Train acc: 0.3732\n",
      "Valid loss: 1.5287, Valid acc: 0.3606\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7515, Train acc: 0.2047\n",
      "Valid loss: 1.6740, Valid acc: 0.2468\n",
      "Epoch 2:\n",
      "Train loss: 1.6541, Train acc: 0.2341\n",
      "Valid loss: 1.6558, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6581, Train acc: 0.2221\n",
      "Valid loss: 1.6572, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6481, Train acc: 0.2290\n",
      "Valid loss: 1.6523, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6483, Train acc: 0.2258\n",
      "Valid loss: 1.6528, Valid acc: 0.2486\n",
      "Epoch 6:\n",
      "Train loss: 1.6551, Train acc: 0.2329\n",
      "Valid loss: 1.6533, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6514, Train acc: 0.2299\n",
      "Valid loss: 1.6524, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6546, Train acc: 0.2221\n",
      "Valid loss: 1.6504, Valid acc: 0.2459\n",
      "Epoch 9:\n",
      "Train loss: 1.6519, Train acc: 0.2279\n",
      "Valid loss: 1.6571, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.6459, Train acc: 0.2226\n",
      "Valid loss: 1.6488, Valid acc: 0.2495\n",
      "Epoch 11:\n",
      "Train loss: 1.6504, Train acc: 0.2348\n",
      "Valid loss: 1.6476, Valid acc: 0.2450\n",
      "Epoch 12:\n",
      "Train loss: 1.6382, Train acc: 0.2439\n",
      "Valid loss: 1.6402, Valid acc: 0.2716\n",
      "Epoch 13:\n",
      "Train loss: 1.5632, Train acc: 0.3230\n",
      "Valid loss: 1.5503, Valid acc: 0.3220\n",
      "Epoch 14:\n",
      "Train loss: 1.4905, Train acc: 0.3723\n",
      "Valid loss: 1.5114, Valid acc: 0.3853\n",
      "Epoch 15:\n",
      "Train loss: 1.4659, Train acc: 0.3863\n",
      "Valid loss: 1.5192, Valid acc: 0.3303\n",
      "Epoch 16:\n",
      "Train loss: 1.4726, Train acc: 0.3624\n",
      "Valid loss: 1.4722, Valid acc: 0.3798\n",
      "Epoch 17:\n",
      "Train loss: 1.4342, Train acc: 0.3689\n",
      "Valid loss: 1.4730, Valid acc: 0.3385\n",
      "Epoch 18:\n",
      "Train loss: 1.4446, Train acc: 0.3718\n",
      "Valid loss: 1.4605, Valid acc: 0.3440\n",
      "Epoch 19:\n",
      "Train loss: 1.4941, Train acc: 0.3304\n",
      "Valid loss: 1.5461, Valid acc: 0.3165\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6907, Train acc: 0.2288\n",
      "Valid loss: 1.6556, Valid acc: 0.2486\n",
      "Epoch 2:\n",
      "Train loss: 1.6519, Train acc: 0.2357\n",
      "Valid loss: 1.6506, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6491, Train acc: 0.2260\n",
      "Valid loss: 1.6544, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6541, Train acc: 0.2263\n",
      "Valid loss: 1.6517, Valid acc: 0.2450\n",
      "Epoch 5:\n",
      "Train loss: 1.6535, Train acc: 0.2164\n",
      "Valid loss: 1.6513, Valid acc: 0.2495\n",
      "Epoch 6:\n",
      "Train loss: 1.6509, Train acc: 0.2215\n",
      "Valid loss: 1.6547, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6645, Train acc: 0.2238\n",
      "Valid loss: 1.6566, Valid acc: 0.2037\n",
      "Epoch 8:\n",
      "Train loss: 1.6560, Train acc: 0.2279\n",
      "Valid loss: 1.6571, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6488, Train acc: 0.2263\n",
      "Valid loss: 1.6580, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.6454, Train acc: 0.2299\n",
      "Valid loss: 1.6517, Valid acc: 0.2468\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6777, Train acc: 0.2189\n",
      "Valid loss: 1.6507, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6593, Train acc: 0.2233\n",
      "Valid loss: 1.6636, Valid acc: 0.2037\n",
      "Epoch 3:\n",
      "Train loss: 1.6575, Train acc: 0.2288\n",
      "Valid loss: 1.6537, Valid acc: 0.2450\n",
      "Epoch 4:\n",
      "Train loss: 1.6514, Train acc: 0.2414\n",
      "Valid loss: 1.6586, Valid acc: 0.2495\n",
      "Epoch 5:\n",
      "Train loss: 1.6536, Train acc: 0.2309\n",
      "Valid loss: 1.6435, Valid acc: 0.2495\n",
      "Epoch 6:\n",
      "Train loss: 1.6461, Train acc: 0.2389\n",
      "Valid loss: 1.6508, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6562, Train acc: 0.2519\n",
      "Valid loss: 1.6553, Valid acc: 0.2349\n",
      "Epoch 8:\n",
      "Train loss: 1.6569, Train acc: 0.2203\n",
      "Valid loss: 1.6511, Valid acc: 0.2468\n",
      "Epoch 9:\n",
      "Train loss: 1.6519, Train acc: 0.2242\n",
      "Valid loss: 1.6580, Valid acc: 0.2037\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6590, Train acc: 0.2176\n",
      "Valid loss: 1.6508, Valid acc: 0.2468\n",
      "Epoch 2:\n",
      "Train loss: 1.6467, Train acc: 0.2315\n",
      "Valid loss: 1.6475, Valid acc: 0.2495\n",
      "Epoch 3:\n",
      "Train loss: 1.6465, Train acc: 0.2265\n",
      "Valid loss: 1.6429, Valid acc: 0.2495\n",
      "Epoch 4:\n",
      "Train loss: 1.6436, Train acc: 0.2428\n",
      "Valid loss: 1.6524, Valid acc: 0.2284\n",
      "Epoch 5:\n",
      "Train loss: 1.5806, Train acc: 0.3125\n",
      "Valid loss: 1.5140, Valid acc: 0.3899\n",
      "Epoch 6:\n",
      "Train loss: 1.4481, Train acc: 0.3916\n",
      "Valid loss: 1.4068, Valid acc: 0.4064\n",
      "Epoch 7:\n",
      "Train loss: 1.3549, Train acc: 0.4349\n",
      "Valid loss: 1.2908, Valid acc: 0.4651\n",
      "Epoch 8:\n",
      "Train loss: 1.2332, Train acc: 0.4750\n",
      "Valid loss: 1.2726, Valid acc: 0.5028\n",
      "Epoch 9:\n",
      "Train loss: 1.1507, Train acc: 0.5241\n",
      "Valid loss: 1.2698, Valid acc: 0.5220\n",
      "Epoch 10:\n",
      "Train loss: 1.0469, Train acc: 0.5759\n",
      "Valid loss: 1.0320, Valid acc: 0.6165\n",
      "Epoch 11:\n",
      "Train loss: 0.9896, Train acc: 0.6080\n",
      "Valid loss: 1.0230, Valid acc: 0.6028\n",
      "Epoch 12:\n",
      "Train loss: 0.9046, Train acc: 0.6467\n",
      "Valid loss: 1.5426, Valid acc: 0.4624\n",
      "Epoch 13:\n",
      "Train loss: 0.8528, Train acc: 0.6731\n",
      "Valid loss: 1.0443, Valid acc: 0.6138\n",
      "Epoch 14:\n",
      "Train loss: 0.9595, Train acc: 0.6495\n",
      "Valid loss: 1.1393, Valid acc: 0.6018\n",
      "Epoch 15:\n",
      "Train loss: 0.8514, Train acc: 0.6758\n",
      "Valid loss: 0.9803, Valid acc: 0.6477\n",
      "Epoch 16:\n",
      "Train loss: 0.8239, Train acc: 0.6820\n",
      "Valid loss: 0.9699, Valid acc: 0.6404\n",
      "Epoch 17:\n",
      "Train loss: 0.7743, Train acc: 0.6999\n",
      "Valid loss: 0.9429, Valid acc: 0.6541\n",
      "Epoch 18:\n",
      "Train loss: 0.7909, Train acc: 0.6914\n",
      "Valid loss: 0.9978, Valid acc: 0.6422\n",
      "Epoch 19:\n",
      "Train loss: 0.7607, Train acc: 0.7052\n",
      "Valid loss: 0.9495, Valid acc: 0.6532\n",
      "Epoch 20:\n",
      "Train loss: 0.7501, Train acc: 0.7084\n",
      "Valid loss: 0.9527, Valid acc: 0.6505\n",
      "Epoch 21:\n",
      "Train loss: 0.7885, Train acc: 0.7029\n",
      "Valid loss: 0.9503, Valid acc: 0.6615\n",
      "Epoch 22:\n",
      "Train loss: 0.7829, Train acc: 0.6898\n",
      "Valid loss: 0.9496, Valid acc: 0.6541\n",
      "Epoch 23:\n",
      "Train loss: 0.8331, Train acc: 0.6765\n",
      "Valid loss: 1.0210, Valid acc: 0.6174\n",
      "Epoch 24:\n",
      "Train loss: 0.7316, Train acc: 0.6965\n",
      "Valid loss: 0.9860, Valid acc: 0.6505\n",
      "Epoch 25:\n",
      "Train loss: 0.7034, Train acc: 0.7169\n",
      "Valid loss: 0.9802, Valid acc: 0.6431\n",
      "Epoch 26:\n",
      "Train loss: 0.7496, Train acc: 0.7111\n",
      "Valid loss: 0.9656, Valid acc: 0.6615\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6593, Train acc: 0.2196\n",
      "Valid loss: 1.6480, Valid acc: 0.2101\n",
      "Epoch 2:\n",
      "Train loss: 1.6477, Train acc: 0.2212\n",
      "Valid loss: 1.6581, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6442, Train acc: 0.2400\n",
      "Valid loss: 1.6471, Valid acc: 0.2284\n",
      "Epoch 4:\n",
      "Train loss: 1.6411, Train acc: 0.2451\n",
      "Valid loss: 1.6858, Valid acc: 0.2202\n",
      "Epoch 5:\n",
      "Train loss: 1.6530, Train acc: 0.2293\n",
      "Valid loss: 1.6800, Valid acc: 0.1560\n",
      "Epoch 6:\n",
      "Train loss: 1.5747, Train acc: 0.3074\n",
      "Valid loss: 1.5716, Valid acc: 0.3312\n",
      "Epoch 7:\n",
      "Train loss: 1.5137, Train acc: 0.3583\n",
      "Valid loss: 1.5107, Valid acc: 0.3697\n",
      "Epoch 8:\n",
      "Train loss: 1.4946, Train acc: 0.3595\n",
      "Valid loss: 1.5142, Valid acc: 0.3541\n",
      "Epoch 9:\n",
      "Train loss: 1.4882, Train acc: 0.3553\n",
      "Valid loss: 1.4914, Valid acc: 0.3881\n",
      "Epoch 10:\n",
      "Train loss: 1.5001, Train acc: 0.3652\n",
      "Valid loss: 1.5053, Valid acc: 0.3835\n",
      "Epoch 11:\n",
      "Train loss: 1.5284, Train acc: 0.3569\n",
      "Valid loss: 1.4957, Valid acc: 0.3899\n",
      "Epoch 12:\n",
      "Train loss: 1.4849, Train acc: 0.3796\n",
      "Valid loss: 1.5091, Valid acc: 0.3394\n",
      "Epoch 13:\n",
      "Train loss: 1.4761, Train acc: 0.3748\n",
      "Valid loss: 1.4950, Valid acc: 0.3771\n",
      "Epoch 14:\n",
      "Train loss: 1.4717, Train acc: 0.3783\n",
      "Valid loss: 1.4742, Valid acc: 0.3495\n",
      "Epoch 15:\n",
      "Train loss: 1.4707, Train acc: 0.3565\n",
      "Valid loss: 1.6506, Valid acc: 0.2459\n",
      "Epoch 16:\n",
      "Train loss: 1.5817, Train acc: 0.2808\n",
      "Valid loss: 1.4956, Valid acc: 0.3651\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6651, Train acc: 0.2331\n",
      "Valid loss: 1.6578, Valid acc: 0.2312\n",
      "Epoch 2:\n",
      "Train loss: 1.6498, Train acc: 0.2311\n",
      "Valid loss: 1.6444, Valid acc: 0.2257\n",
      "Epoch 3:\n",
      "Train loss: 1.6482, Train acc: 0.2446\n",
      "Valid loss: 1.6439, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6368, Train acc: 0.2568\n",
      "Valid loss: 1.5530, Valid acc: 0.3761\n",
      "Epoch 5:\n",
      "Train loss: 1.5312, Train acc: 0.3471\n",
      "Valid loss: 1.4690, Valid acc: 0.3890\n",
      "Epoch 6:\n",
      "Train loss: 1.4858, Train acc: 0.3718\n",
      "Valid loss: 1.5341, Valid acc: 0.3165\n",
      "Epoch 7:\n",
      "Train loss: 1.4775, Train acc: 0.3838\n",
      "Valid loss: 1.6066, Valid acc: 0.3073\n",
      "Epoch 8:\n",
      "Train loss: 1.5220, Train acc: 0.3462\n",
      "Valid loss: 1.6507, Valid acc: 0.2450\n",
      "Epoch 9:\n",
      "Train loss: 1.5670, Train acc: 0.3074\n",
      "Valid loss: 1.5069, Valid acc: 0.3229\n",
      "Epoch 10:\n",
      "Train loss: 1.5355, Train acc: 0.3338\n",
      "Valid loss: 1.6516, Valid acc: 0.2459\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6608, Train acc: 0.2203\n",
      "Valid loss: 1.6358, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.6499, Train acc: 0.2331\n",
      "Valid loss: 1.6547, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6522, Train acc: 0.2283\n",
      "Valid loss: 1.6429, Valid acc: 0.2413\n",
      "Epoch 4:\n",
      "Train loss: 1.6497, Train acc: 0.2354\n",
      "Valid loss: 1.6509, Valid acc: 0.2670\n",
      "Epoch 5:\n",
      "Train loss: 1.6431, Train acc: 0.2522\n",
      "Valid loss: 1.6116, Valid acc: 0.3248\n",
      "Epoch 6:\n",
      "Train loss: 1.4887, Train acc: 0.3666\n",
      "Valid loss: 1.5076, Valid acc: 0.3817\n",
      "Epoch 7:\n",
      "Train loss: 1.5036, Train acc: 0.3680\n",
      "Valid loss: 1.4761, Valid acc: 0.3917\n",
      "Epoch 8:\n",
      "Train loss: 1.4366, Train acc: 0.3874\n",
      "Valid loss: 1.4364, Valid acc: 0.3872\n",
      "Epoch 9:\n",
      "Train loss: 1.4342, Train acc: 0.3673\n",
      "Valid loss: 1.4410, Valid acc: 0.3817\n",
      "Epoch 10:\n",
      "Train loss: 1.4266, Train acc: 0.3592\n",
      "Valid loss: 1.4389, Valid acc: 0.3972\n",
      "Epoch 11:\n",
      "Train loss: 1.3931, Train acc: 0.3996\n",
      "Valid loss: 1.4559, Valid acc: 0.4018\n",
      "Epoch 12:\n",
      "Train loss: 1.3750, Train acc: 0.4147\n",
      "Valid loss: 1.3946, Valid acc: 0.3606\n",
      "Epoch 13:\n",
      "Train loss: 1.2492, Train acc: 0.4741\n",
      "Valid loss: 1.4543, Valid acc: 0.3624\n",
      "Epoch 14:\n",
      "Train loss: 1.1664, Train acc: 0.5105\n",
      "Valid loss: 1.2785, Valid acc: 0.4752\n",
      "Epoch 15:\n",
      "Train loss: 1.0944, Train acc: 0.5465\n",
      "Valid loss: 1.5982, Valid acc: 0.4028\n",
      "Epoch 16:\n",
      "Train loss: 1.0511, Train acc: 0.5644\n",
      "Valid loss: 1.4671, Valid acc: 0.4422\n",
      "Epoch 17:\n",
      "Train loss: 0.9879, Train acc: 0.6004\n",
      "Valid loss: 1.1894, Valid acc: 0.5248\n",
      "Epoch 18:\n",
      "Train loss: 0.9276, Train acc: 0.6403\n",
      "Valid loss: 1.1433, Valid acc: 0.5385\n",
      "Epoch 19:\n",
      "Train loss: 0.8695, Train acc: 0.6625\n",
      "Valid loss: 1.0108, Valid acc: 0.6055\n",
      "Epoch 20:\n",
      "Train loss: 0.7992, Train acc: 0.6935\n",
      "Valid loss: 1.0066, Valid acc: 0.6009\n",
      "Epoch 21:\n",
      "Train loss: 0.7761, Train acc: 0.7024\n",
      "Valid loss: 0.9816, Valid acc: 0.6202\n",
      "Epoch 22:\n",
      "Train loss: 0.7617, Train acc: 0.7141\n",
      "Valid loss: 1.2261, Valid acc: 0.5541\n",
      "Epoch 23:\n",
      "Train loss: 0.7538, Train acc: 0.7105\n",
      "Valid loss: 1.1087, Valid acc: 0.5927\n",
      "Epoch 24:\n",
      "Train loss: 0.7096, Train acc: 0.7224\n",
      "Valid loss: 1.0898, Valid acc: 0.5982\n",
      "Epoch 25:\n",
      "Train loss: 0.7384, Train acc: 0.7199\n",
      "Valid loss: 0.9459, Valid acc: 0.6330\n",
      "Epoch 26:\n",
      "Train loss: 0.6921, Train acc: 0.7265\n",
      "Valid loss: 0.9535, Valid acc: 0.6431\n",
      "Epoch 27:\n",
      "Train loss: 0.6514, Train acc: 0.7439\n",
      "Valid loss: 0.9283, Valid acc: 0.6404\n",
      "Epoch 28:\n",
      "Train loss: 0.5964, Train acc: 0.7623\n",
      "Valid loss: 1.2072, Valid acc: 0.5706\n",
      "Epoch 29:\n",
      "Train loss: 0.6472, Train acc: 0.7451\n",
      "Valid loss: 0.9859, Valid acc: 0.6257\n",
      "Epoch 30:\n",
      "Train loss: 0.6572, Train acc: 0.7407\n",
      "Valid loss: 0.9856, Valid acc: 0.6404\n",
      "Epoch 31:\n",
      "Train loss: 0.6087, Train acc: 0.7613\n",
      "Valid loss: 1.0151, Valid acc: 0.6349\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6608, Train acc: 0.2265\n",
      "Valid loss: 1.6477, Valid acc: 0.2413\n",
      "Epoch 2:\n",
      "Train loss: 1.6523, Train acc: 0.2281\n",
      "Valid loss: 1.6302, Valid acc: 0.2440\n",
      "Epoch 3:\n",
      "Train loss: 1.6501, Train acc: 0.2297\n",
      "Valid loss: 1.6597, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6535, Train acc: 0.2293\n",
      "Valid loss: 1.6622, Valid acc: 0.2550\n",
      "Epoch 5:\n",
      "Train loss: 1.6479, Train acc: 0.2364\n",
      "Valid loss: 1.6486, Valid acc: 0.2706\n",
      "Epoch 6:\n",
      "Train loss: 1.5554, Train acc: 0.3267\n",
      "Valid loss: 1.4965, Valid acc: 0.3477\n",
      "Epoch 7:\n",
      "Train loss: 1.4899, Train acc: 0.3631\n",
      "Valid loss: 1.4782, Valid acc: 0.3908\n",
      "Epoch 8:\n",
      "Train loss: 1.5369, Train acc: 0.3418\n",
      "Valid loss: 1.6859, Valid acc: 0.1505\n",
      "Epoch 9:\n",
      "Train loss: 1.6551, Train acc: 0.2256\n",
      "Valid loss: 1.6663, Valid acc: 0.2459\n",
      "Epoch 10:\n",
      "Train loss: 1.6520, Train acc: 0.2208\n",
      "Valid loss: 1.6755, Valid acc: 0.2046\n",
      "Epoch 11:\n",
      "Train loss: 1.6535, Train acc: 0.2309\n",
      "Valid loss: 1.6452, Valid acc: 0.2468\n",
      "Epoch 12:\n",
      "Train loss: 1.6531, Train acc: 0.2283\n",
      "Valid loss: 1.6693, Valid acc: 0.2055\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6758, Train acc: 0.2208\n",
      "Valid loss: 1.6578, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6492, Train acc: 0.2286\n",
      "Valid loss: 1.6736, Valid acc: 0.2404\n",
      "Epoch 3:\n",
      "Train loss: 1.6514, Train acc: 0.2338\n",
      "Valid loss: 1.6633, Valid acc: 0.2422\n",
      "Epoch 4:\n",
      "Train loss: 1.6538, Train acc: 0.2247\n",
      "Valid loss: 1.6642, Valid acc: 0.2394\n",
      "Epoch 5:\n",
      "Train loss: 1.6516, Train acc: 0.2329\n",
      "Valid loss: 1.6883, Valid acc: 0.2110\n",
      "Epoch 6:\n",
      "Train loss: 1.6474, Train acc: 0.2256\n",
      "Valid loss: 1.6793, Valid acc: 0.2073\n",
      "Epoch 7:\n",
      "Train loss: 1.6482, Train acc: 0.2254\n",
      "Valid loss: 1.6440, Valid acc: 0.2459\n",
      "Epoch 8:\n",
      "Train loss: 1.6449, Train acc: 0.2235\n",
      "Valid loss: 1.6594, Valid acc: 0.2459\n",
      "Epoch 9:\n",
      "Train loss: 1.6452, Train acc: 0.2382\n",
      "Valid loss: 1.6366, Valid acc: 0.2422\n",
      "Epoch 10:\n",
      "Train loss: 1.6450, Train acc: 0.2375\n",
      "Valid loss: 1.6775, Valid acc: 0.2413\n",
      "Epoch 11:\n",
      "Train loss: 1.5940, Train acc: 0.3205\n",
      "Valid loss: 1.5494, Valid acc: 0.3670\n",
      "Epoch 12:\n",
      "Train loss: 1.5781, Train acc: 0.3017\n",
      "Valid loss: 1.7258, Valid acc: 0.2413\n",
      "Epoch 13:\n",
      "Train loss: 1.6464, Train acc: 0.2439\n",
      "Valid loss: 1.6356, Valid acc: 0.2422\n",
      "Epoch 14:\n",
      "Train loss: 1.6473, Train acc: 0.2251\n",
      "Valid loss: 1.6670, Valid acc: 0.1505\n",
      "Epoch 15:\n",
      "Train loss: 1.6489, Train acc: 0.2279\n",
      "Valid loss: 1.6775, Valid acc: 0.1578\n",
      "Epoch 16:\n",
      "Train loss: 1.6474, Train acc: 0.2178\n",
      "Valid loss: 1.7127, Valid acc: 0.2055\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6692, Train acc: 0.2121\n",
      "Valid loss: 1.6530, Valid acc: 0.2385\n",
      "Epoch 2:\n",
      "Train loss: 1.6605, Train acc: 0.2240\n",
      "Valid loss: 1.6540, Valid acc: 0.2376\n",
      "Epoch 3:\n",
      "Train loss: 1.6588, Train acc: 0.2226\n",
      "Valid loss: 1.6547, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6538, Train acc: 0.2247\n",
      "Valid loss: 1.6572, Valid acc: 0.2394\n",
      "Epoch 5:\n",
      "Train loss: 1.6545, Train acc: 0.2295\n",
      "Valid loss: 1.6503, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.6452, Train acc: 0.2370\n",
      "Valid loss: 1.6555, Valid acc: 0.2468\n",
      "Epoch 7:\n",
      "Train loss: 1.6512, Train acc: 0.2279\n",
      "Valid loss: 1.6596, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6589, Train acc: 0.2309\n",
      "Valid loss: 1.6507, Valid acc: 0.2771\n",
      "Epoch 9:\n",
      "Train loss: 1.6403, Train acc: 0.2579\n",
      "Valid loss: 1.5541, Valid acc: 0.3596\n",
      "Epoch 10:\n",
      "Train loss: 1.4748, Train acc: 0.3778\n",
      "Valid loss: 1.5210, Valid acc: 0.3358\n",
      "Epoch 11:\n",
      "Train loss: 1.4051, Train acc: 0.3893\n",
      "Valid loss: 1.4250, Valid acc: 0.4037\n",
      "Epoch 12:\n",
      "Train loss: 1.3974, Train acc: 0.3936\n",
      "Valid loss: 1.4159, Valid acc: 0.4009\n",
      "Epoch 13:\n",
      "Train loss: 1.4316, Train acc: 0.3842\n",
      "Valid loss: 1.4687, Valid acc: 0.3716\n",
      "Epoch 14:\n",
      "Train loss: 1.4120, Train acc: 0.3776\n",
      "Valid loss: 1.4244, Valid acc: 0.4009\n",
      "Epoch 15:\n",
      "Train loss: 1.3699, Train acc: 0.4060\n",
      "Valid loss: 1.4157, Valid acc: 0.4009\n",
      "Epoch 16:\n",
      "Train loss: 1.3544, Train acc: 0.4074\n",
      "Valid loss: 1.4080, Valid acc: 0.4028\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6774, Train acc: 0.2244\n",
      "Valid loss: 1.6604, Valid acc: 0.2394\n",
      "Epoch 2:\n",
      "Train loss: 1.6519, Train acc: 0.2276\n",
      "Valid loss: 1.6552, Valid acc: 0.2358\n",
      "Epoch 3:\n",
      "Train loss: 1.6606, Train acc: 0.2205\n",
      "Valid loss: 1.6607, Valid acc: 0.2431\n",
      "Epoch 4:\n",
      "Train loss: 1.6531, Train acc: 0.2199\n",
      "Valid loss: 1.6633, Valid acc: 0.2413\n",
      "Epoch 5:\n",
      "Train loss: 1.6430, Train acc: 0.2345\n",
      "Valid loss: 1.6778, Valid acc: 0.2055\n",
      "Epoch 6:\n",
      "Train loss: 1.6497, Train acc: 0.2366\n",
      "Valid loss: 1.6505, Valid acc: 0.2459\n",
      "Epoch 7:\n",
      "Train loss: 1.6446, Train acc: 0.2283\n",
      "Valid loss: 1.6602, Valid acc: 0.2385\n",
      "Epoch 8:\n",
      "Train loss: 1.6533, Train acc: 0.2336\n",
      "Valid loss: 1.6553, Valid acc: 0.2367\n",
      "Epoch 9:\n",
      "Train loss: 1.6093, Train acc: 0.2923\n",
      "Valid loss: 1.7229, Valid acc: 0.2220\n",
      "Epoch 10:\n",
      "Train loss: 1.5660, Train acc: 0.3414\n",
      "Valid loss: 1.5706, Valid acc: 0.3284\n",
      "Epoch 11:\n",
      "Train loss: 1.5608, Train acc: 0.3310\n",
      "Valid loss: 1.5617, Valid acc: 0.3505\n",
      "Epoch 12:\n",
      "Train loss: 1.5487, Train acc: 0.3336\n",
      "Valid loss: 1.5758, Valid acc: 0.3349\n",
      "Epoch 13:\n",
      "Train loss: 1.5484, Train acc: 0.3331\n",
      "Valid loss: 1.5473, Valid acc: 0.3468\n",
      "Epoch 14:\n",
      "Train loss: 1.5230, Train acc: 0.3592\n",
      "Valid loss: 1.5247, Valid acc: 0.3532\n",
      "Epoch 15:\n",
      "Train loss: 1.5261, Train acc: 0.3735\n",
      "Valid loss: 1.5712, Valid acc: 0.3312\n",
      "Epoch 16:\n",
      "Train loss: 1.5197, Train acc: 0.3597\n",
      "Valid loss: 1.5410, Valid acc: 0.2761\n",
      "Epoch 17:\n",
      "Train loss: 1.4910, Train acc: 0.3613\n",
      "Valid loss: 1.5380, Valid acc: 0.3339\n",
      "Epoch 18:\n",
      "Train loss: 1.5358, Train acc: 0.3132\n",
      "Valid loss: 1.5615, Valid acc: 0.3128\n",
      "Epoch 19:\n",
      "Train loss: 1.5274, Train acc: 0.3058\n",
      "Valid loss: 1.5471, Valid acc: 0.3165\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.0005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7186, Train acc: 0.2164\n",
      "Valid loss: 1.6865, Valid acc: 0.1541\n",
      "Epoch 2:\n",
      "Train loss: 1.6577, Train acc: 0.2146\n",
      "Valid loss: 1.6780, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6560, Train acc: 0.2290\n",
      "Valid loss: 1.6783, Valid acc: 0.2028\n",
      "Epoch 4:\n",
      "Train loss: 1.6476, Train acc: 0.2226\n",
      "Valid loss: 1.6933, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6517, Train acc: 0.2178\n",
      "Valid loss: 1.6509, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.6613, Train acc: 0.2254\n",
      "Valid loss: 1.6726, Valid acc: 0.2367\n",
      "Epoch 7:\n",
      "Train loss: 1.6523, Train acc: 0.2235\n",
      "Valid loss: 1.6675, Valid acc: 0.2009\n",
      "Epoch 8:\n",
      "Train loss: 1.6531, Train acc: 0.2272\n",
      "Valid loss: 1.6668, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6489, Train acc: 0.2276\n",
      "Valid loss: 1.6516, Valid acc: 0.2367\n",
      "Epoch 10:\n",
      "Train loss: 1.6414, Train acc: 0.2306\n",
      "Valid loss: 1.6892, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7810, Train acc: 0.2102\n",
      "Valid loss: 1.7771, Valid acc: 0.2303\n",
      "Epoch 2:\n",
      "Train loss: 1.7645, Train acc: 0.2102\n",
      "Valid loss: 1.7599, Valid acc: 0.2294\n",
      "Epoch 3:\n",
      "Train loss: 1.7499, Train acc: 0.2137\n",
      "Valid loss: 1.7450, Valid acc: 0.2330\n",
      "Epoch 4:\n",
      "Train loss: 1.7377, Train acc: 0.2144\n",
      "Valid loss: 1.7318, Valid acc: 0.2339\n",
      "Epoch 5:\n",
      "Train loss: 1.7273, Train acc: 0.2160\n",
      "Valid loss: 1.7200, Valid acc: 0.2394\n",
      "Epoch 6:\n",
      "Train loss: 1.7164, Train acc: 0.2210\n",
      "Valid loss: 1.7095, Valid acc: 0.2532\n",
      "Epoch 7:\n",
      "Train loss: 1.7073, Train acc: 0.2370\n",
      "Valid loss: 1.7002, Valid acc: 0.2495\n",
      "Epoch 8:\n",
      "Train loss: 1.6992, Train acc: 0.2331\n",
      "Valid loss: 1.6924, Valid acc: 0.2541\n",
      "Epoch 9:\n",
      "Train loss: 1.6931, Train acc: 0.2302\n",
      "Valid loss: 1.6856, Valid acc: 0.2523\n",
      "Epoch 10:\n",
      "Train loss: 1.6873, Train acc: 0.2315\n",
      "Valid loss: 1.6799, Valid acc: 0.2523\n",
      "Epoch 11:\n",
      "Train loss: 1.6823, Train acc: 0.2302\n",
      "Valid loss: 1.6750, Valid acc: 0.2523\n",
      "Epoch 12:\n",
      "Train loss: 1.6775, Train acc: 0.2290\n",
      "Valid loss: 1.6710, Valid acc: 0.2523\n",
      "Epoch 13:\n",
      "Train loss: 1.6726, Train acc: 0.2325\n",
      "Valid loss: 1.6675, Valid acc: 0.2514\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7745, Train acc: 0.1694\n",
      "Valid loss: 1.7664, Valid acc: 0.1440\n",
      "Epoch 2:\n",
      "Train loss: 1.7635, Train acc: 0.1894\n",
      "Valid loss: 1.7555, Valid acc: 0.2358\n",
      "Epoch 3:\n",
      "Train loss: 1.7545, Train acc: 0.2164\n",
      "Valid loss: 1.7457, Valid acc: 0.2376\n",
      "Epoch 4:\n",
      "Train loss: 1.7449, Train acc: 0.2189\n",
      "Valid loss: 1.7367, Valid acc: 0.2394\n",
      "Epoch 5:\n",
      "Train loss: 1.7370, Train acc: 0.2196\n",
      "Valid loss: 1.7285, Valid acc: 0.2394\n",
      "Epoch 6:\n",
      "Train loss: 1.7289, Train acc: 0.2212\n",
      "Valid loss: 1.7208, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.7220, Train acc: 0.2235\n",
      "Valid loss: 1.7136, Valid acc: 0.2431\n",
      "Epoch 8:\n",
      "Train loss: 1.7147, Train acc: 0.2247\n",
      "Valid loss: 1.7069, Valid acc: 0.2431\n",
      "Epoch 9:\n",
      "Train loss: 1.7087, Train acc: 0.2231\n",
      "Valid loss: 1.7007, Valid acc: 0.2450\n",
      "Epoch 10:\n",
      "Train loss: 1.7029, Train acc: 0.2219\n",
      "Valid loss: 1.6950, Valid acc: 0.2450\n",
      "Epoch 11:\n",
      "Train loss: 1.6979, Train acc: 0.2272\n",
      "Valid loss: 1.6897, Valid acc: 0.2450\n",
      "Epoch 12:\n",
      "Train loss: 1.6920, Train acc: 0.2233\n",
      "Valid loss: 1.6846, Valid acc: 0.2459\n",
      "Epoch 13:\n",
      "Train loss: 1.6874, Train acc: 0.2251\n",
      "Valid loss: 1.6801, Valid acc: 0.2450\n",
      "Epoch 14:\n",
      "Train loss: 1.6827, Train acc: 0.2242\n",
      "Valid loss: 1.6759, Valid acc: 0.2450\n",
      "Epoch 15:\n",
      "Train loss: 1.6782, Train acc: 0.2274\n",
      "Valid loss: 1.6720, Valid acc: 0.2440\n",
      "Epoch 16:\n",
      "Train loss: 1.6744, Train acc: 0.2254\n",
      "Valid loss: 1.6685, Valid acc: 0.2440\n",
      "Epoch 17:\n",
      "Train loss: 1.6708, Train acc: 0.2302\n",
      "Valid loss: 1.6656, Valid acc: 0.2440\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7824, Train acc: 0.2162\n",
      "Valid loss: 1.7781, Valid acc: 0.1936\n",
      "Epoch 2:\n",
      "Train loss: 1.7704, Train acc: 0.2180\n",
      "Valid loss: 1.7655, Valid acc: 0.1963\n",
      "Epoch 3:\n",
      "Train loss: 1.7582, Train acc: 0.2217\n",
      "Valid loss: 1.7541, Valid acc: 0.2009\n",
      "Epoch 4:\n",
      "Train loss: 1.7471, Train acc: 0.2272\n",
      "Valid loss: 1.7436, Valid acc: 0.2055\n",
      "Epoch 5:\n",
      "Train loss: 1.7372, Train acc: 0.2288\n",
      "Valid loss: 1.7338, Valid acc: 0.2055\n",
      "Epoch 6:\n",
      "Train loss: 1.7283, Train acc: 0.2297\n",
      "Valid loss: 1.7248, Valid acc: 0.2055\n",
      "Epoch 7:\n",
      "Train loss: 1.7206, Train acc: 0.2279\n",
      "Valid loss: 1.7163, Valid acc: 0.2055\n",
      "Epoch 8:\n",
      "Train loss: 1.7120, Train acc: 0.2288\n",
      "Valid loss: 1.7082, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.7041, Train acc: 0.2288\n",
      "Valid loss: 1.7007, Valid acc: 0.2055\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.8170, Train acc: 0.0186\n",
      "Valid loss: 1.8271, Valid acc: 0.0394\n",
      "Epoch 2:\n",
      "Train loss: 1.8074, Train acc: 0.1479\n",
      "Valid loss: 1.8173, Valid acc: 0.1569\n",
      "Epoch 3:\n",
      "Train loss: 1.7991, Train acc: 0.1570\n",
      "Valid loss: 1.8084, Valid acc: 0.1578\n",
      "Epoch 4:\n",
      "Train loss: 1.7913, Train acc: 0.1586\n",
      "Valid loss: 1.8002, Valid acc: 0.1661\n",
      "Epoch 5:\n",
      "Train loss: 1.7839, Train acc: 0.1616\n",
      "Valid loss: 1.7929, Valid acc: 0.1862\n",
      "Epoch 6:\n",
      "Train loss: 1.7782, Train acc: 0.2166\n",
      "Valid loss: 1.7858, Valid acc: 0.1991\n",
      "Epoch 7:\n",
      "Train loss: 1.7703, Train acc: 0.2224\n",
      "Valid loss: 1.7792, Valid acc: 0.2000\n",
      "Epoch 8:\n",
      "Train loss: 1.7651, Train acc: 0.2240\n",
      "Valid loss: 1.7729, Valid acc: 0.2009\n",
      "Epoch 9:\n",
      "Train loss: 1.7606, Train acc: 0.2258\n",
      "Valid loss: 1.7670, Valid acc: 0.2018\n",
      "Epoch 10:\n",
      "Train loss: 1.7538, Train acc: 0.2249\n",
      "Valid loss: 1.7614, Valid acc: 0.2028\n",
      "Epoch 11:\n",
      "Train loss: 1.7481, Train acc: 0.2260\n",
      "Valid loss: 1.7560, Valid acc: 0.2028\n",
      "Epoch 12:\n",
      "Train loss: 1.7448, Train acc: 0.2258\n",
      "Valid loss: 1.7507, Valid acc: 0.2037\n",
      "Epoch 13:\n",
      "Train loss: 1.7404, Train acc: 0.2256\n",
      "Valid loss: 1.7457, Valid acc: 0.2046\n",
      "Epoch 14:\n",
      "Train loss: 1.7351, Train acc: 0.2265\n",
      "Valid loss: 1.7409, Valid acc: 0.2055\n",
      "Epoch 15:\n",
      "Train loss: 1.7316, Train acc: 0.2283\n",
      "Valid loss: 1.7363, Valid acc: 0.2064\n",
      "Epoch 16:\n",
      "Train loss: 1.7265, Train acc: 0.2295\n",
      "Valid loss: 1.7319, Valid acc: 0.2064\n",
      "Epoch 17:\n",
      "Train loss: 1.7237, Train acc: 0.2283\n",
      "Valid loss: 1.7277, Valid acc: 0.2064\n",
      "Epoch 18:\n",
      "Train loss: 1.7195, Train acc: 0.2286\n",
      "Valid loss: 1.7236, Valid acc: 0.2064\n",
      "Epoch 19:\n",
      "Train loss: 1.7163, Train acc: 0.2270\n",
      "Valid loss: 1.7196, Valid acc: 0.2064\n",
      "Epoch 20:\n",
      "Train loss: 1.7112, Train acc: 0.2276\n",
      "Valid loss: 1.7158, Valid acc: 0.2073\n",
      "Epoch 21:\n",
      "Train loss: 1.7087, Train acc: 0.2283\n",
      "Valid loss: 1.7121, Valid acc: 0.2083\n",
      "Epoch 22:\n",
      "Train loss: 1.7050, Train acc: 0.2302\n",
      "Valid loss: 1.7085, Valid acc: 0.2101\n",
      "Epoch 23:\n",
      "Train loss: 1.7023, Train acc: 0.2265\n",
      "Valid loss: 1.7052, Valid acc: 0.2119\n",
      "Epoch 24:\n",
      "Train loss: 1.6985, Train acc: 0.2182\n",
      "Valid loss: 1.7019, Valid acc: 0.2440\n",
      "Epoch 25:\n",
      "Train loss: 1.6956, Train acc: 0.2295\n",
      "Valid loss: 1.6988, Valid acc: 0.2404\n",
      "Epoch 26:\n",
      "Train loss: 1.6942, Train acc: 0.2313\n",
      "Valid loss: 1.6958, Valid acc: 0.2404\n",
      "Epoch 27:\n",
      "Train loss: 1.6900, Train acc: 0.2329\n",
      "Valid loss: 1.6930, Valid acc: 0.2440\n",
      "Epoch 28:\n",
      "Train loss: 1.6878, Train acc: 0.2318\n",
      "Valid loss: 1.6903, Valid acc: 0.2450\n",
      "Epoch 29:\n",
      "Train loss: 1.6874, Train acc: 0.2327\n",
      "Valid loss: 1.6878, Valid acc: 0.2450\n",
      "Epoch 30:\n",
      "Train loss: 1.6828, Train acc: 0.2325\n",
      "Valid loss: 1.6854, Valid acc: 0.2431\n",
      "Epoch 31:\n",
      "Train loss: 1.6811, Train acc: 0.2338\n",
      "Valid loss: 1.6830, Valid acc: 0.2431\n",
      "Epoch 32:\n",
      "Train loss: 1.6789, Train acc: 0.2315\n",
      "Valid loss: 1.6807, Valid acc: 0.2431\n",
      "Epoch 33:\n",
      "Train loss: 1.6763, Train acc: 0.2341\n",
      "Valid loss: 1.6787, Valid acc: 0.2422\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7874, Train acc: 0.2182\n",
      "Valid loss: 1.7816, Valid acc: 0.2028\n",
      "Epoch 2:\n",
      "Train loss: 1.7813, Train acc: 0.2224\n",
      "Valid loss: 1.7752, Valid acc: 0.2037\n",
      "Epoch 3:\n",
      "Train loss: 1.7760, Train acc: 0.2194\n",
      "Valid loss: 1.7694, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.7707, Train acc: 0.2231\n",
      "Valid loss: 1.7640, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.7650, Train acc: 0.2201\n",
      "Valid loss: 1.7589, Valid acc: 0.2055\n",
      "Epoch 6:\n",
      "Train loss: 1.7601, Train acc: 0.2215\n",
      "Valid loss: 1.7541, Valid acc: 0.2055\n",
      "Epoch 7:\n",
      "Train loss: 1.7559, Train acc: 0.2215\n",
      "Valid loss: 1.7495, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.7512, Train acc: 0.2228\n",
      "Valid loss: 1.7450, Valid acc: 0.2055\n",
      "Epoch 9:\n",
      "Train loss: 1.7469, Train acc: 0.2215\n",
      "Valid loss: 1.7408, Valid acc: 0.2055\n",
      "Epoch 10:\n",
      "Train loss: 1.7429, Train acc: 0.2217\n",
      "Valid loss: 1.7367, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7858, Train acc: 0.1538\n",
      "Valid loss: 1.7778, Valid acc: 0.1624\n",
      "Epoch 2:\n",
      "Train loss: 1.7783, Train acc: 0.1884\n",
      "Valid loss: 1.7703, Valid acc: 0.2413\n",
      "Epoch 3:\n",
      "Train loss: 1.7708, Train acc: 0.2215\n",
      "Valid loss: 1.7635, Valid acc: 0.2394\n",
      "Epoch 4:\n",
      "Train loss: 1.7643, Train acc: 0.2141\n",
      "Valid loss: 1.7569, Valid acc: 0.2422\n",
      "Epoch 5:\n",
      "Train loss: 1.7586, Train acc: 0.2249\n",
      "Valid loss: 1.7509, Valid acc: 0.2110\n",
      "Epoch 6:\n",
      "Train loss: 1.7530, Train acc: 0.2187\n",
      "Valid loss: 1.7453, Valid acc: 0.2110\n",
      "Epoch 7:\n",
      "Train loss: 1.7462, Train acc: 0.2210\n",
      "Valid loss: 1.7396, Valid acc: 0.2101\n",
      "Epoch 8:\n",
      "Train loss: 1.7412, Train acc: 0.2157\n",
      "Valid loss: 1.7344, Valid acc: 0.2138\n",
      "Epoch 9:\n",
      "Train loss: 1.7367, Train acc: 0.2194\n",
      "Valid loss: 1.7294, Valid acc: 0.2138\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7809, Train acc: 0.2082\n",
      "Valid loss: 1.7784, Valid acc: 0.2358\n",
      "Epoch 2:\n",
      "Train loss: 1.7760, Train acc: 0.2095\n",
      "Valid loss: 1.7750, Valid acc: 0.2367\n",
      "Epoch 3:\n",
      "Train loss: 1.7745, Train acc: 0.2088\n",
      "Valid loss: 1.7717, Valid acc: 0.2367\n",
      "Epoch 4:\n",
      "Train loss: 1.7709, Train acc: 0.2088\n",
      "Valid loss: 1.7686, Valid acc: 0.2367\n",
      "Epoch 5:\n",
      "Train loss: 1.7688, Train acc: 0.2086\n",
      "Valid loss: 1.7656, Valid acc: 0.2367\n",
      "Epoch 6:\n",
      "Train loss: 1.7659, Train acc: 0.2084\n",
      "Valid loss: 1.7627, Valid acc: 0.2367\n",
      "Epoch 7:\n",
      "Train loss: 1.7645, Train acc: 0.2086\n",
      "Valid loss: 1.7599, Valid acc: 0.2367\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7905, Train acc: 0.1552\n",
      "Valid loss: 1.7877, Valid acc: 0.1541\n",
      "Epoch 2:\n",
      "Train loss: 1.7873, Train acc: 0.2011\n",
      "Valid loss: 1.7838, Valid acc: 0.2000\n",
      "Epoch 3:\n",
      "Train loss: 1.7827, Train acc: 0.2212\n",
      "Valid loss: 1.7801, Valid acc: 0.1991\n",
      "Epoch 4:\n",
      "Train loss: 1.7796, Train acc: 0.2221\n",
      "Valid loss: 1.7767, Valid acc: 0.1991\n",
      "Epoch 5:\n",
      "Train loss: 1.7756, Train acc: 0.2212\n",
      "Valid loss: 1.7734, Valid acc: 0.1991\n",
      "Epoch 6:\n",
      "Train loss: 1.7739, Train acc: 0.2242\n",
      "Valid loss: 1.7702, Valid acc: 0.2000\n",
      "Epoch 7:\n",
      "Train loss: 1.7687, Train acc: 0.2247\n",
      "Valid loss: 1.7671, Valid acc: 0.2000\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7983, Train acc: 0.1529\n",
      "Valid loss: 1.7951, Valid acc: 0.1532\n",
      "Epoch 2:\n",
      "Train loss: 1.7962, Train acc: 0.1527\n",
      "Valid loss: 1.7912, Valid acc: 0.1532\n",
      "Epoch 3:\n",
      "Train loss: 1.7925, Train acc: 0.1534\n",
      "Valid loss: 1.7874, Valid acc: 0.1532\n",
      "Epoch 4:\n",
      "Train loss: 1.7877, Train acc: 0.1541\n",
      "Valid loss: 1.7836, Valid acc: 0.1560\n",
      "Epoch 5:\n",
      "Train loss: 1.7848, Train acc: 0.1926\n",
      "Valid loss: 1.7801, Valid acc: 0.2339\n",
      "Epoch 6:\n",
      "Train loss: 1.7802, Train acc: 0.2059\n",
      "Valid loss: 1.7767, Valid acc: 0.2349\n",
      "Epoch 7:\n",
      "Train loss: 1.7766, Train acc: 0.2075\n",
      "Valid loss: 1.7734, Valid acc: 0.2349\n",
      "Epoch 8:\n",
      "Train loss: 1.7750, Train acc: 0.2066\n",
      "Valid loss: 1.7702, Valid acc: 0.2358\n",
      "Epoch 9:\n",
      "Train loss: 1.7709, Train acc: 0.2077\n",
      "Valid loss: 1.7671, Valid acc: 0.2358\n",
      "Epoch 10:\n",
      "Train loss: 1.7672, Train acc: 0.2072\n",
      "Valid loss: 1.7640, Valid acc: 0.2358\n",
      "Epoch 11:\n",
      "Train loss: 1.7647, Train acc: 0.2100\n",
      "Valid loss: 1.7611, Valid acc: 0.2358\n",
      "Epoch 12:\n",
      "Train loss: 1.7633, Train acc: 0.2098\n",
      "Valid loss: 1.7582, Valid acc: 0.2349\n",
      "Epoch 13:\n",
      "Train loss: 1.7606, Train acc: 0.2125\n",
      "Valid loss: 1.7553, Valid acc: 0.2349\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7001, Train acc: 0.2208\n",
      "Valid loss: 1.6553, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.6519, Train acc: 0.2293\n",
      "Valid loss: 1.6501, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6485, Train acc: 0.2263\n",
      "Valid loss: 1.6495, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6478, Train acc: 0.2343\n",
      "Valid loss: 1.6495, Valid acc: 0.2459\n",
      "Epoch 5:\n",
      "Train loss: 1.6470, Train acc: 0.2299\n",
      "Valid loss: 1.6484, Valid acc: 0.2440\n",
      "Epoch 6:\n",
      "Train loss: 1.6488, Train acc: 0.2274\n",
      "Valid loss: 1.6477, Valid acc: 0.2459\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6640, Train acc: 0.2267\n",
      "Valid loss: 1.6522, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6460, Train acc: 0.2373\n",
      "Valid loss: 1.6478, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6458, Train acc: 0.2302\n",
      "Valid loss: 1.6466, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6463, Train acc: 0.2327\n",
      "Valid loss: 1.6460, Valid acc: 0.2587\n",
      "Epoch 5:\n",
      "Train loss: 1.6445, Train acc: 0.2311\n",
      "Valid loss: 1.6471, Valid acc: 0.2303\n",
      "Epoch 6:\n",
      "Train loss: 1.6434, Train acc: 0.2384\n",
      "Valid loss: 1.6477, Valid acc: 0.2367\n",
      "Epoch 7:\n",
      "Train loss: 1.6382, Train acc: 0.2444\n",
      "Valid loss: 1.6450, Valid acc: 0.2596\n",
      "Epoch 8:\n",
      "Train loss: 1.6399, Train acc: 0.2432\n",
      "Valid loss: 1.6452, Valid acc: 0.2550\n",
      "Epoch 9:\n",
      "Train loss: 1.6395, Train acc: 0.2570\n",
      "Valid loss: 1.6441, Valid acc: 0.2569\n",
      "Epoch 10:\n",
      "Train loss: 1.6122, Train acc: 0.2941\n",
      "Valid loss: 1.5435, Valid acc: 0.3633\n",
      "Epoch 11:\n",
      "Train loss: 1.4657, Train acc: 0.3893\n",
      "Valid loss: 1.4576, Valid acc: 0.3982\n",
      "Epoch 12:\n",
      "Train loss: 1.3947, Train acc: 0.4072\n",
      "Valid loss: 1.4046, Valid acc: 0.4174\n",
      "Epoch 13:\n",
      "Train loss: 1.3494, Train acc: 0.4287\n",
      "Valid loss: 1.3726, Valid acc: 0.4239\n",
      "Epoch 14:\n",
      "Train loss: 1.3000, Train acc: 0.4392\n",
      "Valid loss: 1.3642, Valid acc: 0.3890\n",
      "Epoch 15:\n",
      "Train loss: 1.2584, Train acc: 0.4587\n",
      "Valid loss: 1.2996, Valid acc: 0.4679\n",
      "Epoch 16:\n",
      "Train loss: 1.2277, Train acc: 0.4668\n",
      "Valid loss: 1.2675, Valid acc: 0.4587\n",
      "Epoch 17:\n",
      "Train loss: 1.1947, Train acc: 0.4858\n",
      "Valid loss: 1.2874, Valid acc: 0.4917\n",
      "Epoch 18:\n",
      "Train loss: 1.1707, Train acc: 0.5064\n",
      "Valid loss: 1.2196, Valid acc: 0.5147\n",
      "Epoch 19:\n",
      "Train loss: 1.1488, Train acc: 0.5277\n",
      "Valid loss: 1.2496, Valid acc: 0.5211\n",
      "Epoch 20:\n",
      "Train loss: 1.1271, Train acc: 0.5367\n",
      "Valid loss: 1.1933, Valid acc: 0.5367\n",
      "Epoch 21:\n",
      "Train loss: 1.1046, Train acc: 0.5475\n",
      "Valid loss: 1.1736, Valid acc: 0.5578\n",
      "Epoch 22:\n",
      "Train loss: 1.0910, Train acc: 0.5633\n",
      "Valid loss: 1.1621, Valid acc: 0.5440\n",
      "Epoch 23:\n",
      "Train loss: 1.0715, Train acc: 0.5745\n",
      "Valid loss: 1.1439, Valid acc: 0.5670\n",
      "Epoch 24:\n",
      "Train loss: 1.0561, Train acc: 0.5770\n",
      "Valid loss: 1.1569, Valid acc: 0.5514\n",
      "Epoch 25:\n",
      "Train loss: 1.0431, Train acc: 0.5853\n",
      "Valid loss: 1.1445, Valid acc: 0.5330\n",
      "Epoch 26:\n",
      "Train loss: 1.0304, Train acc: 0.6009\n",
      "Valid loss: 1.1292, Valid acc: 0.5578\n",
      "Epoch 27:\n",
      "Train loss: 1.0177, Train acc: 0.6002\n",
      "Valid loss: 1.1082, Valid acc: 0.5706\n",
      "Epoch 28:\n",
      "Train loss: 1.0078, Train acc: 0.6082\n",
      "Valid loss: 1.0968, Valid acc: 0.5862\n",
      "Epoch 29:\n",
      "Train loss: 0.9889, Train acc: 0.6107\n",
      "Valid loss: 1.0848, Valid acc: 0.5908\n",
      "Epoch 30:\n",
      "Train loss: 0.9777, Train acc: 0.6213\n",
      "Valid loss: 1.1136, Valid acc: 0.5917\n",
      "Epoch 31:\n",
      "Train loss: 0.9622, Train acc: 0.6295\n",
      "Valid loss: 1.0649, Valid acc: 0.6028\n",
      "Epoch 32:\n",
      "Train loss: 0.9555, Train acc: 0.6339\n",
      "Valid loss: 1.1001, Valid acc: 0.5789\n",
      "Epoch 33:\n",
      "Train loss: 0.9419, Train acc: 0.6470\n",
      "Valid loss: 1.0438, Valid acc: 0.6110\n",
      "Epoch 34:\n",
      "Train loss: 0.9225, Train acc: 0.6600\n",
      "Valid loss: 1.0325, Valid acc: 0.6073\n",
      "Epoch 35:\n",
      "Train loss: 0.9131, Train acc: 0.6616\n",
      "Valid loss: 1.0424, Valid acc: 0.6028\n",
      "Epoch 36:\n",
      "Train loss: 0.8944, Train acc: 0.6692\n",
      "Valid loss: 1.0351, Valid acc: 0.6211\n",
      "Epoch 37:\n",
      "Train loss: 0.8793, Train acc: 0.6761\n",
      "Valid loss: 1.0087, Valid acc: 0.6257\n",
      "Epoch 38:\n",
      "Train loss: 0.8673, Train acc: 0.6804\n",
      "Valid loss: 1.0105, Valid acc: 0.6092\n",
      "Epoch 39:\n",
      "Train loss: 0.8643, Train acc: 0.6882\n",
      "Valid loss: 1.0001, Valid acc: 0.6257\n",
      "Epoch 40:\n",
      "Train loss: 0.8506, Train acc: 0.6942\n",
      "Valid loss: 0.9975, Valid acc: 0.6339\n",
      "Epoch 41:\n",
      "Train loss: 0.8361, Train acc: 0.7015\n",
      "Valid loss: 0.9997, Valid acc: 0.6321\n",
      "Epoch 42:\n",
      "Train loss: 0.8273, Train acc: 0.7022\n",
      "Valid loss: 0.9803, Valid acc: 0.6413\n",
      "Epoch 43:\n",
      "Train loss: 0.8168, Train acc: 0.7045\n",
      "Valid loss: 1.0137, Valid acc: 0.6193\n",
      "Epoch 44:\n",
      "Train loss: 0.8061, Train acc: 0.7086\n",
      "Valid loss: 0.9683, Valid acc: 0.6431\n",
      "Epoch 45:\n",
      "Train loss: 0.8029, Train acc: 0.7111\n",
      "Valid loss: 0.9931, Valid acc: 0.6312\n",
      "Epoch 46:\n",
      "Train loss: 0.7973, Train acc: 0.7109\n",
      "Valid loss: 0.9783, Valid acc: 0.6440\n",
      "Epoch 47:\n",
      "Train loss: 0.7830, Train acc: 0.7176\n",
      "Valid loss: 0.9739, Valid acc: 0.6477\n",
      "Epoch 48:\n",
      "Train loss: 0.7778, Train acc: 0.7254\n",
      "Valid loss: 0.9593, Valid acc: 0.6440\n",
      "Epoch 49:\n",
      "Train loss: 0.7701, Train acc: 0.7247\n",
      "Valid loss: 0.9511, Valid acc: 0.6468\n",
      "Epoch 50:\n",
      "Train loss: 0.7636, Train acc: 0.7276\n",
      "Valid loss: 0.9752, Valid acc: 0.6459\n",
      "Epoch 51:\n",
      "Train loss: 0.7586, Train acc: 0.7311\n",
      "Valid loss: 0.9464, Valid acc: 0.6514\n",
      "Epoch 52:\n",
      "Train loss: 0.7505, Train acc: 0.7334\n",
      "Valid loss: 0.9455, Valid acc: 0.6523\n",
      "Epoch 53:\n",
      "Train loss: 0.7460, Train acc: 0.7387\n",
      "Valid loss: 0.9944, Valid acc: 0.6358\n",
      "Epoch 54:\n",
      "Train loss: 0.7397, Train acc: 0.7396\n",
      "Valid loss: 0.9387, Valid acc: 0.6505\n",
      "Epoch 55:\n",
      "Train loss: 0.7340, Train acc: 0.7430\n",
      "Valid loss: 0.9572, Valid acc: 0.6541\n",
      "Epoch 56:\n",
      "Train loss: 0.7298, Train acc: 0.7448\n",
      "Valid loss: 0.9434, Valid acc: 0.6514\n",
      "Epoch 57:\n",
      "Train loss: 0.7235, Train acc: 0.7467\n",
      "Valid loss: 0.9762, Valid acc: 0.6468\n",
      "Epoch 58:\n",
      "Train loss: 0.7159, Train acc: 0.7448\n",
      "Valid loss: 0.9622, Valid acc: 0.6514\n",
      "Epoch 59:\n",
      "Train loss: 0.7095, Train acc: 0.7485\n",
      "Valid loss: 0.9552, Valid acc: 0.6532\n",
      "Epoch 60:\n",
      "Train loss: 0.7122, Train acc: 0.7538\n",
      "Valid loss: 0.9285, Valid acc: 0.6642\n",
      "Epoch 61:\n",
      "Train loss: 0.7018, Train acc: 0.7542\n",
      "Valid loss: 0.9351, Valid acc: 0.6624\n",
      "Epoch 62:\n",
      "Train loss: 0.6985, Train acc: 0.7536\n",
      "Valid loss: 0.9356, Valid acc: 0.6624\n",
      "Epoch 63:\n",
      "Train loss: 0.6894, Train acc: 0.7549\n",
      "Valid loss: 0.9285, Valid acc: 0.6679\n",
      "Epoch 64:\n",
      "Train loss: 0.6904, Train acc: 0.7563\n",
      "Valid loss: 0.9259, Valid acc: 0.6679\n",
      "Epoch 65:\n",
      "Train loss: 0.6861, Train acc: 0.7634\n",
      "Valid loss: 0.9300, Valid acc: 0.6624\n",
      "Epoch 66:\n",
      "Train loss: 0.6798, Train acc: 0.7666\n",
      "Valid loss: 0.9284, Valid acc: 0.6642\n",
      "Epoch 67:\n",
      "Train loss: 0.6762, Train acc: 0.7669\n",
      "Valid loss: 0.9700, Valid acc: 0.6587\n",
      "Epoch 68:\n",
      "Train loss: 0.6751, Train acc: 0.7630\n",
      "Valid loss: 0.9225, Valid acc: 0.6670\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6589, Train acc: 0.2219\n",
      "Valid loss: 1.6647, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6463, Train acc: 0.2309\n",
      "Valid loss: 1.6531, Valid acc: 0.2505\n",
      "Epoch 3:\n",
      "Train loss: 1.6447, Train acc: 0.2432\n",
      "Valid loss: 1.6522, Valid acc: 0.2587\n",
      "Epoch 4:\n",
      "Train loss: 1.6417, Train acc: 0.2414\n",
      "Valid loss: 1.6411, Valid acc: 0.2651\n",
      "Epoch 5:\n",
      "Train loss: 1.6075, Train acc: 0.2987\n",
      "Valid loss: 1.5315, Valid acc: 0.3697\n",
      "Epoch 6:\n",
      "Train loss: 1.4787, Train acc: 0.3790\n",
      "Valid loss: 1.4663, Valid acc: 0.3972\n",
      "Epoch 7:\n",
      "Train loss: 1.4204, Train acc: 0.4097\n",
      "Valid loss: 1.4415, Valid acc: 0.4028\n",
      "Epoch 8:\n",
      "Train loss: 1.3648, Train acc: 0.4269\n",
      "Valid loss: 1.4112, Valid acc: 0.4128\n",
      "Epoch 9:\n",
      "Train loss: 1.3181, Train acc: 0.4409\n",
      "Valid loss: 1.3608, Valid acc: 0.4431\n",
      "Epoch 10:\n",
      "Train loss: 1.2755, Train acc: 0.4638\n",
      "Valid loss: 1.2817, Valid acc: 0.4771\n",
      "Epoch 11:\n",
      "Train loss: 1.2189, Train acc: 0.4851\n",
      "Valid loss: 1.2982, Valid acc: 0.4587\n",
      "Epoch 12:\n",
      "Train loss: 1.1909, Train acc: 0.5039\n",
      "Valid loss: 1.2614, Valid acc: 0.5028\n",
      "Epoch 13:\n",
      "Train loss: 1.1483, Train acc: 0.5339\n",
      "Valid loss: 1.2078, Valid acc: 0.5330\n",
      "Epoch 14:\n",
      "Train loss: 1.1253, Train acc: 0.5702\n",
      "Valid loss: 1.2424, Valid acc: 0.5046\n",
      "Epoch 15:\n",
      "Train loss: 1.0969, Train acc: 0.5711\n",
      "Valid loss: 1.1513, Valid acc: 0.5752\n",
      "Epoch 16:\n",
      "Train loss: 1.0723, Train acc: 0.5931\n",
      "Valid loss: 1.1256, Valid acc: 0.5817\n",
      "Epoch 17:\n",
      "Train loss: 1.0321, Train acc: 0.6137\n",
      "Valid loss: 1.1011, Valid acc: 0.5917\n",
      "Epoch 18:\n",
      "Train loss: 0.9983, Train acc: 0.6307\n",
      "Valid loss: 1.0724, Valid acc: 0.6193\n",
      "Epoch 19:\n",
      "Train loss: 0.9712, Train acc: 0.6327\n",
      "Valid loss: 1.0394, Valid acc: 0.6083\n",
      "Epoch 20:\n",
      "Train loss: 0.9458, Train acc: 0.6394\n",
      "Valid loss: 1.0247, Valid acc: 0.6358\n",
      "Epoch 21:\n",
      "Train loss: 0.9303, Train acc: 0.6531\n",
      "Valid loss: 1.0767, Valid acc: 0.5954\n",
      "Epoch 22:\n",
      "Train loss: 0.9062, Train acc: 0.6490\n",
      "Valid loss: 0.9961, Valid acc: 0.6450\n",
      "Epoch 23:\n",
      "Train loss: 0.8868, Train acc: 0.6593\n",
      "Valid loss: 0.9769, Valid acc: 0.6477\n",
      "Epoch 24:\n",
      "Train loss: 0.8717, Train acc: 0.6641\n",
      "Valid loss: 0.9767, Valid acc: 0.6394\n",
      "Epoch 25:\n",
      "Train loss: 0.8600, Train acc: 0.6619\n",
      "Valid loss: 0.9782, Valid acc: 0.6459\n",
      "Epoch 26:\n",
      "Train loss: 0.8477, Train acc: 0.6733\n",
      "Valid loss: 0.9594, Valid acc: 0.6404\n",
      "Epoch 27:\n",
      "Train loss: 0.8489, Train acc: 0.6696\n",
      "Valid loss: 1.0118, Valid acc: 0.6303\n",
      "Epoch 28:\n",
      "Train loss: 0.8299, Train acc: 0.6747\n",
      "Valid loss: 0.9492, Valid acc: 0.6523\n",
      "Epoch 29:\n",
      "Train loss: 0.8169, Train acc: 0.6802\n",
      "Valid loss: 0.9436, Valid acc: 0.6569\n",
      "Epoch 30:\n",
      "Train loss: 0.8309, Train acc: 0.6763\n",
      "Valid loss: 0.9558, Valid acc: 0.6486\n",
      "Epoch 31:\n",
      "Train loss: 0.8169, Train acc: 0.6795\n",
      "Valid loss: 0.9294, Valid acc: 0.6624\n",
      "Epoch 32:\n",
      "Train loss: 0.7891, Train acc: 0.6896\n",
      "Valid loss: 0.9242, Valid acc: 0.6550\n",
      "Epoch 33:\n",
      "Train loss: 0.7746, Train acc: 0.6942\n",
      "Valid loss: 0.9236, Valid acc: 0.6532\n",
      "Epoch 34:\n",
      "Train loss: 0.7728, Train acc: 0.6958\n",
      "Valid loss: 0.9169, Valid acc: 0.6560\n",
      "Epoch 35:\n",
      "Train loss: 0.7753, Train acc: 0.6935\n",
      "Valid loss: 0.9594, Valid acc: 0.6560\n",
      "Epoch 36:\n",
      "Train loss: 0.7482, Train acc: 0.6965\n",
      "Valid loss: 0.9198, Valid acc: 0.6587\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7419, Train acc: 0.1889\n",
      "Valid loss: 1.6742, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6636, Train acc: 0.2270\n",
      "Valid loss: 1.6533, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6547, Train acc: 0.2274\n",
      "Valid loss: 1.6479, Valid acc: 0.2413\n",
      "Epoch 4:\n",
      "Train loss: 1.6492, Train acc: 0.2226\n",
      "Valid loss: 1.6464, Valid acc: 0.2422\n",
      "Epoch 5:\n",
      "Train loss: 1.6507, Train acc: 0.2240\n",
      "Valid loss: 1.6475, Valid acc: 0.2422\n",
      "Epoch 6:\n",
      "Train loss: 1.6484, Train acc: 0.2338\n",
      "Valid loss: 1.6471, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6464, Train acc: 0.2196\n",
      "Valid loss: 1.6473, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6467, Train acc: 0.2249\n",
      "Valid loss: 1.6467, Valid acc: 0.2440\n",
      "Epoch 9:\n",
      "Train loss: 1.6459, Train acc: 0.2247\n",
      "Valid loss: 1.6463, Valid acc: 0.2422\n",
      "Epoch 10:\n",
      "Train loss: 1.6493, Train acc: 0.2235\n",
      "Valid loss: 1.6473, Valid acc: 0.2037\n",
      "Epoch 11:\n",
      "Train loss: 1.6495, Train acc: 0.2274\n",
      "Valid loss: 1.6462, Valid acc: 0.2422\n",
      "Epoch 12:\n",
      "Train loss: 1.6487, Train acc: 0.2311\n",
      "Valid loss: 1.6461, Valid acc: 0.2422\n",
      "Epoch 13:\n",
      "Train loss: 1.6468, Train acc: 0.2247\n",
      "Valid loss: 1.6468, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6638, Train acc: 0.2260\n",
      "Valid loss: 1.6472, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.6507, Train acc: 0.2295\n",
      "Valid loss: 1.6432, Valid acc: 0.2422\n",
      "Epoch 3:\n",
      "Train loss: 1.6499, Train acc: 0.2251\n",
      "Valid loss: 1.6456, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6498, Train acc: 0.2304\n",
      "Valid loss: 1.6463, Valid acc: 0.2422\n",
      "Epoch 5:\n",
      "Train loss: 1.6488, Train acc: 0.2309\n",
      "Valid loss: 1.6441, Valid acc: 0.2413\n",
      "Epoch 6:\n",
      "Train loss: 1.6475, Train acc: 0.2306\n",
      "Valid loss: 1.6446, Valid acc: 0.2376\n",
      "Epoch 7:\n",
      "Train loss: 1.6487, Train acc: 0.2302\n",
      "Valid loss: 1.6452, Valid acc: 0.2394\n",
      "Epoch 8:\n",
      "Train loss: 1.6453, Train acc: 0.2327\n",
      "Valid loss: 1.6455, Valid acc: 0.2358\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6615, Train acc: 0.2201\n",
      "Valid loss: 1.6513, Valid acc: 0.2477\n",
      "Epoch 2:\n",
      "Train loss: 1.6480, Train acc: 0.2393\n",
      "Valid loss: 1.6395, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6483, Train acc: 0.2212\n",
      "Valid loss: 1.6562, Valid acc: 0.2376\n",
      "Epoch 4:\n",
      "Train loss: 1.6436, Train acc: 0.2350\n",
      "Valid loss: 1.6496, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6479, Train acc: 0.2297\n",
      "Valid loss: 1.6515, Valid acc: 0.2624\n",
      "Epoch 6:\n",
      "Train loss: 1.6406, Train acc: 0.2554\n",
      "Valid loss: 1.6547, Valid acc: 0.2257\n",
      "Epoch 7:\n",
      "Train loss: 1.6417, Train acc: 0.2524\n",
      "Valid loss: 1.6451, Valid acc: 0.2651\n",
      "Epoch 8:\n",
      "Train loss: 1.6364, Train acc: 0.2584\n",
      "Valid loss: 1.6271, Valid acc: 0.2752\n",
      "Epoch 9:\n",
      "Train loss: 1.5164, Train acc: 0.3599\n",
      "Valid loss: 1.4734, Valid acc: 0.3853\n",
      "Epoch 10:\n",
      "Train loss: 1.4111, Train acc: 0.4042\n",
      "Valid loss: 1.4303, Valid acc: 0.3908\n",
      "Epoch 11:\n",
      "Train loss: 1.3641, Train acc: 0.4039\n",
      "Valid loss: 1.4091, Valid acc: 0.4009\n",
      "Epoch 12:\n",
      "Train loss: 1.3112, Train acc: 0.4271\n",
      "Valid loss: 1.4168, Valid acc: 0.4284\n",
      "Epoch 13:\n",
      "Train loss: 1.2674, Train acc: 0.4695\n",
      "Valid loss: 1.3325, Valid acc: 0.4303\n",
      "Epoch 14:\n",
      "Train loss: 1.2189, Train acc: 0.4966\n",
      "Valid loss: 1.2644, Valid acc: 0.5110\n",
      "Epoch 15:\n",
      "Train loss: 1.1664, Train acc: 0.5332\n",
      "Valid loss: 1.3576, Valid acc: 0.4615\n",
      "Epoch 16:\n",
      "Train loss: 1.1465, Train acc: 0.5463\n",
      "Valid loss: 1.2356, Valid acc: 0.5275\n",
      "Epoch 17:\n",
      "Train loss: 1.0950, Train acc: 0.5669\n",
      "Valid loss: 1.1894, Valid acc: 0.5633\n",
      "Epoch 18:\n",
      "Train loss: 1.0567, Train acc: 0.5935\n",
      "Valid loss: 1.2462, Valid acc: 0.5459\n",
      "Epoch 19:\n",
      "Train loss: 1.0495, Train acc: 0.5997\n",
      "Valid loss: 1.1441, Valid acc: 0.5780\n",
      "Epoch 20:\n",
      "Train loss: 1.0121, Train acc: 0.6130\n",
      "Valid loss: 1.2104, Valid acc: 0.5266\n",
      "Epoch 21:\n",
      "Train loss: 0.9908, Train acc: 0.6158\n",
      "Valid loss: 1.1697, Valid acc: 0.5706\n",
      "Epoch 22:\n",
      "Train loss: 0.9749, Train acc: 0.6135\n",
      "Valid loss: 1.0929, Valid acc: 0.6046\n",
      "Epoch 23:\n",
      "Train loss: 0.9468, Train acc: 0.6318\n",
      "Valid loss: 1.1339, Valid acc: 0.5972\n",
      "Epoch 24:\n",
      "Train loss: 0.9286, Train acc: 0.6419\n",
      "Valid loss: 1.0572, Valid acc: 0.6083\n",
      "Epoch 25:\n",
      "Train loss: 0.9232, Train acc: 0.6405\n",
      "Valid loss: 1.0626, Valid acc: 0.6092\n",
      "Epoch 26:\n",
      "Train loss: 0.9038, Train acc: 0.6497\n",
      "Valid loss: 1.0286, Valid acc: 0.6156\n",
      "Epoch 27:\n",
      "Train loss: 0.8877, Train acc: 0.6513\n",
      "Valid loss: 1.1189, Valid acc: 0.6028\n",
      "Epoch 28:\n",
      "Train loss: 0.8735, Train acc: 0.6527\n",
      "Valid loss: 1.0147, Valid acc: 0.6147\n",
      "Epoch 29:\n",
      "Train loss: 0.9279, Train acc: 0.6433\n",
      "Valid loss: 1.3030, Valid acc: 0.5248\n",
      "Epoch 30:\n",
      "Train loss: 0.9544, Train acc: 0.6238\n",
      "Valid loss: 1.0321, Valid acc: 0.6193\n",
      "Epoch 31:\n",
      "Train loss: 0.8391, Train acc: 0.6701\n",
      "Valid loss: 1.0021, Valid acc: 0.6229\n",
      "Epoch 32:\n",
      "Train loss: 0.8347, Train acc: 0.6680\n",
      "Valid loss: 0.9938, Valid acc: 0.6358\n",
      "Epoch 33:\n",
      "Train loss: 0.8150, Train acc: 0.6795\n",
      "Valid loss: 1.0306, Valid acc: 0.6193\n",
      "Epoch 34:\n",
      "Train loss: 0.8156, Train acc: 0.6779\n",
      "Valid loss: 0.9866, Valid acc: 0.6376\n",
      "Epoch 35:\n",
      "Train loss: 0.8132, Train acc: 0.6765\n",
      "Valid loss: 0.9802, Valid acc: 0.6349\n",
      "Epoch 36:\n",
      "Train loss: 0.8043, Train acc: 0.6859\n",
      "Valid loss: 1.0471, Valid acc: 0.6147\n",
      "Epoch 37:\n",
      "Train loss: 0.7923, Train acc: 0.6832\n",
      "Valid loss: 1.0002, Valid acc: 0.6385\n",
      "Epoch 38:\n",
      "Train loss: 0.8026, Train acc: 0.6820\n",
      "Valid loss: 0.9692, Valid acc: 0.6358\n",
      "Epoch 39:\n",
      "Train loss: 0.7838, Train acc: 0.6848\n",
      "Valid loss: 0.9653, Valid acc: 0.6321\n",
      "Epoch 40:\n",
      "Train loss: 0.7835, Train acc: 0.6894\n",
      "Valid loss: 0.9622, Valid acc: 0.6358\n",
      "Epoch 41:\n",
      "Train loss: 0.7659, Train acc: 0.6914\n",
      "Valid loss: 0.9795, Valid acc: 0.6385\n",
      "Epoch 42:\n",
      "Train loss: 0.7784, Train acc: 0.6875\n",
      "Valid loss: 0.9650, Valid acc: 0.6303\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7334, Train acc: 0.2192\n",
      "Valid loss: 1.6728, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6658, Train acc: 0.2254\n",
      "Valid loss: 1.6564, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6615, Train acc: 0.2322\n",
      "Valid loss: 1.6537, Valid acc: 0.2468\n",
      "Epoch 4:\n",
      "Train loss: 1.6566, Train acc: 0.2210\n",
      "Valid loss: 1.6519, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6531, Train acc: 0.2281\n",
      "Valid loss: 1.6525, Valid acc: 0.2018\n",
      "Epoch 6:\n",
      "Train loss: 1.6533, Train acc: 0.2279\n",
      "Valid loss: 1.6530, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6519, Train acc: 0.2238\n",
      "Valid loss: 1.6529, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6846, Train acc: 0.2221\n",
      "Valid loss: 1.6576, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6522, Train acc: 0.2203\n",
      "Valid loss: 1.6500, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6752, Train acc: 0.2302\n",
      "Valid loss: 1.6559, Valid acc: 0.2486\n",
      "Epoch 4:\n",
      "Train loss: 1.6529, Train acc: 0.2221\n",
      "Valid loss: 1.6526, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6505, Train acc: 0.2299\n",
      "Valid loss: 1.6495, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.6492, Train acc: 0.2194\n",
      "Valid loss: 1.6512, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6454, Train acc: 0.2251\n",
      "Valid loss: 1.6507, Valid acc: 0.2468\n",
      "Epoch 8:\n",
      "Train loss: 1.6501, Train acc: 0.2240\n",
      "Valid loss: 1.6517, Valid acc: 0.2477\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6711, Train acc: 0.2166\n",
      "Valid loss: 1.6682, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6529, Train acc: 0.2265\n",
      "Valid loss: 1.6544, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6518, Train acc: 0.2327\n",
      "Valid loss: 1.6498, Valid acc: 0.2376\n",
      "Epoch 4:\n",
      "Train loss: 1.6497, Train acc: 0.2189\n",
      "Valid loss: 1.6488, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6563, Train acc: 0.2302\n",
      "Valid loss: 1.6493, Valid acc: 0.2450\n",
      "Epoch 6:\n",
      "Train loss: 1.6496, Train acc: 0.2276\n",
      "Valid loss: 1.6503, Valid acc: 0.2459\n",
      "Epoch 7:\n",
      "Train loss: 1.6477, Train acc: 0.2322\n",
      "Valid loss: 1.6501, Valid acc: 0.2578\n",
      "Epoch 8:\n",
      "Train loss: 1.6513, Train acc: 0.2226\n",
      "Valid loss: 1.6560, Valid acc: 0.2376\n",
      "Epoch 9:\n",
      "Train loss: 1.6445, Train acc: 0.2315\n",
      "Valid loss: 1.6514, Valid acc: 0.2486\n",
      "Epoch 10:\n",
      "Train loss: 1.6435, Train acc: 0.2313\n",
      "Valid loss: 1.6520, Valid acc: 0.2486\n",
      "Epoch 11:\n",
      "Train loss: 1.6402, Train acc: 0.2304\n",
      "Valid loss: 1.6787, Valid acc: 0.2046\n",
      "Epoch 12:\n",
      "Train loss: 1.6423, Train acc: 0.2492\n",
      "Valid loss: 1.6552, Valid acc: 0.2560\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6749, Train acc: 0.2201\n",
      "Valid loss: 1.6593, Valid acc: 0.2477\n",
      "Epoch 2:\n",
      "Train loss: 1.6526, Train acc: 0.2235\n",
      "Valid loss: 1.6376, Valid acc: 0.2505\n",
      "Epoch 3:\n",
      "Train loss: 1.6495, Train acc: 0.2299\n",
      "Valid loss: 1.6393, Valid acc: 0.2578\n",
      "Epoch 4:\n",
      "Train loss: 1.5689, Train acc: 0.3235\n",
      "Valid loss: 1.4687, Valid acc: 0.3468\n",
      "Epoch 5:\n",
      "Train loss: 1.4835, Train acc: 0.3439\n",
      "Valid loss: 1.5739, Valid acc: 0.2991\n",
      "Epoch 6:\n",
      "Train loss: 1.5613, Train acc: 0.2829\n",
      "Valid loss: 1.5582, Valid acc: 0.3073\n",
      "Epoch 7:\n",
      "Train loss: 1.5561, Train acc: 0.2912\n",
      "Valid loss: 1.5476, Valid acc: 0.3119\n",
      "Epoch 8:\n",
      "Train loss: 1.5533, Train acc: 0.2884\n",
      "Valid loss: 1.5366, Valid acc: 0.3202\n",
      "Epoch 9:\n",
      "Train loss: 1.5204, Train acc: 0.3063\n",
      "Valid loss: 1.4720, Valid acc: 0.3413\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6632, Train acc: 0.2299\n",
      "Valid loss: 1.6603, Valid acc: 0.1991\n",
      "Epoch 2:\n",
      "Train loss: 1.6541, Train acc: 0.2240\n",
      "Valid loss: 1.6431, Valid acc: 0.2495\n",
      "Epoch 3:\n",
      "Train loss: 1.6455, Train acc: 0.2485\n",
      "Valid loss: 1.6461, Valid acc: 0.2606\n",
      "Epoch 4:\n",
      "Train loss: 1.6243, Train acc: 0.2703\n",
      "Valid loss: 1.6587, Valid acc: 0.2101\n",
      "Epoch 5:\n",
      "Train loss: 1.6479, Train acc: 0.2348\n",
      "Valid loss: 1.6352, Valid acc: 0.2550\n",
      "Epoch 6:\n",
      "Train loss: 1.6420, Train acc: 0.2423\n",
      "Valid loss: 1.6600, Valid acc: 0.2404\n",
      "Epoch 7:\n",
      "Train loss: 1.6453, Train acc: 0.2403\n",
      "Valid loss: 1.6612, Valid acc: 0.2083\n",
      "Epoch 8:\n",
      "Train loss: 1.6473, Train acc: 0.2343\n",
      "Valid loss: 1.6521, Valid acc: 0.2138\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6666, Train acc: 0.2224\n",
      "Valid loss: 1.6521, Valid acc: 0.2394\n",
      "Epoch 2:\n",
      "Train loss: 1.6510, Train acc: 0.2244\n",
      "Valid loss: 1.6563, Valid acc: 0.2440\n",
      "Epoch 3:\n",
      "Train loss: 1.6552, Train acc: 0.2150\n",
      "Valid loss: 1.6460, Valid acc: 0.2330\n",
      "Epoch 4:\n",
      "Train loss: 1.6461, Train acc: 0.2283\n",
      "Valid loss: 1.6400, Valid acc: 0.2532\n",
      "Epoch 5:\n",
      "Train loss: 1.6461, Train acc: 0.2352\n",
      "Valid loss: 1.6773, Valid acc: 0.2459\n",
      "Epoch 6:\n",
      "Train loss: 1.6509, Train acc: 0.2263\n",
      "Valid loss: 1.6466, Valid acc: 0.2330\n",
      "Epoch 7:\n",
      "Train loss: 1.6389, Train acc: 0.2494\n",
      "Valid loss: 1.6526, Valid acc: 0.1917\n",
      "Epoch 8:\n",
      "Train loss: 1.6510, Train acc: 0.2325\n",
      "Valid loss: 1.6563, Valid acc: 0.2183\n",
      "Epoch 9:\n",
      "Train loss: 1.6276, Train acc: 0.2575\n",
      "Valid loss: 1.6115, Valid acc: 0.2624\n",
      "Epoch 10:\n",
      "Train loss: 1.6948, Train acc: 0.2327\n",
      "Valid loss: 1.6738, Valid acc: 0.2183\n",
      "Epoch 11:\n",
      "Train loss: 1.7493, Train acc: 0.2155\n",
      "Valid loss: 1.7000, Valid acc: 0.2239\n",
      "Epoch 12:\n",
      "Train loss: 1.7082, Train acc: 0.2043\n",
      "Valid loss: 1.6709, Valid acc: 0.2239\n",
      "Epoch 13:\n",
      "Train loss: 1.6892, Train acc: 0.2178\n",
      "Valid loss: 1.6982, Valid acc: 0.2009\n",
      "Epoch 14:\n",
      "Train loss: 1.6840, Train acc: 0.2203\n",
      "Valid loss: 1.6700, Valid acc: 0.2569\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6718, Train acc: 0.2210\n",
      "Valid loss: 1.6605, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.6495, Train acc: 0.2238\n",
      "Valid loss: 1.6551, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6480, Train acc: 0.2288\n",
      "Valid loss: 1.6526, Valid acc: 0.2404\n",
      "Epoch 4:\n",
      "Train loss: 1.6501, Train acc: 0.2391\n",
      "Valid loss: 1.6567, Valid acc: 0.2560\n",
      "Epoch 5:\n",
      "Train loss: 1.5963, Train acc: 0.2884\n",
      "Valid loss: 1.7142, Valid acc: 0.3266\n",
      "Epoch 6:\n",
      "Train loss: 1.5586, Train acc: 0.3391\n",
      "Valid loss: 1.6027, Valid acc: 0.3028\n",
      "Epoch 7:\n",
      "Train loss: 1.5895, Train acc: 0.3187\n",
      "Valid loss: 1.6749, Valid acc: 0.2385\n",
      "Epoch 8:\n",
      "Train loss: 1.6571, Train acc: 0.2210\n",
      "Valid loss: 1.6501, Valid acc: 0.2092\n",
      "Epoch 9:\n",
      "Train loss: 1.6487, Train acc: 0.2290\n",
      "Valid loss: 1.6458, Valid acc: 0.2431\n",
      "Epoch 10:\n",
      "Train loss: 1.6510, Train acc: 0.2192\n",
      "Valid loss: 1.6480, Valid acc: 0.2468\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6681, Train acc: 0.2164\n",
      "Valid loss: 1.6482, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6532, Train acc: 0.2318\n",
      "Valid loss: 1.6378, Valid acc: 0.2459\n",
      "Epoch 3:\n",
      "Train loss: 1.6542, Train acc: 0.2233\n",
      "Valid loss: 1.6711, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6510, Train acc: 0.2286\n",
      "Valid loss: 1.6620, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6496, Train acc: 0.2318\n",
      "Valid loss: 1.6421, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.6431, Train acc: 0.2240\n",
      "Valid loss: 1.6050, Valid acc: 0.2853\n",
      "Epoch 7:\n",
      "Train loss: 1.6540, Train acc: 0.2419\n",
      "Valid loss: 1.6747, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6585, Train acc: 0.2274\n",
      "Valid loss: 1.6559, Valid acc: 0.2064\n",
      "Epoch 9:\n",
      "Train loss: 1.6515, Train acc: 0.2325\n",
      "Valid loss: 1.6402, Valid acc: 0.2321\n",
      "Epoch 10:\n",
      "Train loss: 1.6485, Train acc: 0.2196\n",
      "Valid loss: 1.6337, Valid acc: 0.2330\n",
      "Epoch 11:\n",
      "Train loss: 1.6474, Train acc: 0.2256\n",
      "Valid loss: 1.6469, Valid acc: 0.2064\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6699, Train acc: 0.2265\n",
      "Valid loss: 1.6343, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6524, Train acc: 0.2219\n",
      "Valid loss: 1.6574, Valid acc: 0.2477\n",
      "Epoch 3:\n",
      "Train loss: 1.6515, Train acc: 0.2338\n",
      "Valid loss: 1.6790, Valid acc: 0.2413\n",
      "Epoch 4:\n",
      "Train loss: 1.6586, Train acc: 0.2265\n",
      "Valid loss: 1.6474, Valid acc: 0.2037\n",
      "Epoch 5:\n",
      "Train loss: 1.6466, Train acc: 0.2258\n",
      "Valid loss: 1.6669, Valid acc: 0.2376\n",
      "Epoch 6:\n",
      "Train loss: 1.6450, Train acc: 0.2393\n",
      "Valid loss: 1.6731, Valid acc: 0.2083\n",
      "Epoch 7:\n",
      "Train loss: 1.6500, Train acc: 0.2288\n",
      "Valid loss: 1.6406, Valid acc: 0.2385\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6949, Train acc: 0.2173\n",
      "Valid loss: 1.6518, Valid acc: 0.2477\n",
      "Epoch 2:\n",
      "Train loss: 1.6531, Train acc: 0.2137\n",
      "Valid loss: 1.6566, Valid acc: 0.2486\n",
      "Epoch 3:\n",
      "Train loss: 1.6528, Train acc: 0.2286\n",
      "Valid loss: 1.6538, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6527, Train acc: 0.2306\n",
      "Valid loss: 1.6522, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6244, Train acc: 0.2503\n",
      "Valid loss: 1.5290, Valid acc: 0.3844\n",
      "Epoch 6:\n",
      "Train loss: 1.6484, Train acc: 0.2630\n",
      "Valid loss: 1.6659, Valid acc: 0.2431\n",
      "Epoch 7:\n",
      "Train loss: 1.6545, Train acc: 0.2233\n",
      "Valid loss: 1.6464, Valid acc: 0.2587\n",
      "Epoch 8:\n",
      "Train loss: 1.6391, Train acc: 0.2396\n",
      "Valid loss: 1.6382, Valid acc: 0.2596\n",
      "Epoch 9:\n",
      "Train loss: 1.6262, Train acc: 0.2510\n",
      "Valid loss: 1.6364, Valid acc: 0.2679\n",
      "Epoch 10:\n",
      "Train loss: 1.4963, Train acc: 0.3418\n",
      "Valid loss: 1.4478, Valid acc: 0.3550\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6760, Train acc: 0.2205\n",
      "Valid loss: 1.6619, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6572, Train acc: 0.2130\n",
      "Valid loss: 1.6513, Valid acc: 0.2486\n",
      "Epoch 3:\n",
      "Train loss: 1.6510, Train acc: 0.2196\n",
      "Valid loss: 1.6611, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6514, Train acc: 0.2304\n",
      "Valid loss: 1.6627, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6480, Train acc: 0.2212\n",
      "Valid loss: 1.6528, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6492, Train acc: 0.2311\n",
      "Valid loss: 1.6479, Valid acc: 0.2468\n",
      "Epoch 7:\n",
      "Train loss: 1.6485, Train acc: 0.2210\n",
      "Valid loss: 1.6597, Valid acc: 0.2578\n",
      "Epoch 8:\n",
      "Train loss: 1.6466, Train acc: 0.2384\n",
      "Valid loss: 1.6513, Valid acc: 0.2468\n",
      "Epoch 9:\n",
      "Train loss: 1.6509, Train acc: 0.2288\n",
      "Valid loss: 1.6454, Valid acc: 0.2587\n",
      "Epoch 10:\n",
      "Train loss: 1.6285, Train acc: 0.2627\n",
      "Valid loss: 1.5917, Valid acc: 0.3771\n",
      "Epoch 11:\n",
      "Train loss: 1.5149, Train acc: 0.3684\n",
      "Valid loss: 1.5017, Valid acc: 0.3798\n",
      "Epoch 12:\n",
      "Train loss: 1.5589, Train acc: 0.3489\n",
      "Valid loss: 1.6646, Valid acc: 0.1972\n",
      "Epoch 13:\n",
      "Train loss: 1.6388, Train acc: 0.2600\n",
      "Valid loss: 1.6600, Valid acc: 0.2587\n",
      "Epoch 14:\n",
      "Train loss: 1.6217, Train acc: 0.2519\n",
      "Valid loss: 1.6795, Valid acc: 0.2174\n",
      "Epoch 15:\n",
      "Train loss: 1.5931, Train acc: 0.2783\n",
      "Valid loss: 1.5688, Valid acc: 0.3028\n",
      "Epoch 16:\n",
      "Train loss: 1.5432, Train acc: 0.3404\n",
      "Valid loss: 1.5448, Valid acc: 0.3321\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6736, Train acc: 0.2352\n",
      "Valid loss: 1.6738, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6545, Train acc: 0.2249\n",
      "Valid loss: 1.6674, Valid acc: 0.2037\n",
      "Epoch 3:\n",
      "Train loss: 1.6536, Train acc: 0.2228\n",
      "Valid loss: 1.6583, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6523, Train acc: 0.2274\n",
      "Valid loss: 1.6542, Valid acc: 0.2495\n",
      "Epoch 5:\n",
      "Train loss: 1.6535, Train acc: 0.2448\n",
      "Valid loss: 1.6623, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.6597, Train acc: 0.2079\n",
      "Valid loss: 1.6585, Valid acc: 0.2394\n",
      "Epoch 7:\n",
      "Train loss: 1.6561, Train acc: 0.2166\n",
      "Valid loss: 1.6495, Valid acc: 0.2422\n",
      "Epoch 8:\n",
      "Train loss: 1.6489, Train acc: 0.2322\n",
      "Valid loss: 1.6479, Valid acc: 0.2468\n",
      "Epoch 9:\n",
      "Train loss: 1.6472, Train acc: 0.2276\n",
      "Valid loss: 1.6512, Valid acc: 0.2028\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6620, Train acc: 0.2276\n",
      "Valid loss: 1.6450, Valid acc: 0.2495\n",
      "Epoch 2:\n",
      "Train loss: 1.6485, Train acc: 0.2233\n",
      "Valid loss: 1.6640, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6485, Train acc: 0.2348\n",
      "Valid loss: 1.6139, Valid acc: 0.3073\n",
      "Epoch 4:\n",
      "Train loss: 1.6008, Train acc: 0.2914\n",
      "Valid loss: 1.5216, Valid acc: 0.2817\n",
      "Epoch 5:\n",
      "Train loss: 1.4963, Train acc: 0.3547\n",
      "Valid loss: 1.4907, Valid acc: 0.3688\n",
      "Epoch 6:\n",
      "Train loss: 1.5484, Train acc: 0.3134\n",
      "Valid loss: 1.5285, Valid acc: 0.2807\n",
      "Epoch 7:\n",
      "Train loss: 1.4868, Train acc: 0.3668\n",
      "Valid loss: 1.4755, Valid acc: 0.3908\n",
      "Epoch 8:\n",
      "Train loss: 1.4901, Train acc: 0.3462\n",
      "Valid loss: 1.4868, Valid acc: 0.3550\n",
      "Epoch 9:\n",
      "Train loss: 1.5023, Train acc: 0.3269\n",
      "Valid loss: 1.4970, Valid acc: 0.3303\n",
      "Epoch 10:\n",
      "Train loss: 1.4884, Train acc: 0.3207\n",
      "Valid loss: 1.4876, Valid acc: 0.3440\n",
      "Epoch 11:\n",
      "Train loss: 1.4823, Train acc: 0.3336\n",
      "Valid loss: 1.4778, Valid acc: 0.3394\n",
      "Epoch 12:\n",
      "Train loss: 1.4830, Train acc: 0.3294\n",
      "Valid loss: 1.4799, Valid acc: 0.3404\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6707, Train acc: 0.2127\n",
      "Valid loss: 1.6907, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6534, Train acc: 0.2247\n",
      "Valid loss: 1.6372, Valid acc: 0.2523\n",
      "Epoch 3:\n",
      "Train loss: 1.6517, Train acc: 0.2370\n",
      "Valid loss: 1.6481, Valid acc: 0.2450\n",
      "Epoch 4:\n",
      "Train loss: 1.6499, Train acc: 0.2348\n",
      "Valid loss: 1.6472, Valid acc: 0.2468\n",
      "Epoch 5:\n",
      "Train loss: 1.6468, Train acc: 0.2503\n",
      "Valid loss: 1.6405, Valid acc: 0.2679\n",
      "Epoch 6:\n",
      "Train loss: 1.6462, Train acc: 0.2400\n",
      "Valid loss: 1.6375, Valid acc: 0.2670\n",
      "Epoch 7:\n",
      "Train loss: 1.6425, Train acc: 0.2439\n",
      "Valid loss: 1.6605, Valid acc: 0.2321\n",
      "Epoch 8:\n",
      "Train loss: 1.6425, Train acc: 0.2494\n",
      "Valid loss: 1.6444, Valid acc: 0.2550\n",
      "Epoch 9:\n",
      "Train loss: 1.6262, Train acc: 0.2850\n",
      "Valid loss: 1.6480, Valid acc: 0.2413\n",
      "Epoch 10:\n",
      "Train loss: 1.5964, Train acc: 0.3038\n",
      "Valid loss: 1.6091, Valid acc: 0.3092\n",
      "Epoch 11:\n",
      "Train loss: 1.6179, Train acc: 0.2767\n",
      "Valid loss: 1.6826, Valid acc: 0.1954\n",
      "Epoch 12:\n",
      "Train loss: 1.6452, Train acc: 0.2370\n",
      "Valid loss: 1.6655, Valid acc: 0.2312\n",
      "Epoch 13:\n",
      "Train loss: 1.6381, Train acc: 0.2471\n",
      "Valid loss: 1.6469, Valid acc: 0.2633\n",
      "Epoch 14:\n",
      "Train loss: 1.5122, Train acc: 0.3579\n",
      "Valid loss: 1.4629, Valid acc: 0.3945\n",
      "Epoch 15:\n",
      "Train loss: 1.4975, Train acc: 0.3599\n",
      "Valid loss: 1.5198, Valid acc: 0.2826\n",
      "Epoch 16:\n",
      "Train loss: 1.4978, Train acc: 0.3471\n",
      "Valid loss: 1.4735, Valid acc: 0.3908\n",
      "Epoch 17:\n",
      "Train loss: 1.4862, Train acc: 0.3647\n",
      "Valid loss: 1.7425, Valid acc: 0.2716\n",
      "Epoch 18:\n",
      "Train loss: 1.4870, Train acc: 0.3796\n",
      "Valid loss: 1.4505, Valid acc: 0.4028\n",
      "Epoch 19:\n",
      "Train loss: 1.5570, Train acc: 0.3063\n",
      "Valid loss: 1.6400, Valid acc: 0.2394\n",
      "Epoch 20:\n",
      "Train loss: 1.6478, Train acc: 0.2364\n",
      "Valid loss: 1.6802, Valid acc: 0.2220\n",
      "Epoch 21:\n",
      "Train loss: 1.6240, Train acc: 0.2753\n",
      "Valid loss: 1.5712, Valid acc: 0.2826\n",
      "Epoch 22:\n",
      "Train loss: 1.4543, Train acc: 0.3801\n",
      "Valid loss: 1.4238, Valid acc: 0.4193\n",
      "Epoch 23:\n",
      "Train loss: 1.4337, Train acc: 0.3989\n",
      "Valid loss: 1.4848, Valid acc: 0.3624\n",
      "Epoch 24:\n",
      "Train loss: 1.4345, Train acc: 0.3909\n",
      "Valid loss: 1.4052, Valid acc: 0.4028\n",
      "Epoch 25:\n",
      "Train loss: 1.4362, Train acc: 0.3748\n",
      "Valid loss: 1.4023, Valid acc: 0.4183\n",
      "Epoch 26:\n",
      "Train loss: 1.3817, Train acc: 0.3998\n",
      "Valid loss: 1.4531, Valid acc: 0.3917\n",
      "Epoch 27:\n",
      "Train loss: 1.3818, Train acc: 0.3879\n",
      "Valid loss: 1.4170, Valid acc: 0.3743\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.8294, Train acc: 0.1937\n",
      "Valid loss: 1.7347, Valid acc: 0.2248\n",
      "Epoch 2:\n",
      "Train loss: 1.6963, Train acc: 0.2219\n",
      "Valid loss: 1.7063, Valid acc: 0.2128\n",
      "Epoch 3:\n",
      "Train loss: 1.6832, Train acc: 0.2176\n",
      "Valid loss: 1.7328, Valid acc: 0.2028\n",
      "Epoch 4:\n",
      "Train loss: 1.6790, Train acc: 0.2189\n",
      "Valid loss: 1.6679, Valid acc: 0.2312\n",
      "Epoch 5:\n",
      "Train loss: 1.6827, Train acc: 0.2226\n",
      "Valid loss: 1.7285, Valid acc: 0.2202\n",
      "Epoch 6:\n",
      "Train loss: 1.6894, Train acc: 0.2267\n",
      "Valid loss: 1.6898, Valid acc: 0.2064\n",
      "Epoch 7:\n",
      "Train loss: 1.6811, Train acc: 0.2336\n",
      "Valid loss: 1.6790, Valid acc: 0.2083\n",
      "Epoch 8:\n",
      "Train loss: 1.6823, Train acc: 0.2228\n",
      "Valid loss: 1.7390, Valid acc: 0.2248\n",
      "Epoch 9:\n",
      "Train loss: 1.6806, Train acc: 0.2130\n",
      "Valid loss: 1.6961, Valid acc: 0.2312\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6684, Train acc: 0.2171\n",
      "Valid loss: 1.6677, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6508, Train acc: 0.2260\n",
      "Valid loss: 1.6364, Valid acc: 0.2450\n",
      "Epoch 3:\n",
      "Train loss: 1.6489, Train acc: 0.2263\n",
      "Valid loss: 1.6624, Valid acc: 0.2064\n",
      "Epoch 4:\n",
      "Train loss: 1.6435, Train acc: 0.2235\n",
      "Valid loss: 1.8386, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6518, Train acc: 0.2318\n",
      "Valid loss: 1.6559, Valid acc: 0.2587\n",
      "Epoch 6:\n",
      "Train loss: 1.6470, Train acc: 0.2419\n",
      "Valid loss: 1.6272, Valid acc: 0.2771\n",
      "Epoch 7:\n",
      "Train loss: 1.5727, Train acc: 0.3070\n",
      "Valid loss: 1.5057, Valid acc: 0.3615\n",
      "Epoch 8:\n",
      "Train loss: 1.4615, Train acc: 0.3673\n",
      "Valid loss: 1.4577, Valid acc: 0.3477\n",
      "Epoch 9:\n",
      "Train loss: 1.4245, Train acc: 0.3847\n",
      "Valid loss: 1.4690, Valid acc: 0.4018\n",
      "Epoch 10:\n",
      "Train loss: 1.4254, Train acc: 0.3877\n",
      "Valid loss: 1.4468, Valid acc: 0.3468\n",
      "Epoch 11:\n",
      "Train loss: 1.4251, Train acc: 0.3741\n",
      "Valid loss: 1.5525, Valid acc: 0.3349\n",
      "Epoch 12:\n",
      "Train loss: 1.4529, Train acc: 0.3434\n",
      "Valid loss: 1.4660, Valid acc: 0.2734\n",
      "Epoch 13:\n",
      "Train loss: 1.4437, Train acc: 0.3482\n",
      "Valid loss: 1.4362, Valid acc: 0.3661\n",
      "Epoch 14:\n",
      "Train loss: 1.4388, Train acc: 0.3544\n",
      "Valid loss: 1.4882, Valid acc: 0.3578\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6678, Train acc: 0.2244\n",
      "Valid loss: 1.6864, Valid acc: 0.2422\n",
      "Epoch 2:\n",
      "Train loss: 1.6551, Train acc: 0.2270\n",
      "Valid loss: 1.6724, Valid acc: 0.2064\n",
      "Epoch 3:\n",
      "Train loss: 1.6467, Train acc: 0.2352\n",
      "Valid loss: 1.6752, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6488, Train acc: 0.2380\n",
      "Valid loss: 1.6576, Valid acc: 0.2440\n",
      "Epoch 5:\n",
      "Train loss: 1.6470, Train acc: 0.2354\n",
      "Valid loss: 1.6790, Valid acc: 0.2413\n",
      "Epoch 6:\n",
      "Train loss: 1.6424, Train acc: 0.2437\n",
      "Valid loss: 1.6251, Valid acc: 0.3440\n",
      "Epoch 7:\n",
      "Train loss: 1.6497, Train acc: 0.2439\n",
      "Valid loss: 1.6072, Valid acc: 0.3312\n",
      "Epoch 8:\n",
      "Train loss: 1.5661, Train acc: 0.3414\n",
      "Valid loss: 1.5758, Valid acc: 0.2862\n",
      "Epoch 9:\n",
      "Train loss: 1.5056, Train acc: 0.3668\n",
      "Valid loss: 1.5404, Valid acc: 0.3899\n",
      "Epoch 10:\n",
      "Train loss: 1.5956, Train acc: 0.3143\n",
      "Valid loss: 1.5702, Valid acc: 0.3000\n",
      "Epoch 11:\n",
      "Train loss: 1.5668, Train acc: 0.3047\n",
      "Valid loss: 1.5379, Valid acc: 0.3138\n",
      "Epoch 12:\n",
      "Train loss: 1.5191, Train acc: 0.3530\n",
      "Valid loss: 1.4708, Valid acc: 0.3835\n",
      "Epoch 13:\n",
      "Train loss: 1.5311, Train acc: 0.3375\n",
      "Valid loss: 1.5883, Valid acc: 0.3541\n",
      "Epoch 14:\n",
      "Train loss: 1.5535, Train acc: 0.3377\n",
      "Valid loss: 1.6885, Valid acc: 0.1661\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.8380, Train acc: 0.1997\n",
      "Valid loss: 2.0056, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.7001, Train acc: 0.2265\n",
      "Valid loss: 1.7269, Valid acc: 0.1872\n",
      "Epoch 3:\n",
      "Train loss: 1.6793, Train acc: 0.2242\n",
      "Valid loss: 1.7567, Valid acc: 0.1954\n",
      "Epoch 4:\n",
      "Train loss: 1.6797, Train acc: 0.2109\n",
      "Valid loss: 1.7275, Valid acc: 0.1963\n",
      "Epoch 5:\n",
      "Train loss: 1.6639, Train acc: 0.2421\n",
      "Valid loss: 2.1197, Valid acc: 0.0835\n",
      "Epoch 6:\n",
      "Train loss: 1.7226, Train acc: 0.2231\n",
      "Valid loss: 1.6503, Valid acc: 0.2697\n",
      "Epoch 7:\n",
      "Train loss: 1.6656, Train acc: 0.2609\n",
      "Valid loss: 1.8171, Valid acc: 0.1569\n",
      "Epoch 8:\n",
      "Train loss: 1.5408, Train acc: 0.3320\n",
      "Valid loss: 1.5024, Valid acc: 0.3422\n",
      "Epoch 9:\n",
      "Train loss: 1.4897, Train acc: 0.3686\n",
      "Valid loss: 1.6677, Valid acc: 0.2927\n",
      "Epoch 10:\n",
      "Train loss: 1.4847, Train acc: 0.3707\n",
      "Valid loss: 1.4528, Valid acc: 0.3248\n",
      "Epoch 11:\n",
      "Train loss: 1.5006, Train acc: 0.3441\n",
      "Valid loss: 1.6076, Valid acc: 0.2615\n",
      "Epoch 12:\n",
      "Train loss: 1.4898, Train acc: 0.3377\n",
      "Valid loss: 1.5806, Valid acc: 0.2661\n",
      "Epoch 13:\n",
      "Train loss: 1.4834, Train acc: 0.3434\n",
      "Valid loss: 1.6287, Valid acc: 0.2633\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6604, Train acc: 0.2311\n",
      "Valid loss: 1.6868, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6563, Train acc: 0.2176\n",
      "Valid loss: 1.6631, Valid acc: 0.2440\n",
      "Epoch 3:\n",
      "Train loss: 1.6683, Train acc: 0.2348\n",
      "Valid loss: 1.6603, Valid acc: 0.2404\n",
      "Epoch 4:\n",
      "Train loss: 1.6529, Train acc: 0.2141\n",
      "Valid loss: 1.6593, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6495, Train acc: 0.2375\n",
      "Valid loss: 1.6593, Valid acc: 0.2477\n",
      "Epoch 6:\n",
      "Train loss: 1.6627, Train acc: 0.2432\n",
      "Valid loss: 1.6599, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6364, Train acc: 0.2733\n",
      "Valid loss: 1.5585, Valid acc: 0.2872\n",
      "Epoch 8:\n",
      "Train loss: 1.5020, Train acc: 0.3677\n",
      "Valid loss: 1.5852, Valid acc: 0.3229\n",
      "Epoch 9:\n",
      "Train loss: 1.5258, Train acc: 0.3572\n",
      "Valid loss: 1.5175, Valid acc: 0.3725\n",
      "Epoch 10:\n",
      "Train loss: 1.4969, Train acc: 0.3707\n",
      "Valid loss: 1.5024, Valid acc: 0.3798\n",
      "Epoch 11:\n",
      "Train loss: 1.5324, Train acc: 0.3645\n",
      "Valid loss: 1.4815, Valid acc: 0.3908\n",
      "Epoch 12:\n",
      "Train loss: 1.4656, Train acc: 0.3973\n",
      "Valid loss: 1.4860, Valid acc: 0.3018\n",
      "Epoch 13:\n",
      "Train loss: 1.4612, Train acc: 0.3884\n",
      "Valid loss: 1.4982, Valid acc: 0.3358\n",
      "Epoch 14:\n",
      "Train loss: 1.4396, Train acc: 0.3941\n",
      "Valid loss: 1.4644, Valid acc: 0.3872\n",
      "Epoch 15:\n",
      "Train loss: 1.4487, Train acc: 0.3909\n",
      "Valid loss: 1.4589, Valid acc: 0.3899\n",
      "Epoch 16:\n",
      "Train loss: 1.5885, Train acc: 0.2882\n",
      "Valid loss: 1.5961, Valid acc: 0.2661\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6748, Train acc: 0.2079\n",
      "Valid loss: 1.6639, Valid acc: 0.2440\n",
      "Epoch 2:\n",
      "Train loss: 1.6548, Train acc: 0.2235\n",
      "Valid loss: 1.6691, Valid acc: 0.2413\n",
      "Epoch 3:\n",
      "Train loss: 1.6541, Train acc: 0.2189\n",
      "Valid loss: 1.6670, Valid acc: 0.2349\n",
      "Epoch 4:\n",
      "Train loss: 1.6629, Train acc: 0.2272\n",
      "Valid loss: 1.6666, Valid acc: 0.2394\n",
      "Epoch 5:\n",
      "Train loss: 1.6462, Train acc: 0.2141\n",
      "Valid loss: 1.6521, Valid acc: 0.2495\n",
      "Epoch 6:\n",
      "Train loss: 1.6465, Train acc: 0.2352\n",
      "Valid loss: 1.6991, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6514, Train acc: 0.2382\n",
      "Valid loss: 1.6570, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6485, Train acc: 0.2274\n",
      "Valid loss: 1.6565, Valid acc: 0.2404\n",
      "Epoch 9:\n",
      "Train loss: 1.6487, Train acc: 0.2389\n",
      "Valid loss: 1.6519, Valid acc: 0.2404\n",
      "Epoch 10:\n",
      "Train loss: 1.6552, Train acc: 0.2377\n",
      "Valid loss: 1.6696, Valid acc: 0.2422\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.001, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.8050, Train acc: 0.2027\n",
      "Valid loss: 1.7307, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6735, Train acc: 0.2203\n",
      "Valid loss: 1.7417, Valid acc: 0.1440\n",
      "Epoch 3:\n",
      "Train loss: 1.6747, Train acc: 0.2116\n",
      "Valid loss: 1.7636, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.6693, Train acc: 0.2100\n",
      "Valid loss: 1.7349, Valid acc: 0.1440\n",
      "Epoch 5:\n",
      "Train loss: 1.6694, Train acc: 0.2254\n",
      "Valid loss: 1.7112, Valid acc: 0.2440\n",
      "Epoch 6:\n",
      "Train loss: 1.6600, Train acc: 0.2270\n",
      "Valid loss: 1.9000, Valid acc: 0.2440\n",
      "Epoch 7:\n",
      "Train loss: 1.6764, Train acc: 0.2196\n",
      "Valid loss: 1.7803, Valid acc: 0.2349\n",
      "Epoch 8:\n",
      "Train loss: 1.6657, Train acc: 0.2302\n",
      "Valid loss: 1.9173, Valid acc: 0.2349\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7488, Train acc: 0.2125\n",
      "Valid loss: 1.7188, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.7074, Train acc: 0.2185\n",
      "Valid loss: 1.6848, Valid acc: 0.2523\n",
      "Epoch 3:\n",
      "Train loss: 1.6813, Train acc: 0.2242\n",
      "Valid loss: 1.6637, Valid acc: 0.2404\n",
      "Epoch 4:\n",
      "Train loss: 1.6645, Train acc: 0.2283\n",
      "Valid loss: 1.6537, Valid acc: 0.2440\n",
      "Epoch 5:\n",
      "Train loss: 1.6563, Train acc: 0.2260\n",
      "Valid loss: 1.6493, Valid acc: 0.2110\n",
      "Epoch 6:\n",
      "Train loss: 1.6517, Train acc: 0.2299\n",
      "Valid loss: 1.6459, Valid acc: 0.2440\n",
      "Epoch 7:\n",
      "Train loss: 1.6501, Train acc: 0.2315\n",
      "Valid loss: 1.6468, Valid acc: 0.2394\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7599, Train acc: 0.2297\n",
      "Valid loss: 1.7332, Valid acc: 0.2422\n",
      "Epoch 2:\n",
      "Train loss: 1.7111, Train acc: 0.2348\n",
      "Valid loss: 1.6915, Valid acc: 0.2147\n",
      "Epoch 3:\n",
      "Train loss: 1.6780, Train acc: 0.2265\n",
      "Valid loss: 1.6680, Valid acc: 0.2147\n",
      "Epoch 4:\n",
      "Train loss: 1.6602, Train acc: 0.2283\n",
      "Valid loss: 1.6569, Valid acc: 0.2486\n",
      "Epoch 5:\n",
      "Train loss: 1.6530, Train acc: 0.2334\n",
      "Valid loss: 1.6500, Valid acc: 0.2477\n",
      "Epoch 6:\n",
      "Train loss: 1.6494, Train acc: 0.2327\n",
      "Valid loss: 1.6498, Valid acc: 0.2505\n",
      "Epoch 7:\n",
      "Train loss: 1.6476, Train acc: 0.2313\n",
      "Valid loss: 1.6499, Valid acc: 0.2119\n",
      "Epoch 8:\n",
      "Train loss: 1.6493, Train acc: 0.2203\n",
      "Valid loss: 1.6510, Valid acc: 0.2119\n",
      "Epoch 9:\n",
      "Train loss: 1.6482, Train acc: 0.2352\n",
      "Valid loss: 1.6475, Valid acc: 0.2477\n",
      "Epoch 10:\n",
      "Train loss: 1.6466, Train acc: 0.2286\n",
      "Valid loss: 1.6501, Valid acc: 0.2477\n",
      "Epoch 11:\n",
      "Train loss: 1.6488, Train acc: 0.2235\n",
      "Valid loss: 1.6485, Valid acc: 0.2505\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7670, Train acc: 0.2077\n",
      "Valid loss: 1.7380, Valid acc: 0.2239\n",
      "Epoch 2:\n",
      "Train loss: 1.7133, Train acc: 0.2345\n",
      "Valid loss: 1.6893, Valid acc: 0.2413\n",
      "Epoch 3:\n",
      "Train loss: 1.6760, Train acc: 0.2302\n",
      "Valid loss: 1.6588, Valid acc: 0.2431\n",
      "Epoch 4:\n",
      "Train loss: 1.6568, Train acc: 0.2304\n",
      "Valid loss: 1.6501, Valid acc: 0.2440\n",
      "Epoch 5:\n",
      "Train loss: 1.6503, Train acc: 0.2336\n",
      "Valid loss: 1.6501, Valid acc: 0.2450\n",
      "Epoch 6:\n",
      "Train loss: 1.6477, Train acc: 0.2293\n",
      "Valid loss: 1.6503, Valid acc: 0.2431\n",
      "Epoch 7:\n",
      "Train loss: 1.6472, Train acc: 0.2315\n",
      "Valid loss: 1.6493, Valid acc: 0.2440\n",
      "Epoch 8:\n",
      "Train loss: 1.6471, Train acc: 0.2272\n",
      "Valid loss: 1.6525, Valid acc: 0.2046\n",
      "Epoch 9:\n",
      "Train loss: 1.6467, Train acc: 0.2304\n",
      "Valid loss: 1.6505, Valid acc: 0.2413\n",
      "Epoch 10:\n",
      "Train loss: 1.6479, Train acc: 0.2329\n",
      "Valid loss: 1.6514, Valid acc: 0.2404\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7914, Train acc: 0.2258\n",
      "Valid loss: 1.7667, Valid acc: 0.2404\n",
      "Epoch 2:\n",
      "Train loss: 1.7523, Train acc: 0.2293\n",
      "Valid loss: 1.7338, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.7222, Train acc: 0.2304\n",
      "Valid loss: 1.7087, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6999, Train acc: 0.2311\n",
      "Valid loss: 1.6898, Valid acc: 0.2477\n",
      "Epoch 5:\n",
      "Train loss: 1.6849, Train acc: 0.2329\n",
      "Valid loss: 1.6770, Valid acc: 0.2450\n",
      "Epoch 6:\n",
      "Train loss: 1.6737, Train acc: 0.2304\n",
      "Valid loss: 1.6685, Valid acc: 0.2431\n",
      "Epoch 7:\n",
      "Train loss: 1.6661, Train acc: 0.2295\n",
      "Valid loss: 1.6625, Valid acc: 0.2440\n",
      "Epoch 8:\n",
      "Train loss: 1.6597, Train acc: 0.2315\n",
      "Valid loss: 1.6582, Valid acc: 0.2459\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7683, Train acc: 0.1836\n",
      "Valid loss: 1.7559, Valid acc: 0.1972\n",
      "Epoch 2:\n",
      "Train loss: 1.7425, Train acc: 0.2199\n",
      "Valid loss: 1.7302, Valid acc: 0.2009\n",
      "Epoch 3:\n",
      "Train loss: 1.7206, Train acc: 0.2187\n",
      "Valid loss: 1.7087, Valid acc: 0.2028\n",
      "Epoch 4:\n",
      "Train loss: 1.7016, Train acc: 0.2192\n",
      "Valid loss: 1.6899, Valid acc: 0.2028\n",
      "Epoch 5:\n",
      "Train loss: 1.6863, Train acc: 0.2240\n",
      "Valid loss: 1.6755, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6760, Train acc: 0.2224\n",
      "Valid loss: 1.6643, Valid acc: 0.2073\n",
      "Epoch 7:\n",
      "Train loss: 1.6653, Train acc: 0.2311\n",
      "Valid loss: 1.6562, Valid acc: 0.2312\n",
      "Epoch 8:\n",
      "Train loss: 1.6601, Train acc: 0.2231\n",
      "Valid loss: 1.6520, Valid acc: 0.2073\n",
      "Epoch 9:\n",
      "Train loss: 1.6576, Train acc: 0.2260\n",
      "Valid loss: 1.6482, Valid acc: 0.2459\n",
      "Epoch 10:\n",
      "Train loss: 1.6581, Train acc: 0.2235\n",
      "Valid loss: 1.6469, Valid acc: 0.2321\n",
      "Epoch 11:\n",
      "Train loss: 1.6524, Train acc: 0.2260\n",
      "Valid loss: 1.6458, Valid acc: 0.2073\n",
      "Epoch 12:\n",
      "Train loss: 1.6510, Train acc: 0.2221\n",
      "Valid loss: 1.6450, Valid acc: 0.2055\n",
      "Epoch 13:\n",
      "Train loss: 1.6492, Train acc: 0.2297\n",
      "Valid loss: 1.6463, Valid acc: 0.2073\n",
      "Epoch 14:\n",
      "Train loss: 1.6491, Train acc: 0.2235\n",
      "Valid loss: 1.6459, Valid acc: 0.2073\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7809, Train acc: 0.2212\n",
      "Valid loss: 1.7663, Valid acc: 0.2055\n",
      "Epoch 2:\n",
      "Train loss: 1.7497, Train acc: 0.2263\n",
      "Valid loss: 1.7368, Valid acc: 0.2055\n",
      "Epoch 3:\n",
      "Train loss: 1.7240, Train acc: 0.2315\n",
      "Valid loss: 1.7112, Valid acc: 0.2413\n",
      "Epoch 4:\n",
      "Train loss: 1.6991, Train acc: 0.2322\n",
      "Valid loss: 1.6883, Valid acc: 0.2394\n",
      "Epoch 5:\n",
      "Train loss: 1.6802, Train acc: 0.2325\n",
      "Valid loss: 1.6713, Valid acc: 0.2413\n",
      "Epoch 6:\n",
      "Train loss: 1.6660, Train acc: 0.2318\n",
      "Valid loss: 1.6611, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.6567, Train acc: 0.2304\n",
      "Valid loss: 1.6564, Valid acc: 0.2028\n",
      "Epoch 8:\n",
      "Train loss: 1.6524, Train acc: 0.2288\n",
      "Valid loss: 1.6508, Valid acc: 0.2394\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7909, Train acc: 0.2233\n",
      "Valid loss: 1.7763, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.7724, Train acc: 0.2231\n",
      "Valid loss: 1.7563, Valid acc: 0.2431\n",
      "Epoch 3:\n",
      "Train loss: 1.7507, Train acc: 0.2244\n",
      "Valid loss: 1.7379, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.7352, Train acc: 0.2242\n",
      "Valid loss: 1.7220, Valid acc: 0.2431\n",
      "Epoch 5:\n",
      "Train loss: 1.7190, Train acc: 0.2192\n",
      "Valid loss: 1.7085, Valid acc: 0.2431\n",
      "Epoch 6:\n",
      "Train loss: 1.7060, Train acc: 0.2137\n",
      "Valid loss: 1.6972, Valid acc: 0.1982\n",
      "Epoch 7:\n",
      "Train loss: 1.6973, Train acc: 0.2235\n",
      "Valid loss: 1.6880, Valid acc: 0.2000\n",
      "Epoch 8:\n",
      "Train loss: 1.6883, Train acc: 0.2231\n",
      "Valid loss: 1.6806, Valid acc: 0.1991\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.7764, Train acc: 0.2249\n",
      "Valid loss: 1.7670, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.7609, Train acc: 0.2290\n",
      "Valid loss: 1.7531, Valid acc: 0.2450\n",
      "Epoch 3:\n",
      "Train loss: 1.7479, Train acc: 0.2299\n",
      "Valid loss: 1.7411, Valid acc: 0.2468\n",
      "Epoch 4:\n",
      "Train loss: 1.7376, Train acc: 0.2249\n",
      "Valid loss: 1.7308, Valid acc: 0.2055\n",
      "Epoch 5:\n",
      "Train loss: 1.7282, Train acc: 0.2231\n",
      "Valid loss: 1.7213, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.7195, Train acc: 0.2254\n",
      "Valid loss: 1.7127, Valid acc: 0.2037\n",
      "Epoch 7:\n",
      "Train loss: 1.7090, Train acc: 0.2254\n",
      "Valid loss: 1.7048, Valid acc: 0.2064\n",
      "Epoch 8:\n",
      "Train loss: 1.7036, Train acc: 0.2276\n",
      "Valid loss: 1.6975, Valid acc: 0.2055\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.sgd.SGD'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7828, Train acc: 0.1845\n",
      "Valid loss: 1.7735, Valid acc: 0.2422\n",
      "Epoch 2:\n",
      "Train loss: 1.7651, Train acc: 0.2244\n",
      "Valid loss: 1.7583, Valid acc: 0.2422\n",
      "Epoch 3:\n",
      "Train loss: 1.7525, Train acc: 0.2254\n",
      "Valid loss: 1.7460, Valid acc: 0.2422\n",
      "Epoch 4:\n",
      "Train loss: 1.7423, Train acc: 0.2247\n",
      "Valid loss: 1.7347, Valid acc: 0.2422\n",
      "Epoch 5:\n",
      "Train loss: 1.7306, Train acc: 0.2247\n",
      "Valid loss: 1.7243, Valid acc: 0.2431\n",
      "Epoch 6:\n",
      "Train loss: 1.7214, Train acc: 0.2244\n",
      "Valid loss: 1.7147, Valid acc: 0.2450\n",
      "Epoch 7:\n",
      "Train loss: 1.7110, Train acc: 0.2256\n",
      "Valid loss: 1.7054, Valid acc: 0.2468\n",
      "Epoch 8:\n",
      "Train loss: 1.7023, Train acc: 0.2276\n",
      "Valid loss: 1.6968, Valid acc: 0.2459\n",
      "Epoch 9:\n",
      "Train loss: 1.6961, Train acc: 0.2276\n",
      "Valid loss: 1.6893, Valid acc: 0.2459\n",
      "Epoch 10:\n",
      "Train loss: 1.6867, Train acc: 0.2295\n",
      "Valid loss: 1.6821, Valid acc: 0.2459\n",
      "Epoch 11:\n",
      "Train loss: 1.6852, Train acc: 0.2281\n",
      "Valid loss: 1.6764, Valid acc: 0.2468\n",
      "Epoch 12:\n",
      "Train loss: 1.6768, Train acc: 0.2290\n",
      "Valid loss: 1.6709, Valid acc: 0.2468\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6559, Train acc: 0.2251\n",
      "Valid loss: 1.6428, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.6458, Train acc: 0.2403\n",
      "Valid loss: 1.6448, Valid acc: 0.2422\n",
      "Epoch 3:\n",
      "Train loss: 1.6472, Train acc: 0.2235\n",
      "Valid loss: 1.6482, Valid acc: 0.2321\n",
      "Epoch 4:\n",
      "Train loss: 1.6436, Train acc: 0.2306\n",
      "Valid loss: 1.6588, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6109, Train acc: 0.2735\n",
      "Valid loss: 1.4741, Valid acc: 0.3798\n",
      "Epoch 6:\n",
      "Train loss: 1.4459, Train acc: 0.3865\n",
      "Valid loss: 1.5366, Valid acc: 0.3835\n",
      "Epoch 7:\n",
      "Train loss: 1.3998, Train acc: 0.3895\n",
      "Valid loss: 1.3903, Valid acc: 0.4165\n",
      "Epoch 8:\n",
      "Train loss: 1.3288, Train acc: 0.4278\n",
      "Valid loss: 1.3334, Valid acc: 0.4477\n",
      "Epoch 9:\n",
      "Train loss: 1.2412, Train acc: 0.4764\n",
      "Valid loss: 1.2512, Valid acc: 0.4560\n",
      "Epoch 10:\n",
      "Train loss: 1.1310, Train acc: 0.5287\n",
      "Valid loss: 1.1963, Valid acc: 0.4963\n",
      "Epoch 11:\n",
      "Train loss: 1.0413, Train acc: 0.5750\n",
      "Valid loss: 1.1844, Valid acc: 0.4734\n",
      "Epoch 12:\n",
      "Train loss: 0.9697, Train acc: 0.6041\n",
      "Valid loss: 1.5719, Valid acc: 0.4183\n",
      "Epoch 13:\n",
      "Train loss: 0.9208, Train acc: 0.6396\n",
      "Valid loss: 1.0515, Valid acc: 0.5725\n",
      "Epoch 14:\n",
      "Train loss: 0.8617, Train acc: 0.6637\n",
      "Valid loss: 1.0398, Valid acc: 0.5835\n",
      "Epoch 15:\n",
      "Train loss: 0.8334, Train acc: 0.6829\n",
      "Valid loss: 1.0214, Valid acc: 0.5835\n",
      "Epoch 16:\n",
      "Train loss: 0.7796, Train acc: 0.7024\n",
      "Valid loss: 0.9902, Valid acc: 0.5936\n",
      "Epoch 17:\n",
      "Train loss: 0.7408, Train acc: 0.7141\n",
      "Valid loss: 1.0047, Valid acc: 0.5899\n",
      "Epoch 18:\n",
      "Train loss: 0.7228, Train acc: 0.7199\n",
      "Valid loss: 0.9944, Valid acc: 0.6083\n",
      "Epoch 19:\n",
      "Train loss: 0.6867, Train acc: 0.7366\n",
      "Valid loss: 0.9495, Valid acc: 0.6193\n",
      "Epoch 20:\n",
      "Train loss: 0.6590, Train acc: 0.7414\n",
      "Valid loss: 0.9401, Valid acc: 0.6266\n",
      "Epoch 21:\n",
      "Train loss: 0.6392, Train acc: 0.7469\n",
      "Valid loss: 0.9349, Valid acc: 0.6266\n",
      "Epoch 22:\n",
      "Train loss: 0.6242, Train acc: 0.7536\n",
      "Valid loss: 0.9568, Valid acc: 0.6183\n",
      "Epoch 23:\n",
      "Train loss: 0.6103, Train acc: 0.7565\n",
      "Valid loss: 0.9298, Valid acc: 0.6312\n",
      "Epoch 24:\n",
      "Train loss: 0.5869, Train acc: 0.7675\n",
      "Valid loss: 1.0101, Valid acc: 0.6211\n",
      "Epoch 25:\n",
      "Train loss: 0.5771, Train acc: 0.7685\n",
      "Valid loss: 1.0345, Valid acc: 0.6083\n",
      "Epoch 26:\n",
      "Train loss: 0.5631, Train acc: 0.7744\n",
      "Valid loss: 0.9367, Valid acc: 0.6312\n",
      "Epoch 27:\n",
      "Train loss: 0.5399, Train acc: 0.7822\n",
      "Valid loss: 0.9399, Valid acc: 0.6385\n",
      "Epoch 28:\n",
      "Train loss: 0.5295, Train acc: 0.7840\n",
      "Valid loss: 1.1839, Valid acc: 0.5798\n",
      "Epoch 29:\n",
      "Train loss: 0.5221, Train acc: 0.7856\n",
      "Valid loss: 0.9550, Valid acc: 0.6358\n",
      "Epoch 30:\n",
      "Train loss: 0.5198, Train acc: 0.7856\n",
      "Valid loss: 0.9390, Valid acc: 0.6450\n",
      "Epoch 31:\n",
      "Train loss: 0.5167, Train acc: 0.7843\n",
      "Valid loss: 0.9609, Valid acc: 0.6385\n",
      "Epoch 32:\n",
      "Train loss: 0.5040, Train acc: 0.7895\n",
      "Valid loss: 0.9753, Valid acc: 0.6349\n",
      "Epoch 33:\n",
      "Train loss: 0.4861, Train acc: 0.7946\n",
      "Valid loss: 0.9725, Valid acc: 0.6394\n",
      "Epoch 34:\n",
      "Train loss: 0.4785, Train acc: 0.7957\n",
      "Valid loss: 0.9752, Valid acc: 0.6404\n",
      "Epoch 35:\n",
      "Train loss: 0.4758, Train acc: 0.7976\n",
      "Valid loss: 0.9758, Valid acc: 0.6431\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6598, Train acc: 0.2295\n",
      "Valid loss: 1.6467, Valid acc: 0.2587\n",
      "Epoch 2:\n",
      "Train loss: 1.5957, Train acc: 0.2921\n",
      "Valid loss: 1.5101, Valid acc: 0.3945\n",
      "Epoch 3:\n",
      "Train loss: 1.6519, Train acc: 0.2293\n",
      "Valid loss: 1.6734, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6525, Train acc: 0.2238\n",
      "Valid loss: 1.6562, Valid acc: 0.2404\n",
      "Epoch 5:\n",
      "Train loss: 1.6519, Train acc: 0.2192\n",
      "Valid loss: 1.6462, Valid acc: 0.2459\n",
      "Epoch 6:\n",
      "Train loss: 1.6501, Train acc: 0.2288\n",
      "Valid loss: 1.6456, Valid acc: 0.2037\n",
      "Epoch 7:\n",
      "Train loss: 1.6334, Train acc: 0.2588\n",
      "Valid loss: 1.5637, Valid acc: 0.3679\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6672, Train acc: 0.2290\n",
      "Valid loss: 1.6725, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6489, Train acc: 0.2274\n",
      "Valid loss: 1.6522, Valid acc: 0.2633\n",
      "Epoch 3:\n",
      "Train loss: 1.6458, Train acc: 0.2400\n",
      "Valid loss: 1.6482, Valid acc: 0.2624\n",
      "Epoch 4:\n",
      "Train loss: 1.6279, Train acc: 0.2691\n",
      "Valid loss: 1.6616, Valid acc: 0.3312\n",
      "Epoch 5:\n",
      "Train loss: 1.4932, Train acc: 0.3668\n",
      "Valid loss: 1.5378, Valid acc: 0.3532\n",
      "Epoch 6:\n",
      "Train loss: 1.4972, Train acc: 0.3654\n",
      "Valid loss: 1.7144, Valid acc: 0.2394\n",
      "Epoch 7:\n",
      "Train loss: 1.4774, Train acc: 0.3808\n",
      "Valid loss: 1.3929, Valid acc: 0.4156\n",
      "Epoch 8:\n",
      "Train loss: 1.4308, Train acc: 0.3966\n",
      "Valid loss: 1.4535, Valid acc: 0.3853\n",
      "Epoch 9:\n",
      "Train loss: 1.4591, Train acc: 0.3888\n",
      "Valid loss: 1.4623, Valid acc: 0.3817\n",
      "Epoch 10:\n",
      "Train loss: 1.4470, Train acc: 0.3847\n",
      "Valid loss: 1.4256, Valid acc: 0.3890\n",
      "Epoch 11:\n",
      "Train loss: 1.4497, Train acc: 0.3790\n",
      "Valid loss: 1.4500, Valid acc: 0.3954\n",
      "Epoch 12:\n",
      "Train loss: 1.4597, Train acc: 0.3874\n",
      "Valid loss: 1.4493, Valid acc: 0.3954\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6592, Train acc: 0.2263\n",
      "Valid loss: 1.6653, Valid acc: 0.1578\n",
      "Epoch 2:\n",
      "Train loss: 1.6527, Train acc: 0.2182\n",
      "Valid loss: 1.6574, Valid acc: 0.2477\n",
      "Epoch 3:\n",
      "Train loss: 1.6479, Train acc: 0.2306\n",
      "Valid loss: 1.6473, Valid acc: 0.2505\n",
      "Epoch 4:\n",
      "Train loss: 1.6495, Train acc: 0.2274\n",
      "Valid loss: 1.6473, Valid acc: 0.2450\n",
      "Epoch 5:\n",
      "Train loss: 1.6470, Train acc: 0.2293\n",
      "Valid loss: 1.6471, Valid acc: 0.2459\n",
      "Epoch 6:\n",
      "Train loss: 1.6451, Train acc: 0.2361\n",
      "Valid loss: 1.6351, Valid acc: 0.2670\n",
      "Epoch 7:\n",
      "Train loss: 1.6428, Train acc: 0.2416\n",
      "Valid loss: 1.6418, Valid acc: 0.2651\n",
      "Epoch 8:\n",
      "Train loss: 1.6414, Train acc: 0.2446\n",
      "Valid loss: 1.6490, Valid acc: 0.2330\n",
      "Epoch 9:\n",
      "Train loss: 1.5360, Train acc: 0.3265\n",
      "Valid loss: 1.4540, Valid acc: 0.3862\n",
      "Epoch 10:\n",
      "Train loss: 1.4380, Train acc: 0.3783\n",
      "Valid loss: 1.4184, Valid acc: 0.3890\n",
      "Epoch 11:\n",
      "Train loss: 1.3768, Train acc: 0.4030\n",
      "Valid loss: 1.4115, Valid acc: 0.3899\n",
      "Epoch 12:\n",
      "Train loss: 1.3610, Train acc: 0.4049\n",
      "Valid loss: 1.3814, Valid acc: 0.4110\n",
      "Epoch 13:\n",
      "Train loss: 1.3283, Train acc: 0.4159\n",
      "Valid loss: 1.3646, Valid acc: 0.4174\n",
      "Epoch 14:\n",
      "Train loss: 1.2782, Train acc: 0.4434\n",
      "Valid loss: 1.3932, Valid acc: 0.4349\n",
      "Epoch 15:\n",
      "Train loss: 1.2000, Train acc: 0.4736\n",
      "Valid loss: 1.4011, Valid acc: 0.4385\n",
      "Epoch 16:\n",
      "Train loss: 1.1369, Train acc: 0.5009\n",
      "Valid loss: 1.3122, Valid acc: 0.4734\n",
      "Epoch 17:\n",
      "Train loss: 1.0778, Train acc: 0.5319\n",
      "Valid loss: 1.2290, Valid acc: 0.5092\n",
      "Epoch 18:\n",
      "Train loss: 1.0393, Train acc: 0.5651\n",
      "Valid loss: 1.1524, Valid acc: 0.5294\n",
      "Epoch 19:\n",
      "Train loss: 0.9806, Train acc: 0.5908\n",
      "Valid loss: 1.1094, Valid acc: 0.5615\n",
      "Epoch 20:\n",
      "Train loss: 0.9643, Train acc: 0.6077\n",
      "Valid loss: 1.0832, Valid acc: 0.5826\n",
      "Epoch 21:\n",
      "Train loss: 0.9125, Train acc: 0.6458\n",
      "Valid loss: 1.1735, Valid acc: 0.5055\n",
      "Epoch 22:\n",
      "Train loss: 0.8916, Train acc: 0.6337\n",
      "Valid loss: 0.9970, Valid acc: 0.5954\n",
      "Epoch 23:\n",
      "Train loss: 0.8469, Train acc: 0.6678\n",
      "Valid loss: 1.2832, Valid acc: 0.4725\n",
      "Epoch 24:\n",
      "Train loss: 0.8033, Train acc: 0.6829\n",
      "Valid loss: 0.9513, Valid acc: 0.6064\n",
      "Epoch 25:\n",
      "Train loss: 0.7881, Train acc: 0.6809\n",
      "Valid loss: 1.2502, Valid acc: 0.4991\n",
      "Epoch 26:\n",
      "Train loss: 0.7459, Train acc: 0.6965\n",
      "Valid loss: 1.0143, Valid acc: 0.5972\n",
      "Epoch 27:\n",
      "Train loss: 0.7345, Train acc: 0.7077\n",
      "Valid loss: 0.9107, Valid acc: 0.6413\n",
      "Epoch 28:\n",
      "Train loss: 0.7003, Train acc: 0.7235\n",
      "Valid loss: 1.0071, Valid acc: 0.5872\n",
      "Epoch 29:\n",
      "Train loss: 0.6636, Train acc: 0.7403\n",
      "Valid loss: 0.8961, Valid acc: 0.6229\n",
      "Epoch 30:\n",
      "Train loss: 0.6521, Train acc: 0.7419\n",
      "Valid loss: 0.9958, Valid acc: 0.5963\n",
      "Epoch 31:\n",
      "Train loss: 0.6321, Train acc: 0.7481\n",
      "Valid loss: 1.0807, Valid acc: 0.5532\n",
      "Epoch 32:\n",
      "Train loss: 0.6090, Train acc: 0.7517\n",
      "Valid loss: 0.8973, Valid acc: 0.6294\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6606, Train acc: 0.2352\n",
      "Valid loss: 1.6688, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6502, Train acc: 0.2375\n",
      "Valid loss: 1.6614, Valid acc: 0.1853\n",
      "Epoch 3:\n",
      "Train loss: 1.6487, Train acc: 0.2345\n",
      "Valid loss: 1.6458, Valid acc: 0.2587\n",
      "Epoch 4:\n",
      "Train loss: 1.6161, Train acc: 0.2882\n",
      "Valid loss: 1.5470, Valid acc: 0.3596\n",
      "Epoch 5:\n",
      "Train loss: 1.4911, Train acc: 0.3783\n",
      "Valid loss: 1.5797, Valid acc: 0.3495\n",
      "Epoch 6:\n",
      "Train loss: 1.5195, Train acc: 0.3508\n",
      "Valid loss: 1.4826, Valid acc: 0.3908\n",
      "Epoch 7:\n",
      "Train loss: 1.4712, Train acc: 0.3870\n",
      "Valid loss: 1.5553, Valid acc: 0.3615\n",
      "Epoch 8:\n",
      "Train loss: 1.5109, Train acc: 0.3533\n",
      "Valid loss: 1.5240, Valid acc: 0.3321\n",
      "Epoch 9:\n",
      "Train loss: 1.4902, Train acc: 0.3576\n",
      "Valid loss: 1.5113, Valid acc: 0.3642\n",
      "Epoch 10:\n",
      "Train loss: 1.4758, Train acc: 0.3684\n",
      "Valid loss: 1.5192, Valid acc: 0.3321\n",
      "Epoch 11:\n",
      "Train loss: 1.4970, Train acc: 0.3739\n",
      "Valid loss: 1.5324, Valid acc: 0.3697\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6668, Train acc: 0.2302\n",
      "Valid loss: 1.7081, Valid acc: 0.2028\n",
      "Epoch 2:\n",
      "Train loss: 1.6562, Train acc: 0.2299\n",
      "Valid loss: 1.6953, Valid acc: 0.2330\n",
      "Epoch 3:\n",
      "Train loss: 1.6578, Train acc: 0.2235\n",
      "Valid loss: 1.6523, Valid acc: 0.2422\n",
      "Epoch 4:\n",
      "Train loss: 1.6480, Train acc: 0.2276\n",
      "Valid loss: 1.6424, Valid acc: 0.2477\n",
      "Epoch 5:\n",
      "Train loss: 1.6415, Train acc: 0.2377\n",
      "Valid loss: 1.6559, Valid acc: 0.2477\n",
      "Epoch 6:\n",
      "Train loss: 1.6461, Train acc: 0.2350\n",
      "Valid loss: 1.6533, Valid acc: 0.2413\n",
      "Epoch 7:\n",
      "Train loss: 1.6397, Train acc: 0.2600\n",
      "Valid loss: 1.5975, Valid acc: 0.3294\n",
      "Epoch 8:\n",
      "Train loss: 1.6435, Train acc: 0.2524\n",
      "Valid loss: 1.6849, Valid acc: 0.2459\n",
      "Epoch 9:\n",
      "Train loss: 1.6523, Train acc: 0.2293\n",
      "Valid loss: 1.6583, Valid acc: 0.2037\n",
      "Epoch 10:\n",
      "Train loss: 1.6506, Train acc: 0.2221\n",
      "Valid loss: 1.6532, Valid acc: 0.2009\n",
      "Epoch 11:\n",
      "Train loss: 1.6520, Train acc: 0.2176\n",
      "Valid loss: 1.6479, Valid acc: 0.2413\n",
      "Epoch 12:\n",
      "Train loss: 1.6296, Train acc: 0.2591\n",
      "Valid loss: 1.5367, Valid acc: 0.3706\n",
      "Epoch 13:\n",
      "Train loss: 1.5384, Train acc: 0.3517\n",
      "Valid loss: 1.5460, Valid acc: 0.3193\n",
      "Epoch 14:\n",
      "Train loss: 1.6474, Train acc: 0.2384\n",
      "Valid loss: 1.6408, Valid acc: 0.2422\n",
      "Epoch 15:\n",
      "Train loss: 1.6512, Train acc: 0.2313\n",
      "Valid loss: 1.6552, Valid acc: 0.2440\n",
      "Epoch 16:\n",
      "Train loss: 1.6509, Train acc: 0.2295\n",
      "Valid loss: 1.6567, Valid acc: 0.2440\n",
      "Epoch 17:\n",
      "Train loss: 1.6501, Train acc: 0.2295\n",
      "Valid loss: 1.6527, Valid acc: 0.2459\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6615, Train acc: 0.2219\n",
      "Valid loss: 1.6867, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6491, Train acc: 0.2297\n",
      "Valid loss: 1.6602, Valid acc: 0.2376\n",
      "Epoch 3:\n",
      "Train loss: 1.6508, Train acc: 0.2228\n",
      "Valid loss: 1.6548, Valid acc: 0.2037\n",
      "Epoch 4:\n",
      "Train loss: 1.6604, Train acc: 0.2208\n",
      "Valid loss: 1.6569, Valid acc: 0.2459\n",
      "Epoch 5:\n",
      "Train loss: 1.6551, Train acc: 0.2196\n",
      "Valid loss: 1.6537, Valid acc: 0.2468\n",
      "Epoch 6:\n",
      "Train loss: 1.6487, Train acc: 0.2306\n",
      "Valid loss: 1.6679, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.6489, Train acc: 0.2228\n",
      "Valid loss: 1.6511, Valid acc: 0.2385\n",
      "Epoch 8:\n",
      "Train loss: 1.6547, Train acc: 0.2244\n",
      "Valid loss: 1.6502, Valid acc: 0.2055\n",
      "Epoch 9:\n",
      "Train loss: 1.6460, Train acc: 0.2254\n",
      "Valid loss: 1.6577, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.6449, Train acc: 0.2293\n",
      "Valid loss: 1.6562, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6693, Train acc: 0.2176\n",
      "Valid loss: 1.6675, Valid acc: 0.2376\n",
      "Epoch 2:\n",
      "Train loss: 1.6531, Train acc: 0.2254\n",
      "Valid loss: 1.6554, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6537, Train acc: 0.2299\n",
      "Valid loss: 1.6550, Valid acc: 0.2450\n",
      "Epoch 4:\n",
      "Train loss: 1.6483, Train acc: 0.2244\n",
      "Valid loss: 1.6522, Valid acc: 0.2385\n",
      "Epoch 5:\n",
      "Train loss: 1.6498, Train acc: 0.2260\n",
      "Valid loss: 1.6524, Valid acc: 0.2037\n",
      "Epoch 6:\n",
      "Train loss: 1.6475, Train acc: 0.2267\n",
      "Valid loss: 1.6664, Valid acc: 0.2028\n",
      "Epoch 7:\n",
      "Train loss: 1.6504, Train acc: 0.2272\n",
      "Valid loss: 1.6555, Valid acc: 0.2477\n",
      "Epoch 8:\n",
      "Train loss: 1.6553, Train acc: 0.2254\n",
      "Valid loss: 1.6541, Valid acc: 0.2486\n",
      "Epoch 9:\n",
      "Train loss: 1.6505, Train acc: 0.2329\n",
      "Valid loss: 1.6452, Valid acc: 0.2587\n",
      "Epoch 10:\n",
      "Train loss: 1.6475, Train acc: 0.2540\n",
      "Valid loss: 1.6733, Valid acc: 0.2046\n",
      "Epoch 11:\n",
      "Train loss: 1.6454, Train acc: 0.2267\n",
      "Valid loss: 1.6694, Valid acc: 0.2046\n",
      "Epoch 12:\n",
      "Train loss: 1.6160, Train acc: 0.2994\n",
      "Valid loss: 1.6622, Valid acc: 0.2046\n",
      "Epoch 13:\n",
      "Train loss: 1.5249, Train acc: 0.3379\n",
      "Valid loss: 1.5207, Valid acc: 0.3798\n",
      "Epoch 14:\n",
      "Train loss: 1.4485, Train acc: 0.3597\n",
      "Valid loss: 1.4507, Valid acc: 0.3569\n",
      "Epoch 15:\n",
      "Train loss: 1.4196, Train acc: 0.3735\n",
      "Valid loss: 1.4261, Valid acc: 0.3954\n",
      "Epoch 16:\n",
      "Train loss: 1.4415, Train acc: 0.3929\n",
      "Valid loss: 1.8413, Valid acc: 0.2743\n",
      "Epoch 17:\n",
      "Train loss: 1.5456, Train acc: 0.3540\n",
      "Valid loss: 1.4523, Valid acc: 0.3963\n",
      "Epoch 18:\n",
      "Train loss: 1.4410, Train acc: 0.3906\n",
      "Valid loss: 1.4893, Valid acc: 0.3817\n",
      "Epoch 19:\n",
      "Train loss: 1.4444, Train acc: 0.3751\n",
      "Valid loss: 1.4588, Valid acc: 0.3826\n",
      "Epoch 20:\n",
      "Train loss: 1.6538, Train acc: 0.2758\n",
      "Valid loss: 1.6581, Valid acc: 0.2486\n",
      "Epoch 21:\n",
      "Train loss: 1.6521, Train acc: 0.2364\n",
      "Valid loss: 1.6549, Valid acc: 0.2486\n",
      "Epoch 22:\n",
      "Train loss: 1.6501, Train acc: 0.2313\n",
      "Valid loss: 1.6556, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adagrad.Adagrad'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.6938, Train acc: 0.2116\n",
      "Valid loss: 1.6825, Valid acc: 0.1560\n",
      "Epoch 2:\n",
      "Train loss: 1.6568, Train acc: 0.2238\n",
      "Valid loss: 1.6660, Valid acc: 0.2349\n",
      "Epoch 3:\n",
      "Train loss: 1.6510, Train acc: 0.2247\n",
      "Valid loss: 1.6785, Valid acc: 0.1450\n",
      "Epoch 4:\n",
      "Train loss: 1.6467, Train acc: 0.2297\n",
      "Valid loss: 1.7068, Valid acc: 0.1495\n",
      "Epoch 5:\n",
      "Train loss: 1.6632, Train acc: 0.2219\n",
      "Valid loss: 1.6689, Valid acc: 0.1982\n",
      "Epoch 6:\n",
      "Train loss: 1.6600, Train acc: 0.2338\n",
      "Valid loss: 1.6612, Valid acc: 0.2771\n",
      "Epoch 7:\n",
      "Train loss: 1.6537, Train acc: 0.2483\n",
      "Valid loss: 1.6498, Valid acc: 0.2459\n",
      "Epoch 8:\n",
      "Train loss: 1.6466, Train acc: 0.2205\n",
      "Valid loss: 1.6749, Valid acc: 0.2385\n",
      "Epoch 9:\n",
      "Train loss: 1.6437, Train acc: 0.2501\n",
      "Valid loss: 1.7439, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.6526, Train acc: 0.2416\n",
      "Valid loss: 1.6485, Valid acc: 0.2550\n",
      "Epoch 11:\n",
      "Train loss: 1.6544, Train acc: 0.2384\n",
      "Valid loss: 1.7039, Valid acc: 0.2413\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6701, Train acc: 0.2256\n",
      "Valid loss: 1.6569, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.6565, Train acc: 0.2215\n",
      "Valid loss: 1.6475, Valid acc: 0.2486\n",
      "Epoch 3:\n",
      "Train loss: 1.6528, Train acc: 0.2288\n",
      "Valid loss: 1.6532, Valid acc: 0.2312\n",
      "Epoch 4:\n",
      "Train loss: 1.6658, Train acc: 0.2219\n",
      "Valid loss: 1.6590, Valid acc: 0.2009\n",
      "Epoch 5:\n",
      "Train loss: 1.6857, Train acc: 0.2178\n",
      "Valid loss: 1.7389, Valid acc: 0.1569\n",
      "Epoch 6:\n",
      "Train loss: 1.6603, Train acc: 0.2235\n",
      "Valid loss: 1.6445, Valid acc: 0.2450\n",
      "Epoch 7:\n",
      "Train loss: 1.6549, Train acc: 0.2247\n",
      "Valid loss: 1.6540, Valid acc: 0.2422\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6767, Train acc: 0.2203\n",
      "Valid loss: 1.7249, Valid acc: 0.1569\n",
      "Epoch 2:\n",
      "Train loss: 1.6711, Train acc: 0.2203\n",
      "Valid loss: 1.6683, Valid acc: 0.2505\n",
      "Epoch 3:\n",
      "Train loss: 1.7333, Train acc: 0.2114\n",
      "Valid loss: 1.9437, Valid acc: 0.1651\n",
      "Epoch 4:\n",
      "Train loss: 1.7304, Train acc: 0.2027\n",
      "Valid loss: 1.6750, Valid acc: 0.2459\n",
      "Epoch 5:\n",
      "Train loss: 1.7203, Train acc: 0.2072\n",
      "Valid loss: 1.7781, Valid acc: 0.2404\n",
      "Epoch 6:\n",
      "Train loss: 1.6980, Train acc: 0.2384\n",
      "Valid loss: 1.5719, Valid acc: 0.3459\n",
      "Epoch 7:\n",
      "Train loss: 1.6096, Train acc: 0.3077\n",
      "Valid loss: 1.6029, Valid acc: 0.3459\n",
      "Epoch 8:\n",
      "Train loss: 1.6124, Train acc: 0.3006\n",
      "Valid loss: 1.5720, Valid acc: 0.3376\n",
      "Epoch 9:\n",
      "Train loss: 1.5941, Train acc: 0.3171\n",
      "Valid loss: 1.5810, Valid acc: 0.3367\n",
      "Epoch 10:\n",
      "Train loss: 1.5905, Train acc: 0.3189\n",
      "Valid loss: 1.6069, Valid acc: 0.3450\n",
      "Epoch 11:\n",
      "Train loss: 1.5981, Train acc: 0.2989\n",
      "Valid loss: 1.5903, Valid acc: 0.3358\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.9446, Train acc: 0.1944\n",
      "Valid loss: 2.0659, Valid acc: 0.2404\n",
      "Epoch 2:\n",
      "Train loss: 1.8870, Train acc: 0.2013\n",
      "Valid loss: 2.1521, Valid acc: 0.1945\n",
      "Epoch 3:\n",
      "Train loss: 1.8239, Train acc: 0.2105\n",
      "Valid loss: 1.7940, Valid acc: 0.2000\n",
      "Epoch 4:\n",
      "Train loss: 1.7660, Train acc: 0.2144\n",
      "Valid loss: 1.7045, Valid acc: 0.2092\n",
      "Epoch 5:\n",
      "Train loss: 1.7807, Train acc: 0.2006\n",
      "Valid loss: 1.7714, Valid acc: 0.1670\n",
      "Epoch 6:\n",
      "Train loss: 1.8092, Train acc: 0.2123\n",
      "Valid loss: 1.8509, Valid acc: 0.2009\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6728, Train acc: 0.2228\n",
      "Valid loss: 1.6710, Valid acc: 0.2064\n",
      "Epoch 2:\n",
      "Train loss: 1.6543, Train acc: 0.2247\n",
      "Valid loss: 1.6698, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6534, Train acc: 0.2233\n",
      "Valid loss: 1.6351, Valid acc: 0.2761\n",
      "Epoch 4:\n",
      "Train loss: 1.6681, Train acc: 0.2311\n",
      "Valid loss: 1.6600, Valid acc: 0.2257\n",
      "Epoch 5:\n",
      "Train loss: 1.6618, Train acc: 0.2279\n",
      "Valid loss: 1.6646, Valid acc: 0.2009\n",
      "Epoch 6:\n",
      "Train loss: 1.6508, Train acc: 0.2299\n",
      "Valid loss: 1.6562, Valid acc: 0.2220\n",
      "Epoch 7:\n",
      "Train loss: 1.6544, Train acc: 0.2205\n",
      "Valid loss: 1.6372, Valid acc: 0.2349\n",
      "Epoch 8:\n",
      "Train loss: 1.6500, Train acc: 0.2306\n",
      "Valid loss: 1.6489, Valid acc: 0.2083\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6727, Train acc: 0.2098\n",
      "Valid loss: 1.6948, Valid acc: 0.1972\n",
      "Epoch 2:\n",
      "Train loss: 1.6600, Train acc: 0.2231\n",
      "Valid loss: 1.6713, Valid acc: 0.1624\n",
      "Epoch 3:\n",
      "Train loss: 1.6633, Train acc: 0.2153\n",
      "Valid loss: 1.6700, Valid acc: 0.2569\n",
      "Epoch 4:\n",
      "Train loss: 1.6639, Train acc: 0.2233\n",
      "Valid loss: 1.6633, Valid acc: 0.2028\n",
      "Epoch 5:\n",
      "Train loss: 1.6611, Train acc: 0.2231\n",
      "Valid loss: 1.6728, Valid acc: 0.2440\n",
      "Epoch 6:\n",
      "Train loss: 1.6579, Train acc: 0.2251\n",
      "Valid loss: 1.6576, Valid acc: 0.2000\n",
      "Epoch 7:\n",
      "Train loss: 1.6553, Train acc: 0.2315\n",
      "Valid loss: 1.6386, Valid acc: 0.2312\n",
      "Epoch 8:\n",
      "Train loss: 1.6524, Train acc: 0.2283\n",
      "Valid loss: 1.6501, Valid acc: 0.2073\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7970, Train acc: 0.2068\n",
      "Valid loss: 1.6994, Valid acc: 0.2321\n",
      "Epoch 2:\n",
      "Train loss: 1.7256, Train acc: 0.2004\n",
      "Valid loss: 1.7415, Valid acc: 0.2431\n",
      "Epoch 3:\n",
      "Train loss: 1.7236, Train acc: 0.2084\n",
      "Valid loss: 1.7012, Valid acc: 0.2101\n",
      "Epoch 4:\n",
      "Train loss: 1.7112, Train acc: 0.2121\n",
      "Valid loss: 1.7635, Valid acc: 0.2073\n",
      "Epoch 5:\n",
      "Train loss: 1.7138, Train acc: 0.2153\n",
      "Valid loss: 1.7246, Valid acc: 0.2459\n",
      "Epoch 6:\n",
      "Train loss: 1.7396, Train acc: 0.2217\n",
      "Valid loss: 1.7647, Valid acc: 0.2459\n",
      "Epoch 7:\n",
      "Train loss: 1.7217, Train acc: 0.2036\n",
      "Valid loss: 1.6941, Valid acc: 0.2367\n",
      "Epoch 8:\n",
      "Train loss: 1.7202, Train acc: 0.2118\n",
      "Valid loss: 1.7263, Valid acc: 0.2367\n",
      "Epoch 9:\n",
      "Train loss: 1.7451, Train acc: 0.2182\n",
      "Valid loss: 1.6787, Valid acc: 0.2404\n",
      "Epoch 10:\n",
      "Train loss: 1.7173, Train acc: 0.2020\n",
      "Valid loss: 1.7142, Valid acc: 0.2101\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.6691, Train acc: 0.2221\n",
      "Valid loss: 1.6664, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6594, Train acc: 0.2288\n",
      "Valid loss: 1.6617, Valid acc: 0.2450\n",
      "Epoch 3:\n",
      "Train loss: 1.6661, Train acc: 0.2196\n",
      "Valid loss: 1.6570, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6573, Train acc: 0.2205\n",
      "Valid loss: 1.6584, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6494, Train acc: 0.2169\n",
      "Valid loss: 1.6505, Valid acc: 0.2486\n",
      "Epoch 6:\n",
      "Train loss: 1.6638, Train acc: 0.2249\n",
      "Valid loss: 1.6612, Valid acc: 0.2009\n",
      "Epoch 7:\n",
      "Train loss: 1.6527, Train acc: 0.2203\n",
      "Valid loss: 1.6593, Valid acc: 0.2046\n",
      "Epoch 8:\n",
      "Train loss: 1.6575, Train acc: 0.2178\n",
      "Valid loss: 1.6543, Valid acc: 0.2404\n",
      "Epoch 9:\n",
      "Train loss: 1.6592, Train acc: 0.2254\n",
      "Valid loss: 1.6650, Valid acc: 0.2468\n",
      "Epoch 10:\n",
      "Train loss: 1.6559, Train acc: 0.2389\n",
      "Valid loss: 1.6550, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.6708, Train acc: 0.2276\n",
      "Valid loss: 1.6645, Valid acc: 0.2440\n",
      "Epoch 2:\n",
      "Train loss: 1.6688, Train acc: 0.2263\n",
      "Valid loss: 1.6617, Valid acc: 0.2404\n",
      "Epoch 3:\n",
      "Train loss: 1.6584, Train acc: 0.2180\n",
      "Valid loss: 1.6567, Valid acc: 0.2037\n",
      "Epoch 4:\n",
      "Train loss: 1.6512, Train acc: 0.2361\n",
      "Valid loss: 1.7362, Valid acc: 0.2046\n",
      "Epoch 5:\n",
      "Train loss: 1.6500, Train acc: 0.2260\n",
      "Valid loss: 1.7578, Valid acc: 0.1982\n",
      "Epoch 6:\n",
      "Train loss: 1.6622, Train acc: 0.2166\n",
      "Valid loss: 1.6566, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.adam.Adam'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 1.7046, Train acc: 0.2141\n",
      "Valid loss: 1.7868, Valid acc: 0.2092\n",
      "Epoch 2:\n",
      "Train loss: 1.7447, Train acc: 0.2272\n",
      "Valid loss: 1.8249, Valid acc: 0.1899\n",
      "Epoch 3:\n",
      "Train loss: 1.8724, Train acc: 0.1875\n",
      "Valid loss: 1.7211, Valid acc: 0.2312\n",
      "Epoch 4:\n",
      "Train loss: 1.7380, Train acc: 0.2380\n",
      "Valid loss: 1.9122, Valid acc: 0.1853\n",
      "Epoch 5:\n",
      "Train loss: 1.7573, Train acc: 0.2240\n",
      "Valid loss: 2.5398, Valid acc: 0.1505\n",
      "Epoch 6:\n",
      "Train loss: 1.9519, Train acc: 0.2111\n",
      "Valid loss: 1.7688, Valid acc: 0.2165\n",
      "Epoch 7:\n",
      "Train loss: 1.7315, Train acc: 0.2359\n",
      "Valid loss: 1.7153, Valid acc: 0.2651\n",
      "Epoch 8:\n",
      "Train loss: 1.8058, Train acc: 0.2001\n",
      "Valid loss: 2.0261, Valid acc: 0.1651\n",
      "Epoch 9:\n",
      "Train loss: 1.7125, Train acc: 0.2439\n",
      "Valid loss: 1.7996, Valid acc: 0.2046\n",
      "Epoch 10:\n",
      "Train loss: 1.7635, Train acc: 0.1981\n",
      "Valid loss: 1.6920, Valid acc: 0.1706\n",
      "Epoch 11:\n",
      "Train loss: 1.7605, Train acc: 0.2364\n",
      "Valid loss: 1.6358, Valid acc: 0.2780\n",
      "Epoch 12:\n",
      "Train loss: 1.7343, Train acc: 0.2272\n",
      "Valid loss: 1.7026, Valid acc: 0.2404\n",
      "Epoch 13:\n",
      "Train loss: 1.7322, Train acc: 0.2370\n",
      "Valid loss: 1.7146, Valid acc: 0.2771\n",
      "Epoch 14:\n",
      "Train loss: 1.8664, Train acc: 0.1816\n",
      "Valid loss: 1.7233, Valid acc: 0.2789\n",
      "Epoch 15:\n",
      "Train loss: 1.7525, Train acc: 0.2290\n",
      "Valid loss: 1.7716, Valid acc: 0.1569\n",
      "Epoch 16:\n",
      "Train loss: 1.7649, Train acc: 0.2258\n",
      "Valid loss: 1.7583, Valid acc: 0.1606\n",
      "Epoch 17:\n",
      "Train loss: 1.7523, Train acc: 0.2240\n",
      "Valid loss: 1.8091, Valid acc: 0.1651\n",
      "Epoch 18:\n",
      "Train loss: 1.7803, Train acc: 0.2187\n",
      "Valid loss: 1.7043, Valid acc: 0.2450\n",
      "Epoch 19:\n",
      "Train loss: 1.7125, Train acc: 0.2066\n",
      "Valid loss: 1.7544, Valid acc: 0.2633\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7227, Train acc: 0.2208\n",
      "Valid loss: 1.7876, Valid acc: 0.2431\n",
      "Epoch 2:\n",
      "Train loss: 1.6838, Train acc: 0.2215\n",
      "Valid loss: 1.7246, Valid acc: 0.2486\n",
      "Epoch 3:\n",
      "Train loss: 1.6792, Train acc: 0.2235\n",
      "Valid loss: 1.6866, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6713, Train acc: 0.2272\n",
      "Valid loss: 1.6891, Valid acc: 0.2156\n",
      "Epoch 5:\n",
      "Train loss: 1.6783, Train acc: 0.2160\n",
      "Valid loss: 1.6684, Valid acc: 0.2202\n",
      "Epoch 6:\n",
      "Train loss: 1.6562, Train acc: 0.2387\n",
      "Valid loss: 1.7077, Valid acc: 0.2128\n",
      "Epoch 7:\n",
      "Train loss: 1.6596, Train acc: 0.2338\n",
      "Valid loss: 1.7338, Valid acc: 0.1633\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 1.8809, Train acc: 0.2114\n",
      "Valid loss: 3.2259, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.7444, Train acc: 0.2157\n",
      "Valid loss: 1.8682, Valid acc: 0.1642\n",
      "Epoch 3:\n",
      "Train loss: 1.7249, Train acc: 0.2249\n",
      "Valid loss: 1.8700, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.7479, Train acc: 0.2086\n",
      "Valid loss: 1.9545, Valid acc: 0.2440\n",
      "Epoch 5:\n",
      "Train loss: 1.7375, Train acc: 0.2082\n",
      "Valid loss: 1.8115, Valid acc: 0.2440\n",
      "Epoch 6:\n",
      "Train loss: 1.7343, Train acc: 0.2155\n",
      "Valid loss: 2.6159, Valid acc: 0.2046\n",
      "Epoch 7:\n",
      "Train loss: 1.7450, Train acc: 0.2036\n",
      "Valid loss: 1.9367, Valid acc: 0.1670\n",
      "Epoch 8:\n",
      "Train loss: 1.7576, Train acc: 0.2091\n",
      "Valid loss: 1.8082, Valid acc: 0.2596\n",
      "Epoch 9:\n",
      "Train loss: 1.7212, Train acc: 0.2295\n",
      "Valid loss: 1.8195, Valid acc: 0.1872\n",
      "Epoch 10:\n",
      "Train loss: 1.7148, Train acc: 0.2322\n",
      "Valid loss: 1.6900, Valid acc: 0.2550\n",
      "Epoch 11:\n",
      "Train loss: 1.7192, Train acc: 0.2290\n",
      "Valid loss: 2.4056, Valid acc: 0.2119\n",
      "Epoch 12:\n",
      "Train loss: 1.7139, Train acc: 0.2368\n",
      "Valid loss: 1.8675, Valid acc: 0.2440\n",
      "Epoch 13:\n",
      "Train loss: 1.7110, Train acc: 0.2260\n",
      "Valid loss: 1.7887, Valid acc: 0.2587\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 32, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 2.3528, Train acc: 0.2086\n",
      "Valid loss: 2.2985, Valid acc: 0.1972\n",
      "Epoch 2:\n",
      "Train loss: 1.9853, Train acc: 0.1994\n",
      "Valid loss: 1.9253, Valid acc: 0.1532\n",
      "Epoch 3:\n",
      "Train loss: 1.9290, Train acc: 0.2162\n",
      "Valid loss: 2.2741, Valid acc: 0.1991\n",
      "Epoch 4:\n",
      "Train loss: 1.9459, Train acc: 0.2139\n",
      "Valid loss: 2.2914, Valid acc: 0.1862\n",
      "Epoch 5:\n",
      "Train loss: 1.9023, Train acc: 0.2153\n",
      "Valid loss: 1.9046, Valid acc: 0.2633\n",
      "Epoch 6:\n",
      "Train loss: 1.9215, Train acc: 0.2189\n",
      "Valid loss: 2.6543, Valid acc: 0.2018\n",
      "Epoch 7:\n",
      "Train loss: 1.9403, Train acc: 0.2098\n",
      "Valid loss: 2.1891, Valid acc: 0.2569\n",
      "Epoch 8:\n",
      "Train loss: 1.9494, Train acc: 0.1933\n",
      "Valid loss: 2.0168, Valid acc: 0.2073\n",
      "Epoch 9:\n",
      "Train loss: 1.9235, Train acc: 0.2146\n",
      "Valid loss: 2.2021, Valid acc: 0.1936\n",
      "Epoch 10:\n",
      "Train loss: 1.9393, Train acc: 0.2033\n",
      "Valid loss: 2.0502, Valid acc: 0.2404\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7495, Train acc: 0.2088\n",
      "Valid loss: 1.7173, Valid acc: 0.2211\n",
      "Epoch 2:\n",
      "Train loss: 1.6840, Train acc: 0.2114\n",
      "Valid loss: 1.7485, Valid acc: 0.2413\n",
      "Epoch 3:\n",
      "Train loss: 1.6811, Train acc: 0.2258\n",
      "Valid loss: 1.6946, Valid acc: 0.2376\n",
      "Epoch 4:\n",
      "Train loss: 1.6732, Train acc: 0.2274\n",
      "Valid loss: 1.7379, Valid acc: 0.1982\n",
      "Epoch 5:\n",
      "Train loss: 1.6756, Train acc: 0.2217\n",
      "Valid loss: 1.7030, Valid acc: 0.2110\n",
      "Epoch 6:\n",
      "Train loss: 1.6715, Train acc: 0.2238\n",
      "Valid loss: 1.7601, Valid acc: 0.2064\n",
      "Epoch 7:\n",
      "Train loss: 1.6709, Train acc: 0.2210\n",
      "Valid loss: 1.7118, Valid acc: 0.2046\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 2.0228, Train acc: 0.2077\n",
      "Valid loss: 1.8413, Valid acc: 0.1541\n",
      "Epoch 2:\n",
      "Train loss: 1.7291, Train acc: 0.2072\n",
      "Valid loss: 1.7700, Valid acc: 0.2028\n",
      "Epoch 3:\n",
      "Train loss: 1.7461, Train acc: 0.2095\n",
      "Valid loss: 2.4699, Valid acc: 0.2440\n",
      "Epoch 4:\n",
      "Train loss: 1.7355, Train acc: 0.2139\n",
      "Valid loss: 2.1466, Valid acc: 0.1560\n",
      "Epoch 5:\n",
      "Train loss: 1.7254, Train acc: 0.2134\n",
      "Valid loss: 2.7366, Valid acc: 0.2046\n",
      "Epoch 6:\n",
      "Train loss: 1.7556, Train acc: 0.2079\n",
      "Valid loss: 1.8688, Valid acc: 0.2431\n",
      "Epoch 7:\n",
      "Train loss: 1.7322, Train acc: 0.2173\n",
      "Valid loss: 2.1050, Valid acc: 0.2826\n",
      "Epoch 8:\n",
      "Train loss: 1.6654, Train acc: 0.2613\n",
      "Valid loss: 2.0528, Valid acc: 0.2872\n",
      "Epoch 9:\n",
      "Train loss: 1.6642, Train acc: 0.2478\n",
      "Valid loss: 2.0518, Valid acc: 0.1523\n",
      "Epoch 10:\n",
      "Train loss: 1.6523, Train acc: 0.2503\n",
      "Valid loss: 1.7831, Valid acc: 0.2890\n",
      "Epoch 11:\n",
      "Train loss: 1.6509, Train acc: 0.2490\n",
      "Valid loss: 1.6381, Valid acc: 0.2046\n",
      "Epoch 12:\n",
      "Train loss: 1.6596, Train acc: 0.2474\n",
      "Valid loss: 1.7581, Valid acc: 0.2092\n",
      "Epoch 13:\n",
      "Train loss: 1.6364, Train acc: 0.2556\n",
      "Valid loss: 1.8005, Valid acc: 0.2835\n",
      "Epoch 14:\n",
      "Train loss: 1.6525, Train acc: 0.2510\n",
      "Valid loss: 1.5917, Valid acc: 0.2716\n",
      "Epoch 15:\n",
      "Train loss: 1.6574, Train acc: 0.2455\n",
      "Valid loss: 1.7749, Valid acc: 0.1807\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 64, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 3.1750, Train acc: 0.1823\n",
      "Valid loss: 2.4425, Valid acc: 0.1963\n",
      "Epoch 2:\n",
      "Train loss: 1.9733, Train acc: 0.1967\n",
      "Valid loss: 2.2263, Valid acc: 0.2064\n",
      "Epoch 3:\n",
      "Train loss: 1.8788, Train acc: 0.2068\n",
      "Valid loss: 2.2696, Valid acc: 0.1872\n",
      "Epoch 4:\n",
      "Train loss: 2.0602, Train acc: 0.1926\n",
      "Valid loss: 1.9563, Valid acc: 0.2110\n",
      "Epoch 5:\n",
      "Train loss: 1.8989, Train acc: 0.2038\n",
      "Valid loss: 2.2098, Valid acc: 0.1817\n",
      "Epoch 6:\n",
      "Train loss: 1.8297, Train acc: 0.2192\n",
      "Valid loss: 2.7642, Valid acc: 0.2376\n",
      "Epoch 7:\n",
      "Train loss: 1.9632, Train acc: 0.2100\n",
      "Valid loss: 1.7518, Valid acc: 0.2028\n",
      "Epoch 8:\n",
      "Train loss: 1.8799, Train acc: 0.2125\n",
      "Valid loss: 2.0245, Valid acc: 0.1853\n",
      "Epoch 9:\n",
      "Train loss: 1.9146, Train acc: 0.2063\n",
      "Valid loss: 2.6607, Valid acc: 0.2275\n",
      "Epoch 10:\n",
      "Train loss: 1.9247, Train acc: 0.2056\n",
      "Valid loss: 2.2158, Valid acc: 0.1927\n",
      "Epoch 11:\n",
      "Train loss: 1.9013, Train acc: 0.2123\n",
      "Valid loss: 2.2553, Valid acc: 0.1936\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 64}\n",
      "Epoch 1:\n",
      "Train loss: 1.7671, Train acc: 0.2100\n",
      "Valid loss: 1.7157, Valid acc: 0.2165\n",
      "Epoch 2:\n",
      "Train loss: 1.6881, Train acc: 0.2169\n",
      "Valid loss: 1.7632, Valid acc: 0.1991\n",
      "Epoch 3:\n",
      "Train loss: 1.6819, Train acc: 0.2178\n",
      "Valid loss: 1.7704, Valid acc: 0.2101\n",
      "Epoch 4:\n",
      "Train loss: 1.6727, Train acc: 0.2297\n",
      "Valid loss: 1.7018, Valid acc: 0.2073\n",
      "Epoch 5:\n",
      "Train loss: 1.6694, Train acc: 0.2290\n",
      "Valid loss: 1.7666, Valid acc: 0.2193\n",
      "Epoch 6:\n",
      "Train loss: 1.6783, Train acc: 0.2173\n",
      "Valid loss: 1.7186, Valid acc: 0.2431\n",
      "Epoch 7:\n",
      "Train loss: 1.6795, Train acc: 0.2180\n",
      "Valid loss: 1.7223, Valid acc: 0.1982\n",
      "Epoch 8:\n",
      "Train loss: 1.6799, Train acc: 0.2276\n",
      "Valid loss: 1.7078, Valid acc: 0.2560\n",
      "Epoch 9:\n",
      "Train loss: 1.6677, Train acc: 0.2231\n",
      "Valid loss: 1.7156, Valid acc: 0.1890\n",
      "Epoch 10:\n",
      "Train loss: 1.6651, Train acc: 0.2178\n",
      "Valid loss: 1.7520, Valid acc: 0.1844\n",
      "Epoch 11:\n",
      "Train loss: 1.6712, Train acc: 0.2199\n",
      "Valid loss: 1.7055, Valid acc: 0.2266\n",
      "Epoch 12:\n",
      "Train loss: 1.6653, Train acc: 0.2235\n",
      "Valid loss: 1.8026, Valid acc: 0.1991\n",
      "Epoch 13:\n",
      "Train loss: 1.6743, Train acc: 0.2228\n",
      "Valid loss: 1.7803, Valid acc: 0.2284\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 128}\n",
      "Epoch 1:\n",
      "Train loss: 2.2207, Train acc: 0.1765\n",
      "Valid loss: 2.1083, Valid acc: 0.1761\n",
      "Epoch 2:\n",
      "Train loss: 1.8398, Train acc: 0.1969\n",
      "Valid loss: 2.1874, Valid acc: 0.2064\n",
      "Epoch 3:\n",
      "Train loss: 1.7501, Train acc: 0.2038\n",
      "Valid loss: 2.0758, Valid acc: 0.2174\n",
      "Epoch 4:\n",
      "Train loss: 1.7431, Train acc: 0.1965\n",
      "Valid loss: 1.8981, Valid acc: 0.2119\n",
      "Epoch 5:\n",
      "Train loss: 1.7226, Train acc: 0.2180\n",
      "Valid loss: 1.8158, Valid acc: 0.2110\n",
      "Epoch 6:\n",
      "Train loss: 1.7331, Train acc: 0.2029\n",
      "Valid loss: 1.8172, Valid acc: 0.2083\n",
      "Epoch 7:\n",
      "Train loss: 1.6957, Train acc: 0.2297\n",
      "Valid loss: 1.7705, Valid acc: 0.1679\n",
      "Epoch 8:\n",
      "Train loss: 1.7176, Train acc: 0.2182\n",
      "Valid loss: 1.8755, Valid acc: 0.2119\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Training with hyperparameters: {'lrs': 0.005, 'optimizers': <class 'torch.optim.rmsprop.RMSprop'>, 'batch_sizes': 128, 'hidden_dims': 256}\n",
      "Epoch 1:\n",
      "Train loss: 3.1919, Train acc: 0.1717\n",
      "Valid loss: 2.3066, Valid acc: 0.2101\n",
      "Epoch 2:\n",
      "Train loss: 2.2100, Train acc: 0.1994\n",
      "Valid loss: 2.2547, Valid acc: 0.1881\n",
      "Epoch 3:\n",
      "Train loss: 2.0444, Train acc: 0.1662\n",
      "Valid loss: 2.0348, Valid acc: 0.1872\n",
      "Epoch 4:\n",
      "Train loss: 1.8475, Train acc: 0.2205\n",
      "Valid loss: 2.3919, Valid acc: 0.1917\n",
      "Epoch 5:\n",
      "Train loss: 1.9995, Train acc: 0.2148\n",
      "Valid loss: 1.8980, Valid acc: 0.2229\n",
      "Epoch 6:\n",
      "Train loss: 1.9921, Train acc: 0.2024\n",
      "Valid loss: 2.3100, Valid acc: 0.1936\n",
      "Epoch 7:\n",
      "Train loss: 1.8788, Train acc: 0.2022\n",
      "Valid loss: 1.9281, Valid acc: 0.1138\n",
      "Epoch 8:\n",
      "Train loss: 1.9107, Train acc: 0.2178\n",
      "Valid loss: 2.7384, Valid acc: 0.1780\n",
      "Epoch 9:\n",
      "Train loss: 1.9445, Train acc: 0.2109\n",
      "Valid loss: 1.9075, Valid acc: 0.2009\n",
      "Epoch 10:\n",
      "Train loss: 1.8597, Train acc: 0.1930\n",
      "Valid loss: 2.2204, Valid acc: 0.2028\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Best Hyperparamters:  {'lr': 0.0001, 'optimizer': RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    capturable: False\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      "), 'batch_size': 32, 'hidden_dim': 256, 'epochs ran': 51}\n",
      "Best validation accuracy:  0.8128440366972477\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for simple hyperparameter tuning based on validation accuracy\n",
    "param_grid = {\n",
    "    'lrs': [0.0001, 0.0005, 0.001, 0.005],\n",
    "    'optimizers': [torch.optim.SGD, torch.optim.Adagrad, torch.optim.Adam, torch.optim.RMSprop],\n",
    "    'batch_sizes': [32, 64, 128],\n",
    "    'hidden_dims': [64, 128, 256]\n",
    "}\n",
    "\n",
    "# Run function to find optimal hyperparameters for (a)\n",
    "results, best_hyperparams = find_optimal_hyperparams(param_grid, TEXT.vocab.vectors.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c1a2dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "optimizer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "batch_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_dim",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "best_valid_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epochs ran",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a914dde7-33ad-4823-98b1-8289a62884c1",
       "rows": [
        [
         "29",
         "0.0001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.8128440366972477",
         "51"
        ],
        [
         "22",
         "0.0001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.7972477064220184",
         "61"
        ],
        [
         "20",
         "0.0001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.7880733944954128",
         "33"
        ],
        [
         "32",
         "0.0001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "256",
         "0.7669724770642202",
         "49"
        ],
        [
         "31",
         "0.0001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.744954128440367",
         "39"
        ],
        [
         "28",
         "0.0001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.7376146788990826",
         "54"
        ],
        [
         "82",
         "0.001",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.001\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.6678899082568808",
         "68"
        ],
        [
         "83",
         "0.001",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.001\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.6623853211009174",
         "36"
        ],
        [
         "63",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "64",
         "0.6614678899082569",
         "26"
        ],
        [
         "27",
         "0.0001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "64",
         "0.6559633027522935",
         "52"
        ],
        [
         "117",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "64",
         "0.6449541284403669",
         "35"
        ],
        [
         "66",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "64",
         "0.6431192660550459",
         "31"
        ],
        [
         "120",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "64",
         "0.6412844036697247",
         "32"
        ],
        [
         "86",
         "0.001",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.001\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "256",
         "0.6385321100917432",
         "42"
        ],
        [
         "54",
         "0.0005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "64",
         "0.6091743119266055",
         "31"
        ],
        [
         "100",
         "0.001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.41926605504587156",
         "27"
        ],
        [
         "119",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.41559633027522935",
         "12"
        ],
        [
         "69",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "128",
         "64",
         "0.4036697247706422",
         "16"
        ],
        [
         "102",
         "0.001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "64",
         "0.4018348623853211",
         "14"
        ],
        [
         "124",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "128",
         "0.3963302752293578",
         "22"
        ],
        [
         "118",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.3944954128440367",
         "7"
        ],
        [
         "99",
         "0.001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "64",
         "0.3908256880733945",
         "12"
        ],
        [
         "55",
         "0.0005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.3908256880733945",
         "14"
        ],
        [
         "67",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.3908256880733945",
         "12"
        ],
        [
         "121",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.3908256880733945",
         "11"
        ],
        [
         "105",
         "0.001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "128",
         "64",
         "0.3908256880733945",
         "16"
        ],
        [
         "64",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.38990825688073394",
         "16"
        ],
        [
         "103",
         "0.001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.38990825688073394",
         "14"
        ],
        [
         "65",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.3889908256880734",
         "10"
        ],
        [
         "60",
         "0.0005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "64",
         "0.3853211009174312",
         "19"
        ],
        [
         "96",
         "0.001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "64",
         "0.38440366972477064",
         "10"
        ],
        [
         "97",
         "0.001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "128",
         "0.3798165137614679",
         "16"
        ],
        [
         "59",
         "0.0005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "256",
         "0.37339449541284403",
         "17"
        ],
        [
         "122",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "256",
         "0.3706422018348624",
         "17"
        ],
        [
         "68",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "256",
         "0.3669724770642202",
         "16"
        ],
        [
         "70",
         "0.0005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "128",
         "128",
         "0.3532110091743119",
         "19"
        ],
        [
         "90",
         "0.001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "64",
         "0.3467889908256881",
         "9"
        ],
        [
         "127",
         "0.005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.005\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "128",
         "0.3458715596330275",
         "11"
        ],
        [
         "104",
         "0.001",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "256",
         "0.3422018348623853",
         "13"
        ],
        [
         "93",
         "0.001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "64",
         "0.326605504587156",
         "10"
        ],
        [
         "58",
         "0.0005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.3165137614678899",
         "10"
        ],
        [
         "53",
         "0.0005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.0005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "256",
         "0.2944954128440367",
         "11"
        ],
        [
         "139",
         "0.005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.2889908256880734",
         "15"
        ],
        [
         "94",
         "0.001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "128",
         "0.2853211009174312",
         "11"
        ],
        [
         "134",
         "0.005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.005\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "256",
         "0.27889908256880735",
         "19"
        ],
        [
         "125",
         "0.005",
         "Adagrad (\nParameter Group 0\n    differentiable: False\n    eps: 1e-10\n    foreach: None\n    fused: None\n    initial_accumulator_value: 0\n    lr: 0.005\n    lr_decay: 0\n    maximize: False\n    weight_decay: 0\n)",
         "128",
         "256",
         "0.27706422018348625",
         "11"
        ],
        [
         "129",
         "0.005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.005\n    maximize: False\n    weight_decay: 0\n)",
         "64",
         "64",
         "0.2761467889908257",
         "8"
        ],
        [
         "56",
         "0.0005",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.27155963302752295",
         "11"
        ],
        [
         "137",
         "0.005",
         "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.005\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.26330275229357797",
         "10"
        ],
        [
         "92",
         "0.001",
         "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)",
         "32",
         "256",
         "0.26238532110091745",
         "14"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 144
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>best_valid_acc</th>\n",
       "      <th>epochs ran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>RMSprop (\\nParameter Group 0\\n    alpha: 0.99\\...</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>0.812844</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.797248</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>0.788073</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>RMSprop (\\nParameter Group 0\\n    alpha: 0.99\\...</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>RMSprop (\\nParameter Group 0\\n    alpha: 0.99\\...</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.744954</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0.154128</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0.144954</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.143119</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr                                          optimizer  batch_size  \\\n",
       "29  0.0001  RMSprop (\\nParameter Group 0\\n    alpha: 0.99\\...          32   \n",
       "22  0.0001  Adam (\\nParameter Group 0\\n    amsgrad: False\\...          64   \n",
       "20  0.0001  Adam (\\nParameter Group 0\\n    amsgrad: False\\...          32   \n",
       "32  0.0001  RMSprop (\\nParameter Group 0\\n    alpha: 0.99\\...          64   \n",
       "31  0.0001  RMSprop (\\nParameter Group 0\\n    alpha: 0.99\\...          64   \n",
       "..     ...                                                ...         ...   \n",
       "6   0.0001  SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...         128   \n",
       "42  0.0005  SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...         128   \n",
       "4   0.0001  SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...          64   \n",
       "7   0.0001  SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...         128   \n",
       "0   0.0001  SGD (\\nParameter Group 0\\n    dampening: 0\\n  ...          32   \n",
       "\n",
       "    hidden_dim  best_valid_acc  epochs ran  \n",
       "29         256        0.812844          51  \n",
       "22         128        0.797248          61  \n",
       "20         256        0.788073          33  \n",
       "32         256        0.766972          49  \n",
       "31         128        0.744954          39  \n",
       "..         ...             ...         ...  \n",
       "6           64        0.154128           6  \n",
       "42          64        0.144954          12  \n",
       "4          128        0.143119          13  \n",
       "7          128        0.022936           6  \n",
       "0           64        0.018349           6  \n",
       "\n",
       "[144 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To put everything in a dataframe for neater results\n",
    "df_results_a = pd.DataFrame(results)\n",
    "df_results_a = df_results_a.sort_values(by='best_valid_acc', ascending=False)\n",
    "df_results_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c920952",
   "metadata": {},
   "source": [
    "### Answer (a):\n",
    "Final Configuration of Best Model \n",
    "Number of training epochs = 42\n",
    "Learning rate = 0.0001\n",
    "Optimizer = Adam\n",
    "Batch Size = 32\n",
    "Hidden dimension = 256\n",
    "\n",
    "Best validation accuracy based on optimal parameters: 0.7936"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68973e1",
   "metadata": {},
   "source": [
    "**(b) Report all the regularization strategies you have tried. Compare the accuracy on the test set among all strategies and the one without any regularization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8eb1be",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "Here, our approach is to try most of the regularization strategies (that does not change the number of layers) that we have learnt during the lectures to avoid overfitting, namely:\n",
    "1. Baseline (as per qn requirement)\n",
    "2. L2 Regularization (Weight Decay)\n",
    "3. Dropout\n",
    "4. Gradient Clipping\n",
    "\n",
    "We first experiment with the regularization strategies individually with parameter tuning, e.g. Dropout ONLY or Gradient Clipping ONLY, and we do a comparison with the baseline to see how no regularisation here would perform compared to having regularization.\n",
    "\n",
    "Thereafter, we try to find the best possible \"strategy\" to use for the later part by trying a combination of the strategies to see which would perform the best after evaluating on test accuracy as per question requirements (e.g. whether dropout + L2 regularisation is better than just dropout, whether dropout + gradient clipping + L2 regularisation outperforms having lesser strategies combined etc.)\n",
    "\n",
    "Note: Even though early stopping is a regularization technique, we do not consider it here as one of the strategies to try out since we already implemented it earlier on. The goal here for us is to try out other strategies that we have not implemented in part (a).\n",
    "\n",
    "Note 2: We did not consider L1 regularisation as a strategy because we found that Adam is the best optimizer for our model in part (a), and since Adam is an adaptive optimizer, trying to use L1 can potentially cause the issue of sparse weights (which we want to avoid here).\n",
    "\n",
    "Note 3: While we did consider trying batch normalisation, we realised it is best used in between 2 hidden layers. Since we only had 1 hidden layer, internal covariate shift is minimal in a shallow network, and we think that the stabilising benefits are limited compared to the unnecessary overhead and noise introduced in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba361b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ideal hyperparameters from 2(a)\n",
    "if best_hyperparams[\"epochs ran\"] <= 50:\n",
    "    no_epoch = 50\n",
    "elif best_hyperparams[\"epochs ran\"] > 50 & best_hyperparams[\"epochs ran\"] <= 100:\n",
    "    no_epoch = 100\n",
    "else:\n",
    "    no_epoch = 200\n",
    "batch_size = best_hyperparams[\"batch_size\"]\n",
    "hidden_dim = best_hyperparams[\"hidden_dim\"]\n",
    "lr = best_hyperparams[\"lr\"]\n",
    "optimizer = best_hyperparams[\"optimizer\"]\n",
    "\n",
    "best_reg_technique = []\n",
    "\n",
    "# Define a function for Regularisation Tests\n",
    "def regularisation_test(weight_decay, dropout, grad_clip, max_norm, reg_technique, optimizer):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Initialise model\n",
    "    model = ClassifierRNN(TEXT.vocab.vectors.numpy() , hidden_dim, dropout=dropout)\n",
    "\n",
    "    # Initialise optimiser with L2 regularization\n",
    "    optimizer = optimizer.__class__(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if grad_clip == True:\n",
    "        _, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch, grad_clip=True, max_norm=max_norm)\n",
    "    else:\n",
    "        _, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_acc = test_loop(model, test_loader)\n",
    "    print(f\"Test Accuracy {reg_technique} (Dropout: {dropout}, Weight Decay: {weight_decay}, Max Norm: {max_norm}): {test_acc:.4f}\") # Print test accuracy for regularisation strategy\n",
    "\n",
    "    return {\n",
    "        'technique': reg_technique,\n",
    "        'dropout': dropout,\n",
    "        'weight_decay': weight_decay,\n",
    "        'grad_clip': grad_clip,\n",
    "        'max_norm': max_norm,\n",
    "        'best_val_acc': max(valid_accuracies),\n",
    "        'test_acc': test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16e7cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.6587, Train acc: 0.2201\n",
      "Valid loss: 1.6436, Valid acc: 0.2486\n",
      "Epoch 2:\n",
      "Train loss: 1.6493, Train acc: 0.2309\n",
      "Valid loss: 1.6429, Valid acc: 0.2587\n",
      "Epoch 3:\n",
      "Train loss: 1.6456, Train acc: 0.2189\n",
      "Valid loss: 1.6439, Valid acc: 0.2468\n",
      "Epoch 4:\n",
      "Train loss: 1.6406, Train acc: 0.2540\n",
      "Valid loss: 1.6458, Valid acc: 0.2569\n",
      "Epoch 5:\n",
      "Train loss: 1.6338, Train acc: 0.2618\n",
      "Valid loss: 1.5557, Valid acc: 0.3596\n",
      "Epoch 6:\n",
      "Train loss: 1.4925, Train acc: 0.3794\n",
      "Valid loss: 1.4795, Valid acc: 0.3908\n",
      "Epoch 7:\n",
      "Train loss: 1.4354, Train acc: 0.4033\n",
      "Valid loss: 1.4420, Valid acc: 0.4083\n",
      "Epoch 8:\n",
      "Train loss: 1.3649, Train acc: 0.4294\n",
      "Valid loss: 1.3510, Valid acc: 0.4477\n",
      "Epoch 9:\n",
      "Train loss: 1.2695, Train acc: 0.4633\n",
      "Valid loss: 1.2838, Valid acc: 0.4505\n",
      "Epoch 10:\n",
      "Train loss: 1.2169, Train acc: 0.4851\n",
      "Valid loss: 1.2864, Valid acc: 0.4826\n",
      "Epoch 11:\n",
      "Train loss: 1.1646, Train acc: 0.5071\n",
      "Valid loss: 1.2134, Valid acc: 0.5064\n",
      "Epoch 12:\n",
      "Train loss: 1.1245, Train acc: 0.5112\n",
      "Valid loss: 1.1717, Valid acc: 0.4862\n",
      "Epoch 13:\n",
      "Train loss: 1.0914, Train acc: 0.5234\n",
      "Valid loss: 1.1598, Valid acc: 0.5330\n",
      "Epoch 14:\n",
      "Train loss: 1.0522, Train acc: 0.5497\n",
      "Valid loss: 1.1688, Valid acc: 0.4991\n",
      "Epoch 15:\n",
      "Train loss: 1.0090, Train acc: 0.6087\n",
      "Valid loss: 1.1304, Valid acc: 0.5596\n",
      "Epoch 16:\n",
      "Train loss: 0.9790, Train acc: 0.6249\n",
      "Valid loss: 1.5440, Valid acc: 0.4376\n",
      "Epoch 17:\n",
      "Train loss: 0.9411, Train acc: 0.6520\n",
      "Valid loss: 1.2837, Valid acc: 0.5174\n",
      "Epoch 18:\n",
      "Train loss: 0.8956, Train acc: 0.6816\n",
      "Valid loss: 0.9492, Valid acc: 0.6688\n",
      "Epoch 19:\n",
      "Train loss: 0.9145, Train acc: 0.6956\n",
      "Valid loss: 0.9629, Valid acc: 0.6633\n",
      "Epoch 20:\n",
      "Train loss: 0.8273, Train acc: 0.7233\n",
      "Valid loss: 1.1080, Valid acc: 0.5725\n",
      "Epoch 21:\n",
      "Train loss: 0.8187, Train acc: 0.7201\n",
      "Valid loss: 0.9257, Valid acc: 0.6780\n",
      "Epoch 22:\n",
      "Train loss: 0.7663, Train acc: 0.7536\n",
      "Valid loss: 0.8878, Valid acc: 0.7018\n",
      "Epoch 23:\n",
      "Train loss: 0.7705, Train acc: 0.7510\n",
      "Valid loss: 0.9496, Valid acc: 0.6633\n",
      "Epoch 24:\n",
      "Train loss: 0.7339, Train acc: 0.7707\n",
      "Valid loss: 0.8559, Valid acc: 0.7211\n",
      "Epoch 25:\n",
      "Train loss: 0.7108, Train acc: 0.7813\n",
      "Valid loss: 1.0152, Valid acc: 0.6826\n",
      "Epoch 26:\n",
      "Train loss: 0.6853, Train acc: 0.7900\n",
      "Valid loss: 0.8894, Valid acc: 0.7009\n",
      "Epoch 27:\n",
      "Train loss: 0.6751, Train acc: 0.7923\n",
      "Valid loss: 1.4763, Valid acc: 0.5165\n",
      "Epoch 28:\n",
      "Train loss: 0.6679, Train acc: 0.8012\n",
      "Valid loss: 0.8466, Valid acc: 0.7220\n",
      "Epoch 29:\n",
      "Train loss: 0.6497, Train acc: 0.8049\n",
      "Valid loss: 0.8352, Valid acc: 0.7358\n",
      "Epoch 30:\n",
      "Train loss: 0.6464, Train acc: 0.8095\n",
      "Valid loss: 0.8638, Valid acc: 0.7202\n",
      "Epoch 31:\n",
      "Train loss: 0.6313, Train acc: 0.8187\n",
      "Valid loss: 0.9638, Valid acc: 0.7028\n",
      "Epoch 32:\n",
      "Train loss: 0.6128, Train acc: 0.8223\n",
      "Valid loss: 1.0507, Valid acc: 0.6339\n",
      "Epoch 33:\n",
      "Train loss: 0.5779, Train acc: 0.8375\n",
      "Valid loss: 1.1031, Valid acc: 0.6422\n",
      "Epoch 34:\n",
      "Train loss: 0.6050, Train acc: 0.8326\n",
      "Valid loss: 1.2942, Valid acc: 0.6248\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Baseline (Dropout: 0.0, Weight Decay: 0.0, Max Norm: 0.0): 0.6260\n"
     ]
    }
   ],
   "source": [
    "# Regularisation - Baseline (No Regularisation)\n",
    "best_reg_technique.append(regularisation_test(weight_decay=0.0,dropout=0.0, grad_clip=False, max_norm=0.0, reg_technique=\"Baseline\", optimizer=optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fcd0ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing L2 Regularization with weight decay: 1e-05\n",
      "Epoch 1:\n",
      "Train loss: 1.6605, Train acc: 0.2249\n",
      "Valid loss: 1.6615, Valid acc: 0.2477\n",
      "Epoch 2:\n",
      "Train loss: 1.6489, Train acc: 0.2375\n",
      "Valid loss: 1.6425, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6489, Train acc: 0.2279\n",
      "Valid loss: 1.6460, Valid acc: 0.2486\n",
      "Epoch 4:\n",
      "Train loss: 1.6452, Train acc: 0.2341\n",
      "Valid loss: 1.6507, Valid acc: 0.2495\n",
      "Epoch 5:\n",
      "Train loss: 1.6429, Train acc: 0.2455\n",
      "Valid loss: 1.6423, Valid acc: 0.2495\n",
      "Epoch 6:\n",
      "Train loss: 1.6354, Train acc: 0.2492\n",
      "Valid loss: 1.5901, Valid acc: 0.3312\n",
      "Epoch 7:\n",
      "Train loss: 1.4891, Train acc: 0.3867\n",
      "Valid loss: 1.4595, Valid acc: 0.4083\n",
      "Epoch 8:\n",
      "Train loss: 1.4217, Train acc: 0.4065\n",
      "Valid loss: 1.4070, Valid acc: 0.4165\n",
      "Epoch 9:\n",
      "Train loss: 1.3336, Train acc: 0.4372\n",
      "Valid loss: 1.3417, Valid acc: 0.4450\n",
      "Epoch 10:\n",
      "Train loss: 1.2480, Train acc: 0.4764\n",
      "Valid loss: 1.2591, Valid acc: 0.4844\n",
      "Epoch 11:\n",
      "Train loss: 1.1911, Train acc: 0.4931\n",
      "Valid loss: 1.2375, Valid acc: 0.4908\n",
      "Epoch 12:\n",
      "Train loss: 1.1360, Train acc: 0.5326\n",
      "Valid loss: 1.2923, Valid acc: 0.4541\n",
      "Epoch 13:\n",
      "Train loss: 1.1195, Train acc: 0.5518\n",
      "Valid loss: 1.1662, Valid acc: 0.5248\n",
      "Epoch 14:\n",
      "Train loss: 1.0420, Train acc: 0.5995\n",
      "Valid loss: 1.7101, Valid acc: 0.4110\n",
      "Epoch 15:\n",
      "Train loss: 0.9960, Train acc: 0.6094\n",
      "Valid loss: 1.0574, Valid acc: 0.6220\n",
      "Epoch 16:\n",
      "Train loss: 0.9442, Train acc: 0.6327\n",
      "Valid loss: 0.9735, Valid acc: 0.6220\n",
      "Epoch 17:\n",
      "Train loss: 0.9215, Train acc: 0.6447\n",
      "Valid loss: 1.6479, Valid acc: 0.4679\n",
      "Epoch 18:\n",
      "Train loss: 0.8969, Train acc: 0.6467\n",
      "Valid loss: 0.9873, Valid acc: 0.6404\n",
      "Epoch 19:\n",
      "Train loss: 0.8686, Train acc: 0.6605\n",
      "Valid loss: 1.0274, Valid acc: 0.6294\n",
      "Epoch 20:\n",
      "Train loss: 0.8601, Train acc: 0.6600\n",
      "Valid loss: 1.5485, Valid acc: 0.5183\n",
      "Epoch 21:\n",
      "Train loss: 0.8412, Train acc: 0.6729\n",
      "Valid loss: 0.9633, Valid acc: 0.6440\n",
      "Epoch 22:\n",
      "Train loss: 0.7956, Train acc: 0.6845\n",
      "Valid loss: 0.8982, Valid acc: 0.6569\n",
      "Epoch 23:\n",
      "Train loss: 0.8099, Train acc: 0.6756\n",
      "Valid loss: 1.0163, Valid acc: 0.6147\n",
      "Epoch 24:\n",
      "Train loss: 0.7643, Train acc: 0.6928\n",
      "Valid loss: 0.9000, Valid acc: 0.6514\n",
      "Epoch 25:\n",
      "Train loss: 0.7704, Train acc: 0.6935\n",
      "Valid loss: 0.8961, Valid acc: 0.6633\n",
      "Epoch 26:\n",
      "Train loss: 0.7639, Train acc: 0.6917\n",
      "Valid loss: 0.9401, Valid acc: 0.6532\n",
      "Epoch 27:\n",
      "Train loss: 0.7295, Train acc: 0.7031\n",
      "Valid loss: 0.8624, Valid acc: 0.6752\n",
      "Epoch 28:\n",
      "Train loss: 0.7490, Train acc: 0.7077\n",
      "Valid loss: 1.0495, Valid acc: 0.6229\n",
      "Epoch 29:\n",
      "Train loss: 0.7371, Train acc: 0.6972\n",
      "Valid loss: 0.9735, Valid acc: 0.6550\n",
      "Epoch 30:\n",
      "Train loss: 0.6725, Train acc: 0.7178\n",
      "Valid loss: 0.9462, Valid acc: 0.6560\n",
      "Epoch 31:\n",
      "Train loss: 0.6691, Train acc: 0.7283\n",
      "Valid loss: 1.0496, Valid acc: 0.6358\n",
      "Epoch 32:\n",
      "Train loss: 0.6777, Train acc: 0.7199\n",
      "Valid loss: 0.8911, Valid acc: 0.6761\n",
      "Epoch 33:\n",
      "Train loss: 0.6504, Train acc: 0.7384\n",
      "Valid loss: 0.9905, Valid acc: 0.6294\n",
      "Epoch 34:\n",
      "Train loss: 0.6335, Train acc: 0.7384\n",
      "Valid loss: 0.8899, Valid acc: 0.6716\n",
      "Epoch 35:\n",
      "Train loss: 0.6233, Train acc: 0.7572\n",
      "Valid loss: 0.8739, Valid acc: 0.7110\n",
      "Epoch 36:\n",
      "Train loss: 0.6360, Train acc: 0.7531\n",
      "Valid loss: 0.8475, Valid acc: 0.6972\n",
      "Epoch 37:\n",
      "Train loss: 0.5992, Train acc: 0.7749\n",
      "Valid loss: 0.9059, Valid acc: 0.6450\n",
      "Epoch 38:\n",
      "Train loss: 0.5871, Train acc: 0.7813\n",
      "Valid loss: 0.8514, Valid acc: 0.6908\n",
      "Epoch 39:\n",
      "Train loss: 0.5613, Train acc: 0.8136\n",
      "Valid loss: 0.8797, Valid acc: 0.7174\n",
      "Epoch 40:\n",
      "Train loss: 0.5316, Train acc: 0.8290\n",
      "Valid loss: 0.8128, Valid acc: 0.7404\n",
      "Epoch 41:\n",
      "Train loss: 0.5220, Train acc: 0.8363\n",
      "Valid loss: 0.7487, Valid acc: 0.7789\n",
      "Epoch 42:\n",
      "Train loss: 0.4777, Train acc: 0.8544\n",
      "Valid loss: 0.7626, Valid acc: 0.7771\n",
      "Epoch 43:\n",
      "Train loss: 0.4850, Train acc: 0.8542\n",
      "Valid loss: 0.8265, Valid acc: 0.7550\n",
      "Epoch 44:\n",
      "Train loss: 0.4447, Train acc: 0.8716\n",
      "Valid loss: 0.8197, Valid acc: 0.7651\n",
      "Epoch 45:\n",
      "Train loss: 0.4523, Train acc: 0.8737\n",
      "Valid loss: 0.8376, Valid acc: 0.7560\n",
      "Epoch 46:\n",
      "Train loss: 0.4193, Train acc: 0.8845\n",
      "Valid loss: 0.7706, Valid acc: 0.7972\n",
      "Epoch 47:\n",
      "Train loss: 0.3959, Train acc: 0.8923\n",
      "Valid loss: 0.7537, Valid acc: 0.7890\n",
      "Epoch 48:\n",
      "Train loss: 0.4092, Train acc: 0.8881\n",
      "Valid loss: 0.7171, Valid acc: 0.8009\n",
      "Epoch 49:\n",
      "Train loss: 0.3626, Train acc: 0.9037\n",
      "Valid loss: 0.8408, Valid acc: 0.7761\n",
      "Epoch 50:\n",
      "Train loss: 0.3653, Train acc: 0.9037\n",
      "Valid loss: 0.7346, Valid acc: 0.8083\n",
      "Epoch 51:\n",
      "Train loss: 0.3652, Train acc: 0.9044\n",
      "Valid loss: 0.7441, Valid acc: 0.8028\n",
      "Epoch 52:\n",
      "Train loss: 0.3503, Train acc: 0.9090\n",
      "Valid loss: 0.7488, Valid acc: 0.8083\n",
      "Epoch 53:\n",
      "Train loss: 0.3489, Train acc: 0.9113\n",
      "Valid loss: 0.6957, Valid acc: 0.8183\n",
      "Epoch 54:\n",
      "Train loss: 0.3161, Train acc: 0.9179\n",
      "Valid loss: 0.9676, Valid acc: 0.7156\n",
      "Epoch 55:\n",
      "Train loss: 0.3093, Train acc: 0.9237\n",
      "Valid loss: 0.8217, Valid acc: 0.7743\n",
      "Epoch 56:\n",
      "Train loss: 0.3186, Train acc: 0.9188\n",
      "Valid loss: 0.7073, Valid acc: 0.8193\n",
      "Epoch 57:\n",
      "Train loss: 0.3054, Train acc: 0.9246\n",
      "Valid loss: 0.6991, Valid acc: 0.8183\n",
      "Epoch 58:\n",
      "Train loss: 0.3107, Train acc: 0.9225\n",
      "Valid loss: 0.7227, Valid acc: 0.8119\n",
      "Epoch 59:\n",
      "Train loss: 0.3045, Train acc: 0.9237\n",
      "Valid loss: 0.6649, Valid acc: 0.8303\n",
      "Epoch 60:\n",
      "Train loss: 0.2764, Train acc: 0.9305\n",
      "Valid loss: 0.6642, Valid acc: 0.8312\n",
      "Epoch 61:\n",
      "Train loss: 0.2552, Train acc: 0.9360\n",
      "Valid loss: 0.7708, Valid acc: 0.8083\n",
      "Epoch 62:\n",
      "Train loss: 0.2772, Train acc: 0.9317\n",
      "Valid loss: 0.6904, Valid acc: 0.8183\n",
      "Epoch 63:\n",
      "Train loss: 0.2634, Train acc: 0.9324\n",
      "Valid loss: 0.7805, Valid acc: 0.7972\n",
      "Epoch 64:\n",
      "Train loss: 0.2612, Train acc: 0.9349\n",
      "Valid loss: 0.8254, Valid acc: 0.7945\n",
      "Epoch 65:\n",
      "Train loss: 0.2753, Train acc: 0.9301\n",
      "Valid loss: 0.6737, Valid acc: 0.8239\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy L2 Regularization (Dropout: 0.0, Weight Decay: 1e-05, Max Norm: 0.0): 0.8500\n",
      "Testing L2 Regularization with weight decay: 5e-05\n",
      "Epoch 1:\n",
      "Train loss: 1.6584, Train acc: 0.2238\n",
      "Valid loss: 1.6479, Valid acc: 0.2303\n",
      "Epoch 2:\n",
      "Train loss: 1.6487, Train acc: 0.2309\n",
      "Valid loss: 1.6476, Valid acc: 0.2394\n",
      "Epoch 3:\n",
      "Train loss: 1.6433, Train acc: 0.2455\n",
      "Valid loss: 1.6477, Valid acc: 0.2459\n",
      "Epoch 4:\n",
      "Train loss: 1.6453, Train acc: 0.2393\n",
      "Valid loss: 1.6401, Valid acc: 0.2688\n",
      "Epoch 5:\n",
      "Train loss: 1.5744, Train acc: 0.3207\n",
      "Valid loss: 1.5027, Valid acc: 0.3835\n",
      "Epoch 6:\n",
      "Train loss: 1.4796, Train acc: 0.3838\n",
      "Valid loss: 1.4559, Valid acc: 0.3936\n",
      "Epoch 7:\n",
      "Train loss: 1.3998, Train acc: 0.4074\n",
      "Valid loss: 1.3934, Valid acc: 0.4349\n",
      "Epoch 8:\n",
      "Train loss: 1.3439, Train acc: 0.4365\n",
      "Valid loss: 1.3943, Valid acc: 0.4367\n",
      "Epoch 9:\n",
      "Train loss: 1.2694, Train acc: 0.4677\n",
      "Valid loss: 1.3736, Valid acc: 0.4541\n",
      "Epoch 10:\n",
      "Train loss: 1.2199, Train acc: 0.4977\n",
      "Valid loss: 1.2293, Valid acc: 0.5165\n",
      "Epoch 11:\n",
      "Train loss: 1.1601, Train acc: 0.5229\n",
      "Valid loss: 1.4117, Valid acc: 0.4569\n",
      "Epoch 12:\n",
      "Train loss: 1.1388, Train acc: 0.5468\n",
      "Valid loss: 1.1766, Valid acc: 0.5394\n",
      "Epoch 13:\n",
      "Train loss: 1.1115, Train acc: 0.5575\n",
      "Valid loss: 1.2655, Valid acc: 0.5183\n",
      "Epoch 14:\n",
      "Train loss: 1.0773, Train acc: 0.5766\n",
      "Valid loss: 1.0900, Valid acc: 0.5706\n",
      "Epoch 15:\n",
      "Train loss: 1.0277, Train acc: 0.6039\n",
      "Valid loss: 1.0719, Valid acc: 0.5615\n",
      "Epoch 16:\n",
      "Train loss: 1.0167, Train acc: 0.5901\n",
      "Valid loss: 1.1619, Valid acc: 0.5670\n",
      "Epoch 17:\n",
      "Train loss: 0.9869, Train acc: 0.6183\n",
      "Valid loss: 1.0377, Valid acc: 0.6028\n",
      "Epoch 18:\n",
      "Train loss: 0.9384, Train acc: 0.6392\n",
      "Valid loss: 1.0172, Valid acc: 0.6284\n",
      "Epoch 19:\n",
      "Train loss: 0.9308, Train acc: 0.6447\n",
      "Valid loss: 1.0669, Valid acc: 0.6073\n",
      "Epoch 20:\n",
      "Train loss: 0.9022, Train acc: 0.6664\n",
      "Valid loss: 1.1400, Valid acc: 0.5606\n",
      "Epoch 21:\n",
      "Train loss: 0.8845, Train acc: 0.6692\n",
      "Valid loss: 0.9636, Valid acc: 0.6431\n",
      "Epoch 22:\n",
      "Train loss: 0.8747, Train acc: 0.6836\n",
      "Valid loss: 1.0391, Valid acc: 0.6587\n",
      "Epoch 23:\n",
      "Train loss: 0.8271, Train acc: 0.7059\n",
      "Valid loss: 0.9965, Valid acc: 0.6239\n",
      "Epoch 24:\n",
      "Train loss: 0.8240, Train acc: 0.7079\n",
      "Valid loss: 0.9728, Valid acc: 0.6560\n",
      "Epoch 25:\n",
      "Train loss: 0.7981, Train acc: 0.7341\n",
      "Valid loss: 0.9228, Valid acc: 0.7009\n",
      "Epoch 26:\n",
      "Train loss: 0.7711, Train acc: 0.7403\n",
      "Valid loss: 1.0168, Valid acc: 0.6514\n",
      "Epoch 27:\n",
      "Train loss: 0.7307, Train acc: 0.7705\n",
      "Valid loss: 0.8549, Valid acc: 0.7312\n",
      "Epoch 28:\n",
      "Train loss: 0.7329, Train acc: 0.7529\n",
      "Valid loss: 0.8229, Valid acc: 0.7376\n",
      "Epoch 29:\n",
      "Train loss: 0.6485, Train acc: 0.8028\n",
      "Valid loss: 0.8159, Valid acc: 0.7294\n",
      "Epoch 30:\n",
      "Train loss: 0.6422, Train acc: 0.8028\n",
      "Valid loss: 0.8913, Valid acc: 0.7312\n",
      "Epoch 31:\n",
      "Train loss: 0.6316, Train acc: 0.8116\n",
      "Valid loss: 0.7886, Valid acc: 0.7339\n",
      "Epoch 32:\n",
      "Train loss: 0.5920, Train acc: 0.8216\n",
      "Valid loss: 0.7931, Valid acc: 0.7798\n",
      "Epoch 33:\n",
      "Train loss: 0.5999, Train acc: 0.8237\n",
      "Valid loss: 0.7864, Valid acc: 0.7523\n",
      "Epoch 34:\n",
      "Train loss: 0.5989, Train acc: 0.8265\n",
      "Valid loss: 0.8360, Valid acc: 0.7312\n",
      "Epoch 35:\n",
      "Train loss: 0.5505, Train acc: 0.8462\n",
      "Valid loss: 0.7510, Valid acc: 0.7826\n",
      "Epoch 36:\n",
      "Train loss: 0.5315, Train acc: 0.8524\n",
      "Valid loss: 0.7389, Valid acc: 0.7853\n",
      "Epoch 37:\n",
      "Train loss: 0.5162, Train acc: 0.8565\n",
      "Valid loss: 0.8984, Valid acc: 0.7440\n",
      "Epoch 38:\n",
      "Train loss: 0.5249, Train acc: 0.8501\n",
      "Valid loss: 1.7331, Valid acc: 0.4220\n",
      "Epoch 39:\n",
      "Train loss: 0.4852, Train acc: 0.8700\n",
      "Valid loss: 0.7499, Valid acc: 0.7853\n",
      "Epoch 40:\n",
      "Train loss: 0.5222, Train acc: 0.8569\n",
      "Valid loss: 0.8191, Valid acc: 0.7587\n",
      "Epoch 41:\n",
      "Train loss: 0.4815, Train acc: 0.8682\n",
      "Valid loss: 0.8889, Valid acc: 0.7147\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy L2 Regularization (Dropout: 0.0, Weight Decay: 5e-05, Max Norm: 0.0): 0.7440\n",
      "Testing L2 Regularization with weight decay: 0.0001\n",
      "Epoch 1:\n",
      "Train loss: 1.6569, Train acc: 0.2274\n",
      "Valid loss: 1.6581, Valid acc: 0.2477\n",
      "Epoch 2:\n",
      "Train loss: 1.6493, Train acc: 0.2304\n",
      "Valid loss: 1.6518, Valid acc: 0.2495\n",
      "Epoch 3:\n",
      "Train loss: 1.6436, Train acc: 0.2393\n",
      "Valid loss: 1.6712, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6422, Train acc: 0.2414\n",
      "Valid loss: 1.6506, Valid acc: 0.2569\n",
      "Epoch 5:\n",
      "Train loss: 1.6374, Train acc: 0.2483\n",
      "Valid loss: 1.6333, Valid acc: 0.2862\n",
      "Epoch 6:\n",
      "Train loss: 1.5250, Train acc: 0.3560\n",
      "Valid loss: 1.4771, Valid acc: 0.3991\n",
      "Epoch 7:\n",
      "Train loss: 1.4537, Train acc: 0.3877\n",
      "Valid loss: 1.4585, Valid acc: 0.3917\n",
      "Epoch 8:\n",
      "Train loss: 1.3922, Train acc: 0.4062\n",
      "Valid loss: 1.4814, Valid acc: 0.3917\n",
      "Epoch 9:\n",
      "Train loss: 1.3183, Train acc: 0.4321\n",
      "Valid loss: 1.3369, Valid acc: 0.4413\n",
      "Epoch 10:\n",
      "Train loss: 1.2511, Train acc: 0.4691\n",
      "Valid loss: 1.2337, Valid acc: 0.4991\n",
      "Epoch 11:\n",
      "Train loss: 1.1747, Train acc: 0.5199\n",
      "Valid loss: 1.2093, Valid acc: 0.5275\n",
      "Epoch 12:\n",
      "Train loss: 1.1383, Train acc: 0.5314\n",
      "Valid loss: 1.2675, Valid acc: 0.4881\n",
      "Epoch 13:\n",
      "Train loss: 1.0888, Train acc: 0.5702\n",
      "Valid loss: 1.0747, Valid acc: 0.6028\n",
      "Epoch 14:\n",
      "Train loss: 1.0212, Train acc: 0.6128\n",
      "Valid loss: 1.0031, Valid acc: 0.6275\n",
      "Epoch 15:\n",
      "Train loss: 0.9785, Train acc: 0.6339\n",
      "Valid loss: 1.0304, Valid acc: 0.6349\n",
      "Epoch 16:\n",
      "Train loss: 0.9110, Train acc: 0.6660\n",
      "Valid loss: 0.9276, Valid acc: 0.6514\n",
      "Epoch 17:\n",
      "Train loss: 0.8773, Train acc: 0.6832\n",
      "Valid loss: 0.9328, Valid acc: 0.6450\n",
      "Epoch 18:\n",
      "Train loss: 0.8495, Train acc: 0.7070\n",
      "Valid loss: 0.8665, Valid acc: 0.7064\n",
      "Epoch 19:\n",
      "Train loss: 0.8376, Train acc: 0.7013\n",
      "Valid loss: 0.8681, Valid acc: 0.7028\n",
      "Epoch 20:\n",
      "Train loss: 0.7716, Train acc: 0.7304\n",
      "Valid loss: 1.0449, Valid acc: 0.6477\n",
      "Epoch 21:\n",
      "Train loss: 0.7687, Train acc: 0.7437\n",
      "Valid loss: 0.8823, Valid acc: 0.6651\n",
      "Epoch 22:\n",
      "Train loss: 0.7329, Train acc: 0.7735\n",
      "Valid loss: 0.8220, Valid acc: 0.7413\n",
      "Epoch 23:\n",
      "Train loss: 0.6956, Train acc: 0.7792\n",
      "Valid loss: 1.2582, Valid acc: 0.5550\n",
      "Epoch 24:\n",
      "Train loss: 0.6666, Train acc: 0.7962\n",
      "Valid loss: 0.7628, Valid acc: 0.7679\n",
      "Epoch 25:\n",
      "Train loss: 0.6698, Train acc: 0.8022\n",
      "Valid loss: 0.8909, Valid acc: 0.7083\n",
      "Epoch 26:\n",
      "Train loss: 0.6226, Train acc: 0.8138\n",
      "Valid loss: 0.7662, Valid acc: 0.7550\n",
      "Epoch 27:\n",
      "Train loss: 0.5999, Train acc: 0.8228\n",
      "Valid loss: 0.7226, Valid acc: 0.7661\n",
      "Epoch 28:\n",
      "Train loss: 0.5907, Train acc: 0.8251\n",
      "Valid loss: 0.7267, Valid acc: 0.7706\n",
      "Epoch 29:\n",
      "Train loss: 0.6072, Train acc: 0.8200\n",
      "Valid loss: 0.7800, Valid acc: 0.7532\n",
      "Epoch 30:\n",
      "Train loss: 0.5480, Train acc: 0.8469\n",
      "Valid loss: 0.8618, Valid acc: 0.7257\n",
      "Epoch 31:\n",
      "Train loss: 0.5441, Train acc: 0.8457\n",
      "Valid loss: 0.6811, Valid acc: 0.7872\n",
      "Epoch 32:\n",
      "Train loss: 0.6363, Train acc: 0.8166\n",
      "Valid loss: 0.7350, Valid acc: 0.7761\n",
      "Epoch 33:\n",
      "Train loss: 0.5227, Train acc: 0.8537\n",
      "Valid loss: 0.8644, Valid acc: 0.7239\n",
      "Epoch 34:\n",
      "Train loss: 0.5080, Train acc: 0.8576\n",
      "Valid loss: 1.0431, Valid acc: 0.6761\n",
      "Epoch 35:\n",
      "Train loss: 0.5065, Train acc: 0.8576\n",
      "Valid loss: 0.9886, Valid acc: 0.7275\n",
      "Epoch 36:\n",
      "Train loss: 0.4984, Train acc: 0.8618\n",
      "Valid loss: 0.7131, Valid acc: 0.7963\n",
      "Epoch 37:\n",
      "Train loss: 0.4693, Train acc: 0.8757\n",
      "Valid loss: 0.7895, Valid acc: 0.7670\n",
      "Epoch 38:\n",
      "Train loss: 0.4788, Train acc: 0.8661\n",
      "Valid loss: 0.7588, Valid acc: 0.7734\n",
      "Epoch 39:\n",
      "Train loss: 0.4608, Train acc: 0.8732\n",
      "Valid loss: 0.7527, Valid acc: 0.7752\n",
      "Epoch 40:\n",
      "Train loss: 0.4286, Train acc: 0.8881\n",
      "Valid loss: 0.8207, Valid acc: 0.7789\n",
      "Epoch 41:\n",
      "Train loss: 0.4241, Train acc: 0.8904\n",
      "Valid loss: 0.6789, Valid acc: 0.8202\n",
      "Epoch 42:\n",
      "Train loss: 0.4310, Train acc: 0.8858\n",
      "Valid loss: 1.0618, Valid acc: 0.6963\n",
      "Epoch 43:\n",
      "Train loss: 0.4167, Train acc: 0.8932\n",
      "Valid loss: 0.7222, Valid acc: 0.8092\n",
      "Epoch 44:\n",
      "Train loss: 0.4065, Train acc: 0.8932\n",
      "Valid loss: 1.0010, Valid acc: 0.7156\n",
      "Epoch 45:\n",
      "Train loss: 0.4083, Train acc: 0.8959\n",
      "Valid loss: 0.7751, Valid acc: 0.7963\n",
      "Epoch 46:\n",
      "Train loss: 0.3730, Train acc: 0.9046\n",
      "Valid loss: 0.7153, Valid acc: 0.8028\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy L2 Regularization (Dropout: 0.0, Weight Decay: 0.0001, Max Norm: 0.0): 0.8260\n",
      "Testing L2 Regularization with weight decay: 0.0005\n",
      "Epoch 1:\n",
      "Train loss: 1.6595, Train acc: 0.2217\n",
      "Valid loss: 1.6507, Valid acc: 0.2459\n",
      "Epoch 2:\n",
      "Train loss: 1.6472, Train acc: 0.2290\n",
      "Valid loss: 1.6530, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6442, Train acc: 0.2384\n",
      "Valid loss: 1.6514, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6226, Train acc: 0.2769\n",
      "Valid loss: 1.5658, Valid acc: 0.3450\n",
      "Epoch 5:\n",
      "Train loss: 1.5096, Train acc: 0.3847\n",
      "Valid loss: 1.5177, Valid acc: 0.3826\n",
      "Epoch 6:\n",
      "Train loss: 1.4714, Train acc: 0.3966\n",
      "Valid loss: 1.4820, Valid acc: 0.4028\n",
      "Epoch 7:\n",
      "Train loss: 1.4194, Train acc: 0.4138\n",
      "Valid loss: 1.4136, Valid acc: 0.4193\n",
      "Epoch 8:\n",
      "Train loss: 1.3418, Train acc: 0.4482\n",
      "Valid loss: 1.3530, Valid acc: 0.4550\n",
      "Epoch 9:\n",
      "Train loss: 1.2822, Train acc: 0.4789\n",
      "Valid loss: 1.2626, Valid acc: 0.4963\n",
      "Epoch 10:\n",
      "Train loss: 1.2238, Train acc: 0.4865\n",
      "Valid loss: 1.2669, Valid acc: 0.4826\n",
      "Epoch 11:\n",
      "Train loss: 1.1775, Train acc: 0.5076\n",
      "Valid loss: 1.3180, Valid acc: 0.4385\n",
      "Epoch 12:\n",
      "Train loss: 1.1686, Train acc: 0.5101\n",
      "Valid loss: 1.3185, Valid acc: 0.4523\n",
      "Epoch 13:\n",
      "Train loss: 1.1313, Train acc: 0.5186\n",
      "Valid loss: 1.1842, Valid acc: 0.4798\n",
      "Epoch 14:\n",
      "Train loss: 1.1100, Train acc: 0.5344\n",
      "Valid loss: 1.5100, Valid acc: 0.4037\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy L2 Regularization (Dropout: 0.0, Weight Decay: 0.0005, Max Norm: 0.0): 0.3040\n",
      "Testing L2 Regularization with weight decay: 0.001\n",
      "Epoch 1:\n",
      "Train loss: 1.6557, Train acc: 0.2322\n",
      "Valid loss: 1.6401, Valid acc: 0.2468\n",
      "Epoch 2:\n",
      "Train loss: 1.6489, Train acc: 0.2249\n",
      "Valid loss: 1.6542, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6450, Train acc: 0.2361\n",
      "Valid loss: 1.6596, Valid acc: 0.2385\n",
      "Epoch 4:\n",
      "Train loss: 1.6446, Train acc: 0.2315\n",
      "Valid loss: 1.6392, Valid acc: 0.2679\n",
      "Epoch 5:\n",
      "Train loss: 1.6315, Train acc: 0.2694\n",
      "Valid loss: 1.5898, Valid acc: 0.3239\n",
      "Epoch 6:\n",
      "Train loss: 1.5012, Train acc: 0.3783\n",
      "Valid loss: 1.4993, Valid acc: 0.3890\n",
      "Epoch 7:\n",
      "Train loss: 1.4558, Train acc: 0.3925\n",
      "Valid loss: 1.4729, Valid acc: 0.3963\n",
      "Epoch 8:\n",
      "Train loss: 1.4075, Train acc: 0.4037\n",
      "Valid loss: 1.4318, Valid acc: 0.4156\n",
      "Epoch 9:\n",
      "Train loss: 1.3282, Train acc: 0.4420\n",
      "Valid loss: 1.2949, Valid acc: 0.4578\n",
      "Epoch 10:\n",
      "Train loss: 1.2484, Train acc: 0.4780\n",
      "Valid loss: 1.2633, Valid acc: 0.5211\n",
      "Epoch 11:\n",
      "Train loss: 1.1853, Train acc: 0.5248\n",
      "Valid loss: 1.2183, Valid acc: 0.5046\n",
      "Epoch 12:\n",
      "Train loss: 1.1138, Train acc: 0.5658\n",
      "Valid loss: 1.1544, Valid acc: 0.5826\n",
      "Epoch 13:\n",
      "Train loss: 1.0607, Train acc: 0.5947\n",
      "Valid loss: 1.0756, Valid acc: 0.6073\n",
      "Epoch 14:\n",
      "Train loss: 1.0117, Train acc: 0.6071\n",
      "Valid loss: 1.0032, Valid acc: 0.6339\n",
      "Epoch 15:\n",
      "Train loss: 0.9749, Train acc: 0.6229\n",
      "Valid loss: 1.0711, Valid acc: 0.5972\n",
      "Epoch 16:\n",
      "Train loss: 0.9535, Train acc: 0.6348\n",
      "Valid loss: 1.0033, Valid acc: 0.6330\n",
      "Epoch 17:\n",
      "Train loss: 0.9127, Train acc: 0.6424\n",
      "Valid loss: 1.0681, Valid acc: 0.6138\n",
      "Epoch 18:\n",
      "Train loss: 0.9217, Train acc: 0.6408\n",
      "Valid loss: 0.9843, Valid acc: 0.6248\n",
      "Epoch 19:\n",
      "Train loss: 0.8860, Train acc: 0.6531\n",
      "Valid loss: 0.9587, Valid acc: 0.6514\n",
      "Epoch 20:\n",
      "Train loss: 0.8586, Train acc: 0.6467\n",
      "Valid loss: 0.9879, Valid acc: 0.6422\n",
      "Epoch 21:\n",
      "Train loss: 0.8394, Train acc: 0.6589\n",
      "Valid loss: 0.9061, Valid acc: 0.6541\n",
      "Epoch 22:\n",
      "Train loss: 0.8162, Train acc: 0.6735\n",
      "Valid loss: 0.9120, Valid acc: 0.6156\n",
      "Epoch 23:\n",
      "Train loss: 0.8090, Train acc: 0.6784\n",
      "Valid loss: 0.8829, Valid acc: 0.6706\n",
      "Epoch 24:\n",
      "Train loss: 0.8020, Train acc: 0.6816\n",
      "Valid loss: 0.9190, Valid acc: 0.6798\n",
      "Epoch 25:\n",
      "Train loss: 0.7725, Train acc: 0.7072\n",
      "Valid loss: 0.8837, Valid acc: 0.6725\n",
      "Epoch 26:\n",
      "Train loss: 0.7595, Train acc: 0.7187\n",
      "Valid loss: 0.9432, Valid acc: 0.6697\n",
      "Epoch 27:\n",
      "Train loss: 0.7365, Train acc: 0.7235\n",
      "Valid loss: 1.0404, Valid acc: 0.5982\n",
      "Epoch 28:\n",
      "Train loss: 0.7343, Train acc: 0.7279\n",
      "Valid loss: 0.8529, Valid acc: 0.7101\n",
      "Epoch 29:\n",
      "Train loss: 0.7027, Train acc: 0.7494\n",
      "Valid loss: 0.8262, Valid acc: 0.7138\n",
      "Epoch 30:\n",
      "Train loss: 0.6863, Train acc: 0.7657\n",
      "Valid loss: 0.8807, Valid acc: 0.6541\n",
      "Epoch 31:\n",
      "Train loss: 0.6410, Train acc: 0.7856\n",
      "Valid loss: 0.9548, Valid acc: 0.6202\n",
      "Epoch 32:\n",
      "Train loss: 0.6559, Train acc: 0.7811\n",
      "Valid loss: 0.8033, Valid acc: 0.7514\n",
      "Epoch 33:\n",
      "Train loss: 0.6139, Train acc: 0.8132\n",
      "Valid loss: 0.8983, Valid acc: 0.7248\n",
      "Epoch 34:\n",
      "Train loss: 0.6180, Train acc: 0.8168\n",
      "Valid loss: 0.7263, Valid acc: 0.7835\n",
      "Epoch 35:\n",
      "Train loss: 0.5946, Train acc: 0.8249\n",
      "Valid loss: 0.7772, Valid acc: 0.7761\n",
      "Epoch 36:\n",
      "Train loss: 0.5336, Train acc: 0.8441\n",
      "Valid loss: 0.7357, Valid acc: 0.7780\n",
      "Epoch 37:\n",
      "Train loss: 0.5334, Train acc: 0.8436\n",
      "Valid loss: 0.9202, Valid acc: 0.7321\n",
      "Epoch 38:\n",
      "Train loss: 0.5141, Train acc: 0.8492\n",
      "Valid loss: 0.7471, Valid acc: 0.7835\n",
      "Epoch 39:\n",
      "Train loss: 0.6185, Train acc: 0.8343\n",
      "Valid loss: 0.8678, Valid acc: 0.7266\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy L2 Regularization (Dropout: 0.0, Weight Decay: 0.001, Max Norm: 0.0): 0.7700\n"
     ]
    }
   ],
   "source": [
    "# Regularisation - L2 Regularization/Weight Decay ONLY (varying values)\n",
    "weight_decay = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]\n",
    "for weight_decay in weight_decay:\n",
    "    print(f\"Testing L2 Regularization with weight decay: {weight_decay}\")\n",
    "    best_reg_technique.append(regularisation_test(weight_decay=weight_decay,dropout=0.0, grad_clip=False, max_norm=0.0, reg_technique=\"L2 Regularization\", optimizer=optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e412dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dropout: 0.2\n",
      "Epoch 1:\n",
      "Train loss: 1.6636, Train acc: 0.2208\n",
      "Valid loss: 1.6569, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6482, Train acc: 0.2279\n",
      "Valid loss: 1.6451, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6407, Train acc: 0.2529\n",
      "Valid loss: 1.6703, Valid acc: 0.2239\n",
      "Epoch 4:\n",
      "Train loss: 1.5601, Train acc: 0.3345\n",
      "Valid loss: 1.5343, Valid acc: 0.3670\n",
      "Epoch 5:\n",
      "Train loss: 1.4475, Train acc: 0.3968\n",
      "Valid loss: 1.7755, Valid acc: 0.2422\n",
      "Epoch 6:\n",
      "Train loss: 1.3761, Train acc: 0.4227\n",
      "Valid loss: 1.3833, Valid acc: 0.4174\n",
      "Epoch 7:\n",
      "Train loss: 1.2784, Train acc: 0.4578\n",
      "Valid loss: 1.2917, Valid acc: 0.4936\n",
      "Epoch 8:\n",
      "Train loss: 1.2137, Train acc: 0.4966\n",
      "Valid loss: 1.2676, Valid acc: 0.4789\n",
      "Epoch 9:\n",
      "Train loss: 1.1489, Train acc: 0.5436\n",
      "Valid loss: 1.2101, Valid acc: 0.4908\n",
      "Epoch 10:\n",
      "Train loss: 1.0948, Train acc: 0.5715\n",
      "Valid loss: 1.1544, Valid acc: 0.5156\n",
      "Epoch 11:\n",
      "Train loss: 1.0508, Train acc: 0.6050\n",
      "Valid loss: 1.0681, Valid acc: 0.6156\n",
      "Epoch 12:\n",
      "Train loss: 0.9855, Train acc: 0.6309\n",
      "Valid loss: 1.0952, Valid acc: 0.5972\n",
      "Epoch 13:\n",
      "Train loss: 0.9717, Train acc: 0.6373\n",
      "Valid loss: 1.2636, Valid acc: 0.5147\n",
      "Epoch 14:\n",
      "Train loss: 0.9206, Train acc: 0.6538\n",
      "Valid loss: 0.9820, Valid acc: 0.6431\n",
      "Epoch 15:\n",
      "Train loss: 0.9083, Train acc: 0.6586\n",
      "Valid loss: 1.0513, Valid acc: 0.6248\n",
      "Epoch 16:\n",
      "Train loss: 0.8775, Train acc: 0.6751\n",
      "Valid loss: 0.9880, Valid acc: 0.6138\n",
      "Epoch 17:\n",
      "Train loss: 0.8508, Train acc: 0.6761\n",
      "Valid loss: 0.9249, Valid acc: 0.6367\n",
      "Epoch 18:\n",
      "Train loss: 0.8279, Train acc: 0.6813\n",
      "Valid loss: 0.9939, Valid acc: 0.6083\n",
      "Epoch 19:\n",
      "Train loss: 0.8415, Train acc: 0.6786\n",
      "Valid loss: 0.9309, Valid acc: 0.6743\n",
      "Epoch 20:\n",
      "Train loss: 0.8047, Train acc: 0.6910\n",
      "Valid loss: 0.8852, Valid acc: 0.6963\n",
      "Epoch 21:\n",
      "Train loss: 0.8102, Train acc: 0.6939\n",
      "Valid loss: 0.9973, Valid acc: 0.6156\n",
      "Epoch 22:\n",
      "Train loss: 0.7932, Train acc: 0.7114\n",
      "Valid loss: 0.8845, Valid acc: 0.6826\n",
      "Epoch 23:\n",
      "Train loss: 0.7515, Train acc: 0.7251\n",
      "Valid loss: 0.8981, Valid acc: 0.6789\n",
      "Epoch 24:\n",
      "Train loss: 0.7321, Train acc: 0.7338\n",
      "Valid loss: 0.8768, Valid acc: 0.6789\n",
      "Epoch 25:\n",
      "Train loss: 0.7083, Train acc: 0.7675\n",
      "Valid loss: 0.9812, Valid acc: 0.6514\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Dropout (Dropout: 0.2, Weight Decay: 0.0, Max Norm: 0.0): 0.6660\n",
      "Testing Dropout: 0.3\n",
      "Epoch 1:\n",
      "Train loss: 1.6633, Train acc: 0.2297\n",
      "Valid loss: 1.6459, Valid acc: 0.2037\n",
      "Epoch 2:\n",
      "Train loss: 1.6528, Train acc: 0.2281\n",
      "Valid loss: 1.6525, Valid acc: 0.2450\n",
      "Epoch 3:\n",
      "Train loss: 1.6522, Train acc: 0.2320\n",
      "Valid loss: 1.6456, Valid acc: 0.2541\n",
      "Epoch 4:\n",
      "Train loss: 1.6471, Train acc: 0.2476\n",
      "Valid loss: 1.6395, Valid acc: 0.2725\n",
      "Epoch 5:\n",
      "Train loss: 1.5987, Train acc: 0.3033\n",
      "Valid loss: 1.5292, Valid acc: 0.3642\n",
      "Epoch 6:\n",
      "Train loss: 1.4888, Train acc: 0.3872\n",
      "Valid loss: 1.4618, Valid acc: 0.4083\n",
      "Epoch 7:\n",
      "Train loss: 1.4362, Train acc: 0.3980\n",
      "Valid loss: 1.4598, Valid acc: 0.4028\n",
      "Epoch 8:\n",
      "Train loss: 1.4258, Train acc: 0.3961\n",
      "Valid loss: 1.3879, Valid acc: 0.4202\n",
      "Epoch 9:\n",
      "Train loss: 1.3405, Train acc: 0.4227\n",
      "Valid loss: 1.3334, Valid acc: 0.4358\n",
      "Epoch 10:\n",
      "Train loss: 1.2669, Train acc: 0.4686\n",
      "Valid loss: 1.3286, Valid acc: 0.4330\n",
      "Epoch 11:\n",
      "Train loss: 1.1974, Train acc: 0.5030\n",
      "Valid loss: 1.2446, Valid acc: 0.5477\n",
      "Epoch 12:\n",
      "Train loss: 1.1298, Train acc: 0.5484\n",
      "Valid loss: 1.1422, Valid acc: 0.5761\n",
      "Epoch 13:\n",
      "Train loss: 1.1281, Train acc: 0.5555\n",
      "Valid loss: 1.2085, Valid acc: 0.5468\n",
      "Epoch 14:\n",
      "Train loss: 1.0481, Train acc: 0.5876\n",
      "Valid loss: 1.1135, Valid acc: 0.5954\n",
      "Epoch 15:\n",
      "Train loss: 0.9816, Train acc: 0.6165\n",
      "Valid loss: 1.0058, Valid acc: 0.6266\n",
      "Epoch 16:\n",
      "Train loss: 0.9447, Train acc: 0.6323\n",
      "Valid loss: 1.0316, Valid acc: 0.6193\n",
      "Epoch 17:\n",
      "Train loss: 0.9075, Train acc: 0.6456\n",
      "Valid loss: 0.9865, Valid acc: 0.6367\n",
      "Epoch 18:\n",
      "Train loss: 0.8865, Train acc: 0.6566\n",
      "Valid loss: 1.1028, Valid acc: 0.5798\n",
      "Epoch 19:\n",
      "Train loss: 0.8562, Train acc: 0.6566\n",
      "Valid loss: 1.0836, Valid acc: 0.5945\n",
      "Epoch 20:\n",
      "Train loss: 0.8667, Train acc: 0.6653\n",
      "Valid loss: 0.8963, Valid acc: 0.6688\n",
      "Epoch 21:\n",
      "Train loss: 0.8350, Train acc: 0.6751\n",
      "Valid loss: 1.0436, Valid acc: 0.6394\n",
      "Epoch 22:\n",
      "Train loss: 0.7902, Train acc: 0.6981\n",
      "Valid loss: 0.8908, Valid acc: 0.6991\n",
      "Epoch 23:\n",
      "Train loss: 0.7888, Train acc: 0.6816\n",
      "Valid loss: 0.9014, Valid acc: 0.6477\n",
      "Epoch 24:\n",
      "Train loss: 0.7459, Train acc: 0.7196\n",
      "Valid loss: 0.8958, Valid acc: 0.7064\n",
      "Epoch 25:\n",
      "Train loss: 0.7460, Train acc: 0.7180\n",
      "Valid loss: 0.9599, Valid acc: 0.6862\n",
      "Epoch 26:\n",
      "Train loss: 0.7302, Train acc: 0.7320\n",
      "Valid loss: 0.8425, Valid acc: 0.7266\n",
      "Epoch 27:\n",
      "Train loss: 0.7211, Train acc: 0.7508\n",
      "Valid loss: 0.9214, Valid acc: 0.6367\n",
      "Epoch 28:\n",
      "Train loss: 0.6889, Train acc: 0.7575\n",
      "Valid loss: 0.8683, Valid acc: 0.6826\n",
      "Epoch 29:\n",
      "Train loss: 0.6430, Train acc: 0.7852\n",
      "Valid loss: 0.8133, Valid acc: 0.7514\n",
      "Epoch 30:\n",
      "Train loss: 0.6451, Train acc: 0.7905\n",
      "Valid loss: 0.9121, Valid acc: 0.7220\n",
      "Epoch 31:\n",
      "Train loss: 0.6198, Train acc: 0.8088\n",
      "Valid loss: 0.7916, Valid acc: 0.7569\n",
      "Epoch 32:\n",
      "Train loss: 0.5609, Train acc: 0.8306\n",
      "Valid loss: 0.8376, Valid acc: 0.7422\n",
      "Epoch 33:\n",
      "Train loss: 0.5647, Train acc: 0.8370\n",
      "Valid loss: 0.7397, Valid acc: 0.7881\n",
      "Epoch 34:\n",
      "Train loss: 0.5544, Train acc: 0.8377\n",
      "Valid loss: 0.8248, Valid acc: 0.7633\n",
      "Epoch 35:\n",
      "Train loss: 0.5791, Train acc: 0.8290\n",
      "Valid loss: 0.8584, Valid acc: 0.7587\n",
      "Epoch 36:\n",
      "Train loss: 0.4953, Train acc: 0.8556\n",
      "Valid loss: 0.7346, Valid acc: 0.7881\n",
      "Epoch 37:\n",
      "Train loss: 0.4867, Train acc: 0.8634\n",
      "Valid loss: 0.7825, Valid acc: 0.7642\n",
      "Epoch 38:\n",
      "Train loss: 0.4816, Train acc: 0.8631\n",
      "Valid loss: 0.7397, Valid acc: 0.7862\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Dropout (Dropout: 0.3, Weight Decay: 0.0, Max Norm: 0.0): 0.8180\n",
      "Testing Dropout: 0.4\n",
      "Epoch 1:\n",
      "Train loss: 1.6645, Train acc: 0.2302\n",
      "Valid loss: 1.6489, Valid acc: 0.2358\n",
      "Epoch 2:\n",
      "Train loss: 1.6514, Train acc: 0.2370\n",
      "Valid loss: 1.6683, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6506, Train acc: 0.2387\n",
      "Valid loss: 1.6437, Valid acc: 0.2477\n",
      "Epoch 4:\n",
      "Train loss: 1.6106, Train acc: 0.2909\n",
      "Valid loss: 1.6124, Valid acc: 0.3128\n",
      "Epoch 5:\n",
      "Train loss: 1.4756, Train acc: 0.3838\n",
      "Valid loss: 1.4525, Valid acc: 0.3908\n",
      "Epoch 6:\n",
      "Train loss: 1.4338, Train acc: 0.3904\n",
      "Valid loss: 1.4432, Valid acc: 0.4009\n",
      "Epoch 7:\n",
      "Train loss: 1.3904, Train acc: 0.4026\n",
      "Valid loss: 1.3724, Valid acc: 0.4321\n",
      "Epoch 8:\n",
      "Train loss: 1.3303, Train acc: 0.4294\n",
      "Valid loss: 1.3323, Valid acc: 0.4404\n",
      "Epoch 9:\n",
      "Train loss: 1.2656, Train acc: 0.4544\n",
      "Valid loss: 1.4354, Valid acc: 0.4505\n",
      "Epoch 10:\n",
      "Train loss: 1.2354, Train acc: 0.4782\n",
      "Valid loss: 1.5122, Valid acc: 0.3734\n",
      "Epoch 11:\n",
      "Train loss: 1.1555, Train acc: 0.5126\n",
      "Valid loss: 1.1981, Valid acc: 0.5174\n",
      "Epoch 12:\n",
      "Train loss: 1.0967, Train acc: 0.5628\n",
      "Valid loss: 1.1734, Valid acc: 0.5202\n",
      "Epoch 13:\n",
      "Train loss: 1.0566, Train acc: 0.5830\n",
      "Valid loss: 1.1159, Valid acc: 0.5450\n",
      "Epoch 14:\n",
      "Train loss: 0.9981, Train acc: 0.6190\n",
      "Valid loss: 1.0561, Valid acc: 0.6202\n",
      "Epoch 15:\n",
      "Train loss: 0.9427, Train acc: 0.6385\n",
      "Valid loss: 0.9967, Valid acc: 0.6422\n",
      "Epoch 16:\n",
      "Train loss: 0.9051, Train acc: 0.6616\n",
      "Valid loss: 1.0321, Valid acc: 0.6193\n",
      "Epoch 17:\n",
      "Train loss: 0.8598, Train acc: 0.6845\n",
      "Valid loss: 0.9653, Valid acc: 0.6514\n",
      "Epoch 18:\n",
      "Train loss: 0.8219, Train acc: 0.7027\n",
      "Valid loss: 0.9730, Valid acc: 0.6743\n",
      "Epoch 19:\n",
      "Train loss: 0.8049, Train acc: 0.7199\n",
      "Valid loss: 0.9053, Valid acc: 0.6908\n",
      "Epoch 20:\n",
      "Train loss: 0.7591, Train acc: 0.7412\n",
      "Valid loss: 0.9925, Valid acc: 0.6541\n",
      "Epoch 21:\n",
      "Train loss: 0.7820, Train acc: 0.7338\n",
      "Valid loss: 0.9055, Valid acc: 0.6936\n",
      "Epoch 22:\n",
      "Train loss: 0.7057, Train acc: 0.7707\n",
      "Valid loss: 0.8332, Valid acc: 0.7303\n",
      "Epoch 23:\n",
      "Train loss: 0.7030, Train acc: 0.7827\n",
      "Valid loss: 0.8155, Valid acc: 0.7569\n",
      "Epoch 24:\n",
      "Train loss: 0.6956, Train acc: 0.7873\n",
      "Valid loss: 0.7729, Valid acc: 0.7550\n",
      "Epoch 25:\n",
      "Train loss: 0.6680, Train acc: 0.8003\n",
      "Valid loss: 0.8172, Valid acc: 0.7477\n",
      "Epoch 26:\n",
      "Train loss: 0.6147, Train acc: 0.8189\n",
      "Valid loss: 0.7424, Valid acc: 0.7807\n",
      "Epoch 27:\n",
      "Train loss: 0.6127, Train acc: 0.8198\n",
      "Valid loss: 0.7816, Valid acc: 0.7541\n",
      "Epoch 28:\n",
      "Train loss: 0.5946, Train acc: 0.8262\n",
      "Valid loss: 0.7688, Valid acc: 0.7615\n",
      "Epoch 29:\n",
      "Train loss: 0.6136, Train acc: 0.8198\n",
      "Valid loss: 0.7476, Valid acc: 0.7615\n",
      "Epoch 30:\n",
      "Train loss: 0.5643, Train acc: 0.8409\n",
      "Valid loss: 0.7581, Valid acc: 0.7706\n",
      "Epoch 31:\n",
      "Train loss: 0.5573, Train acc: 0.8446\n",
      "Valid loss: 0.7982, Valid acc: 0.7743\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Dropout (Dropout: 0.4, Weight Decay: 0.0, Max Norm: 0.0): 0.8240\n"
     ]
    }
   ],
   "source": [
    "# Regularisation - Dropout ONLY (varying values)\n",
    "dropout = [0.2, 0.3, 0.4]\n",
    "for dropout in dropout:\n",
    "    print(f\"Testing Dropout: {dropout}\")\n",
    "    best_reg_technique.append(regularisation_test(weight_decay=0.0,dropout=dropout, grad_clip=False, max_norm=0.0, reg_technique=\"Dropout\", optimizer=optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "500d83f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Gradient Clipping with Value: 0.1\n",
      "Epoch 1:\n",
      "Train loss: 1.6579, Train acc: 0.2260\n",
      "Valid loss: 1.6577, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6464, Train acc: 0.2293\n",
      "Valid loss: 1.6461, Valid acc: 0.2394\n",
      "Epoch 3:\n",
      "Train loss: 1.6426, Train acc: 0.2490\n",
      "Valid loss: 1.6410, Valid acc: 0.2587\n",
      "Epoch 4:\n",
      "Train loss: 1.5477, Train acc: 0.3434\n",
      "Valid loss: 1.5152, Valid acc: 0.3725\n",
      "Epoch 5:\n",
      "Train loss: 1.4531, Train acc: 0.4014\n",
      "Valid loss: 1.4322, Valid acc: 0.4101\n",
      "Epoch 6:\n",
      "Train loss: 1.3750, Train acc: 0.4211\n",
      "Valid loss: 1.3843, Valid acc: 0.4174\n",
      "Epoch 7:\n",
      "Train loss: 1.2733, Train acc: 0.4548\n",
      "Valid loss: 1.3709, Valid acc: 0.4358\n",
      "Epoch 8:\n",
      "Train loss: 1.2207, Train acc: 0.4888\n",
      "Valid loss: 1.2932, Valid acc: 0.4789\n",
      "Epoch 9:\n",
      "Train loss: 1.1593, Train acc: 0.5248\n",
      "Valid loss: 1.2747, Valid acc: 0.4514\n",
      "Epoch 10:\n",
      "Train loss: 1.1060, Train acc: 0.5596\n",
      "Valid loss: 1.2322, Valid acc: 0.5220\n",
      "Epoch 11:\n",
      "Train loss: 1.0412, Train acc: 0.5896\n",
      "Valid loss: 1.0734, Valid acc: 0.5789\n",
      "Epoch 12:\n",
      "Train loss: 0.9931, Train acc: 0.6169\n",
      "Valid loss: 1.1402, Valid acc: 0.5844\n",
      "Epoch 13:\n",
      "Train loss: 0.9761, Train acc: 0.6282\n",
      "Valid loss: 0.9771, Valid acc: 0.6156\n",
      "Epoch 14:\n",
      "Train loss: 0.9415, Train acc: 0.6476\n",
      "Valid loss: 1.0395, Valid acc: 0.6018\n",
      "Epoch 15:\n",
      "Train loss: 0.8993, Train acc: 0.6706\n",
      "Valid loss: 0.9459, Valid acc: 0.6587\n",
      "Epoch 16:\n",
      "Train loss: 0.8831, Train acc: 0.6751\n",
      "Valid loss: 1.0240, Valid acc: 0.6220\n",
      "Epoch 17:\n",
      "Train loss: 0.8613, Train acc: 0.6898\n",
      "Valid loss: 0.9307, Valid acc: 0.6752\n",
      "Epoch 18:\n",
      "Train loss: 0.8298, Train acc: 0.7160\n",
      "Valid loss: 1.1711, Valid acc: 0.6028\n",
      "Epoch 19:\n",
      "Train loss: 0.8300, Train acc: 0.7240\n",
      "Valid loss: 0.9371, Valid acc: 0.6917\n",
      "Epoch 20:\n",
      "Train loss: 0.7879, Train acc: 0.7393\n",
      "Valid loss: 1.1487, Valid acc: 0.6468\n",
      "Epoch 21:\n",
      "Train loss: 0.7666, Train acc: 0.7536\n",
      "Valid loss: 1.1252, Valid acc: 0.6670\n",
      "Epoch 22:\n",
      "Train loss: 0.7474, Train acc: 0.7712\n",
      "Valid loss: 0.8899, Valid acc: 0.7349\n",
      "Epoch 23:\n",
      "Train loss: 0.7532, Train acc: 0.7680\n",
      "Valid loss: 0.8924, Valid acc: 0.7193\n",
      "Epoch 24:\n",
      "Train loss: 0.7213, Train acc: 0.7801\n",
      "Valid loss: 0.8749, Valid acc: 0.7183\n",
      "Epoch 25:\n",
      "Train loss: 0.7022, Train acc: 0.7882\n",
      "Valid loss: 1.1468, Valid acc: 0.6083\n",
      "Epoch 26:\n",
      "Train loss: 0.6867, Train acc: 0.8006\n",
      "Valid loss: 0.8800, Valid acc: 0.7303\n",
      "Epoch 27:\n",
      "Train loss: 0.6789, Train acc: 0.8035\n",
      "Valid loss: 0.9108, Valid acc: 0.7220\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Gradient Clipping (Dropout: 0.0, Weight Decay: 0.0, Max Norm: 0.1): 0.7860\n",
      "Testing Gradient Clipping with Value: 0.5\n",
      "Epoch 1:\n",
      "Train loss: 1.6618, Train acc: 0.2242\n",
      "Valid loss: 1.6511, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6475, Train acc: 0.2377\n",
      "Valid loss: 1.6410, Valid acc: 0.2468\n",
      "Epoch 3:\n",
      "Train loss: 1.6212, Train acc: 0.2847\n",
      "Valid loss: 1.5613, Valid acc: 0.3367\n",
      "Epoch 4:\n",
      "Train loss: 1.4710, Train acc: 0.3833\n",
      "Valid loss: 1.4771, Valid acc: 0.3945\n",
      "Epoch 5:\n",
      "Train loss: 1.3936, Train acc: 0.4067\n",
      "Valid loss: 1.3621, Valid acc: 0.4284\n",
      "Epoch 6:\n",
      "Train loss: 1.3215, Train acc: 0.4370\n",
      "Valid loss: 1.3205, Valid acc: 0.4523\n",
      "Epoch 7:\n",
      "Train loss: 1.2336, Train acc: 0.4846\n",
      "Valid loss: 1.4213, Valid acc: 0.4339\n",
      "Epoch 8:\n",
      "Train loss: 1.1807, Train acc: 0.5282\n",
      "Valid loss: 1.1760, Valid acc: 0.5422\n",
      "Epoch 9:\n",
      "Train loss: 1.1125, Train acc: 0.5653\n",
      "Valid loss: 1.1089, Valid acc: 0.5881\n",
      "Epoch 10:\n",
      "Train loss: 1.0469, Train acc: 0.5988\n",
      "Valid loss: 1.0755, Valid acc: 0.6138\n",
      "Epoch 11:\n",
      "Train loss: 0.9684, Train acc: 0.6286\n",
      "Valid loss: 1.0253, Valid acc: 0.5945\n",
      "Epoch 12:\n",
      "Train loss: 0.9493, Train acc: 0.6431\n",
      "Valid loss: 1.0133, Valid acc: 0.6211\n",
      "Epoch 13:\n",
      "Train loss: 0.9218, Train acc: 0.6559\n",
      "Valid loss: 1.0595, Valid acc: 0.5917\n",
      "Epoch 14:\n",
      "Train loss: 0.8875, Train acc: 0.6777\n",
      "Valid loss: 1.1918, Valid acc: 0.5697\n",
      "Epoch 15:\n",
      "Train loss: 0.8694, Train acc: 0.6834\n",
      "Valid loss: 0.8917, Valid acc: 0.6853\n",
      "Epoch 16:\n",
      "Train loss: 0.8353, Train acc: 0.7066\n",
      "Valid loss: 0.9427, Valid acc: 0.6376\n",
      "Epoch 17:\n",
      "Train loss: 0.8105, Train acc: 0.7139\n",
      "Valid loss: 0.8883, Valid acc: 0.6780\n",
      "Epoch 18:\n",
      "Train loss: 0.7944, Train acc: 0.7313\n",
      "Valid loss: 0.8963, Valid acc: 0.6936\n",
      "Epoch 19:\n",
      "Train loss: 0.7558, Train acc: 0.7485\n",
      "Valid loss: 0.9073, Valid acc: 0.6945\n",
      "Epoch 20:\n",
      "Train loss: 0.7255, Train acc: 0.7705\n",
      "Valid loss: 0.8636, Valid acc: 0.7174\n",
      "Epoch 21:\n",
      "Train loss: 0.7002, Train acc: 0.7820\n",
      "Valid loss: 0.7739, Valid acc: 0.7569\n",
      "Epoch 22:\n",
      "Train loss: 0.6808, Train acc: 0.7957\n",
      "Valid loss: 0.8720, Valid acc: 0.7165\n",
      "Epoch 23:\n",
      "Train loss: 0.6798, Train acc: 0.8065\n",
      "Valid loss: 0.7716, Valid acc: 0.7560\n",
      "Epoch 24:\n",
      "Train loss: 0.6513, Train acc: 0.8132\n",
      "Valid loss: 1.1335, Valid acc: 0.6807\n",
      "Epoch 25:\n",
      "Train loss: 0.6316, Train acc: 0.8175\n",
      "Valid loss: 0.8581, Valid acc: 0.7321\n",
      "Epoch 26:\n",
      "Train loss: 0.6171, Train acc: 0.8230\n",
      "Valid loss: 0.7942, Valid acc: 0.7578\n",
      "Epoch 27:\n",
      "Train loss: 0.6067, Train acc: 0.8265\n",
      "Valid loss: 0.7633, Valid acc: 0.7697\n",
      "Epoch 28:\n",
      "Train loss: 0.6088, Train acc: 0.8285\n",
      "Valid loss: 0.7649, Valid acc: 0.7697\n",
      "Epoch 29:\n",
      "Train loss: 0.6036, Train acc: 0.8320\n",
      "Valid loss: 0.7814, Valid acc: 0.7587\n",
      "Epoch 30:\n",
      "Train loss: 0.5763, Train acc: 0.8393\n",
      "Valid loss: 0.7861, Valid acc: 0.7596\n",
      "Epoch 31:\n",
      "Train loss: 0.5638, Train acc: 0.8446\n",
      "Valid loss: 0.8016, Valid acc: 0.7670\n",
      "Epoch 32:\n",
      "Train loss: 0.5472, Train acc: 0.8485\n",
      "Valid loss: 0.8187, Valid acc: 0.7569\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Gradient Clipping (Dropout: 0.0, Weight Decay: 0.0, Max Norm: 0.5): 0.7960\n",
      "Testing Gradient Clipping with Value: 1.0\n",
      "Epoch 1:\n",
      "Train loss: 1.6535, Train acc: 0.2380\n",
      "Valid loss: 1.6600, Valid acc: 0.2284\n",
      "Epoch 2:\n",
      "Train loss: 1.5952, Train acc: 0.2987\n",
      "Valid loss: 1.5038, Valid acc: 0.3780\n",
      "Epoch 3:\n",
      "Train loss: 1.4559, Train acc: 0.3906\n",
      "Valid loss: 1.4174, Valid acc: 0.4055\n",
      "Epoch 4:\n",
      "Train loss: 1.3748, Train acc: 0.4117\n",
      "Valid loss: 1.3463, Valid acc: 0.4349\n",
      "Epoch 5:\n",
      "Train loss: 1.3098, Train acc: 0.4381\n",
      "Valid loss: 1.3097, Valid acc: 0.4477\n",
      "Epoch 6:\n",
      "Train loss: 1.2262, Train acc: 0.4897\n",
      "Valid loss: 1.1959, Valid acc: 0.5394\n",
      "Epoch 7:\n",
      "Train loss: 1.1721, Train acc: 0.5328\n",
      "Valid loss: 1.1341, Valid acc: 0.5771\n",
      "Epoch 8:\n",
      "Train loss: 1.0932, Train acc: 0.5692\n",
      "Valid loss: 1.0765, Valid acc: 0.5945\n",
      "Epoch 9:\n",
      "Train loss: 1.0377, Train acc: 0.6091\n",
      "Valid loss: 1.0700, Valid acc: 0.5862\n",
      "Epoch 10:\n",
      "Train loss: 0.9887, Train acc: 0.6359\n",
      "Valid loss: 1.0417, Valid acc: 0.6119\n",
      "Epoch 11:\n",
      "Train loss: 0.9458, Train acc: 0.6529\n",
      "Valid loss: 1.0108, Valid acc: 0.6037\n",
      "Epoch 12:\n",
      "Train loss: 0.9263, Train acc: 0.6651\n",
      "Valid loss: 1.0446, Valid acc: 0.6165\n",
      "Epoch 13:\n",
      "Train loss: 0.8738, Train acc: 0.7029\n",
      "Valid loss: 0.8808, Valid acc: 0.6954\n",
      "Epoch 14:\n",
      "Train loss: 0.8495, Train acc: 0.7102\n",
      "Valid loss: 0.8887, Valid acc: 0.7147\n",
      "Epoch 15:\n",
      "Train loss: 0.8027, Train acc: 0.7387\n",
      "Valid loss: 0.8288, Valid acc: 0.7220\n",
      "Epoch 16:\n",
      "Train loss: 0.7870, Train acc: 0.7460\n",
      "Valid loss: 0.8899, Valid acc: 0.7128\n",
      "Epoch 17:\n",
      "Train loss: 0.7622, Train acc: 0.7641\n",
      "Valid loss: 1.1807, Valid acc: 0.6661\n",
      "Epoch 18:\n",
      "Train loss: 0.7357, Train acc: 0.7788\n",
      "Valid loss: 0.9044, Valid acc: 0.7239\n",
      "Epoch 19:\n",
      "Train loss: 0.7189, Train acc: 0.7790\n",
      "Valid loss: 0.8153, Valid acc: 0.7606\n",
      "Epoch 20:\n",
      "Train loss: 0.6895, Train acc: 0.7946\n",
      "Valid loss: 0.8276, Valid acc: 0.7394\n",
      "Epoch 21:\n",
      "Train loss: 0.7157, Train acc: 0.7955\n",
      "Valid loss: 0.8395, Valid acc: 0.7312\n",
      "Epoch 22:\n",
      "Train loss: 0.6682, Train acc: 0.8033\n",
      "Valid loss: 0.8928, Valid acc: 0.7349\n",
      "Epoch 23:\n",
      "Train loss: 0.6490, Train acc: 0.8122\n",
      "Valid loss: 0.9056, Valid acc: 0.7037\n",
      "Epoch 24:\n",
      "Train loss: 0.6351, Train acc: 0.8143\n",
      "Valid loss: 0.7404, Valid acc: 0.7771\n",
      "Epoch 25:\n",
      "Train loss: 0.6331, Train acc: 0.8207\n",
      "Valid loss: 0.9412, Valid acc: 0.7422\n",
      "Epoch 26:\n",
      "Train loss: 0.6311, Train acc: 0.8155\n",
      "Valid loss: 0.7540, Valid acc: 0.7661\n",
      "Epoch 27:\n",
      "Train loss: 0.6016, Train acc: 0.8294\n",
      "Valid loss: 0.7764, Valid acc: 0.7927\n",
      "Epoch 28:\n",
      "Train loss: 0.5977, Train acc: 0.8304\n",
      "Valid loss: 0.8264, Valid acc: 0.7743\n",
      "Epoch 29:\n",
      "Train loss: 0.5834, Train acc: 0.8345\n",
      "Valid loss: 0.8096, Valid acc: 0.7606\n",
      "Epoch 30:\n",
      "Train loss: 0.5628, Train acc: 0.8439\n",
      "Valid loss: 0.7416, Valid acc: 0.7752\n",
      "Epoch 31:\n",
      "Train loss: 0.5495, Train acc: 0.8501\n",
      "Valid loss: 0.9160, Valid acc: 0.7294\n",
      "Epoch 32:\n",
      "Train loss: 0.5364, Train acc: 0.8535\n",
      "Valid loss: 0.7061, Valid acc: 0.7936\n",
      "Epoch 33:\n",
      "Train loss: 0.5285, Train acc: 0.8579\n",
      "Valid loss: 0.8002, Valid acc: 0.7633\n",
      "Epoch 34:\n",
      "Train loss: 0.5374, Train acc: 0.8526\n",
      "Valid loss: 0.7742, Valid acc: 0.7908\n",
      "Epoch 35:\n",
      "Train loss: 0.5161, Train acc: 0.8599\n",
      "Valid loss: 0.7718, Valid acc: 0.7789\n",
      "Epoch 36:\n",
      "Train loss: 0.5123, Train acc: 0.8645\n",
      "Valid loss: 0.8123, Valid acc: 0.7780\n",
      "Epoch 37:\n",
      "Train loss: 0.4835, Train acc: 0.8712\n",
      "Valid loss: 0.6784, Valid acc: 0.8110\n",
      "Epoch 38:\n",
      "Train loss: 0.5097, Train acc: 0.8604\n",
      "Valid loss: 0.7318, Valid acc: 0.7872\n",
      "Epoch 39:\n",
      "Train loss: 0.4819, Train acc: 0.8707\n",
      "Valid loss: 0.6869, Valid acc: 0.8101\n",
      "Epoch 40:\n",
      "Train loss: 0.4737, Train acc: 0.8709\n",
      "Valid loss: 0.8168, Valid acc: 0.7917\n",
      "Epoch 41:\n",
      "Train loss: 0.4716, Train acc: 0.8771\n",
      "Valid loss: 0.7916, Valid acc: 0.7817\n",
      "Epoch 42:\n",
      "Train loss: 0.4410, Train acc: 0.8835\n",
      "Valid loss: 0.7042, Valid acc: 0.8183\n",
      "Epoch 43:\n",
      "Train loss: 0.4367, Train acc: 0.8865\n",
      "Valid loss: 0.7403, Valid acc: 0.7963\n",
      "Epoch 44:\n",
      "Train loss: 0.4541, Train acc: 0.8792\n",
      "Valid loss: 0.7368, Valid acc: 0.8110\n",
      "Epoch 45:\n",
      "Train loss: 0.4248, Train acc: 0.8877\n",
      "Valid loss: 0.7929, Valid acc: 0.8092\n",
      "Epoch 46:\n",
      "Train loss: 0.4386, Train acc: 0.8870\n",
      "Valid loss: 0.7501, Valid acc: 0.8046\n",
      "Epoch 47:\n",
      "Train loss: 0.4177, Train acc: 0.8927\n",
      "Valid loss: 0.7919, Valid acc: 0.7991\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Gradient Clipping (Dropout: 0.0, Weight Decay: 0.0, Max Norm: 1.0): 0.8120\n"
     ]
    }
   ],
   "source": [
    "# Regularisation - Gradient Clipping ONLY (varying values)\n",
    "max_norm = [0.1, 0.5, 1.0]\n",
    "for max_norm in max_norm:\n",
    "    print(f\"Testing Gradient Clipping with Value: {max_norm}\")\n",
    "    best_reg_technique.append(regularisation_test(weight_decay=0.0,dropout=0.0, grad_clip=True, max_norm=max_norm, reg_technique=\"Gradient Clipping\", optimizer=optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "26f332c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "technique",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dropout",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight_decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grad_clip",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "max_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4eaea7ce-748e-4757-91c0-6b95dc71f6a7",
       "rows": [
        [
         "0",
         "L2 Regularization",
         "0.0",
         "1e-05",
         "False",
         null,
         "0.8312",
         "0.85"
        ],
        [
         "1",
         "Dropout",
         "0.4",
         "0.0",
         "False",
         null,
         "0.7807",
         "0.824"
        ],
        [
         "2",
         "Gradient Clipping",
         "0.0",
         "0.0",
         "True",
         "1.0",
         "0.8183",
         "0.812"
        ],
        [
         "3",
         "Baseline",
         "0.0",
         "0.0",
         "False",
         null,
         "0.7358",
         "0.626"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>max_norm</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 Regularization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Clipping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           technique  dropout  weight_decay  grad_clip  max_norm  \\\n",
       "0  L2 Regularization      0.0       0.00001      False       NaN   \n",
       "1            Dropout      0.4       0.00000      False       NaN   \n",
       "2  Gradient Clipping      0.0       0.00000       True       1.0   \n",
       "3           Baseline      0.0       0.00000      False       NaN   \n",
       "\n",
       "   best_val_acc  test_acc  \n",
       "0        0.8312     0.850  \n",
       "1        0.7807     0.824  \n",
       "2        0.8183     0.812  \n",
       "3        0.7358     0.626  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile results into dataframe for comparisons across strategies\n",
    "cols = ['technique', 'dropout', 'weight_decay', 'grad_clip', 'max_norm', 'best_val_acc', 'test_acc']\n",
    "\n",
    "df_best_reg_technique = pd.DataFrame(best_reg_technique)\n",
    "\n",
    "df_best_reg_technique.loc[~df_best_reg_technique['grad_clip'], 'max_norm'] = pd.NA # Hde max_norm when grad clipping isn't used\n",
    "df_best_reg_technique = df_best_reg_technique[cols]\n",
    "\n",
    "df_best_reg_technique['best_val_acc'] = df_best_reg_technique['best_val_acc'].round(4)\n",
    "df_best_reg_technique['test_acc'] = df_best_reg_technique['test_acc'].round(4)\n",
    "\n",
    "# Find best parameters per technique\n",
    "df_best_reg_technique = (\n",
    "    df_best_reg_technique.sort_values('test_acc', ascending=False)\n",
    "      .groupby('technique', as_index=False, sort=False)\n",
    "      .head(1)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_best_reg_technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79e872",
   "metadata": {},
   "source": [
    "### Answer (b):\n",
    "- Dropout ONLY with value of 0.4 gives the best test accuracy of 0.836\n",
    "- Performing any regularization technique alone beats having no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5cd98796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/2xkb6hns26q621bjtf6rkkmc0000gn/T/ipykernel_58968/250750837.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  m = df['technique'].str.contains(pattern, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.6673, Train acc: 0.2212\n",
      "Valid loss: 1.6487, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6525, Train acc: 0.2325\n",
      "Valid loss: 1.6486, Valid acc: 0.2505\n",
      "Epoch 3:\n",
      "Train loss: 1.6521, Train acc: 0.2251\n",
      "Valid loss: 1.6415, Valid acc: 0.2642\n",
      "Epoch 4:\n",
      "Train loss: 1.6482, Train acc: 0.2299\n",
      "Valid loss: 1.6455, Valid acc: 0.2404\n",
      "Epoch 5:\n",
      "Train loss: 1.5489, Train acc: 0.3329\n",
      "Valid loss: 1.5611, Valid acc: 0.3303\n",
      "Epoch 6:\n",
      "Train loss: 1.4241, Train acc: 0.4010\n",
      "Valid loss: 1.3866, Valid acc: 0.4266\n",
      "Epoch 7:\n",
      "Train loss: 1.3589, Train acc: 0.4287\n",
      "Valid loss: 1.3173, Valid acc: 0.4862\n",
      "Epoch 8:\n",
      "Train loss: 1.2609, Train acc: 0.4826\n",
      "Valid loss: 1.2804, Valid acc: 0.4624\n",
      "Epoch 9:\n",
      "Train loss: 1.1831, Train acc: 0.5206\n",
      "Valid loss: 1.1650, Valid acc: 0.5284\n",
      "Epoch 10:\n",
      "Train loss: 1.1307, Train acc: 0.5539\n",
      "Valid loss: 1.1402, Valid acc: 0.5413\n",
      "Epoch 11:\n",
      "Train loss: 1.0770, Train acc: 0.5727\n",
      "Valid loss: 1.2694, Valid acc: 0.5294\n",
      "Epoch 12:\n",
      "Train loss: 1.0174, Train acc: 0.6059\n",
      "Valid loss: 1.0418, Valid acc: 0.5972\n",
      "Epoch 13:\n",
      "Train loss: 0.9841, Train acc: 0.6194\n",
      "Valid loss: 1.0115, Valid acc: 0.6202\n",
      "Epoch 14:\n",
      "Train loss: 0.9470, Train acc: 0.6327\n",
      "Valid loss: 1.4169, Valid acc: 0.5303\n",
      "Epoch 15:\n",
      "Train loss: 0.9219, Train acc: 0.6444\n",
      "Valid loss: 1.0233, Valid acc: 0.6073\n",
      "Epoch 16:\n",
      "Train loss: 0.8998, Train acc: 0.6506\n",
      "Valid loss: 1.0499, Valid acc: 0.5872\n",
      "Epoch 17:\n",
      "Train loss: 0.8746, Train acc: 0.6664\n",
      "Valid loss: 1.0680, Valid acc: 0.5991\n",
      "Epoch 18:\n",
      "Train loss: 0.8527, Train acc: 0.6781\n",
      "Valid loss: 0.9666, Valid acc: 0.6055\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Dropout + GradClip (Dropout: 0.4, Weight Decay: 0.0, Max Norm: 1.0): 0.7180\n",
      "Epoch 1:\n",
      "Train loss: 1.6572, Train acc: 0.2309\n",
      "Valid loss: 1.6560, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6455, Train acc: 0.2270\n",
      "Valid loss: 1.6563, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6463, Train acc: 0.2398\n",
      "Valid loss: 1.6458, Valid acc: 0.2633\n",
      "Epoch 4:\n",
      "Train loss: 1.5907, Train acc: 0.3044\n",
      "Valid loss: 1.5070, Valid acc: 0.3826\n",
      "Epoch 5:\n",
      "Train loss: 1.4722, Train acc: 0.3893\n",
      "Valid loss: 1.4883, Valid acc: 0.4055\n",
      "Epoch 6:\n",
      "Train loss: 1.4057, Train acc: 0.4179\n",
      "Valid loss: 1.4456, Valid acc: 0.4147\n",
      "Epoch 7:\n",
      "Train loss: 1.3032, Train acc: 0.4583\n",
      "Valid loss: 1.3067, Valid acc: 0.4798\n",
      "Epoch 8:\n",
      "Train loss: 1.2415, Train acc: 0.4865\n",
      "Valid loss: 1.2734, Valid acc: 0.4908\n",
      "Epoch 9:\n",
      "Train loss: 1.1954, Train acc: 0.5057\n",
      "Valid loss: 1.2853, Valid acc: 0.4881\n",
      "Epoch 10:\n",
      "Train loss: 1.1554, Train acc: 0.5213\n",
      "Valid loss: 1.4017, Valid acc: 0.4569\n",
      "Epoch 11:\n",
      "Train loss: 1.1181, Train acc: 0.5300\n",
      "Valid loss: 1.2228, Valid acc: 0.5110\n",
      "Epoch 12:\n",
      "Train loss: 1.1006, Train acc: 0.5392\n",
      "Valid loss: 1.1486, Valid acc: 0.5376\n",
      "Epoch 13:\n",
      "Train loss: 1.0629, Train acc: 0.5699\n",
      "Valid loss: 1.0516, Valid acc: 0.6284\n",
      "Epoch 14:\n",
      "Train loss: 0.9916, Train acc: 0.6110\n",
      "Valid loss: 1.0784, Valid acc: 0.5972\n",
      "Epoch 15:\n",
      "Train loss: 0.9590, Train acc: 0.6337\n",
      "Valid loss: 1.1963, Valid acc: 0.5394\n",
      "Epoch 16:\n",
      "Train loss: 0.9215, Train acc: 0.6362\n",
      "Valid loss: 0.9408, Valid acc: 0.6468\n",
      "Epoch 17:\n",
      "Train loss: 0.8865, Train acc: 0.6561\n",
      "Valid loss: 0.9433, Valid acc: 0.6404\n",
      "Epoch 18:\n",
      "Train loss: 0.8786, Train acc: 0.6545\n",
      "Valid loss: 0.9170, Valid acc: 0.6587\n",
      "Epoch 19:\n",
      "Train loss: 0.8548, Train acc: 0.6738\n",
      "Valid loss: 0.9813, Valid acc: 0.6495\n",
      "Epoch 20:\n",
      "Train loss: 0.8309, Train acc: 0.6862\n",
      "Valid loss: 0.9990, Valid acc: 0.6156\n",
      "Epoch 21:\n",
      "Train loss: 0.8191, Train acc: 0.6857\n",
      "Valid loss: 1.0452, Valid acc: 0.6330\n",
      "Epoch 22:\n",
      "Train loss: 0.8017, Train acc: 0.6889\n",
      "Valid loss: 1.0718, Valid acc: 0.6367\n",
      "Epoch 23:\n",
      "Train loss: 0.7771, Train acc: 0.7045\n",
      "Valid loss: 0.9020, Valid acc: 0.6789\n",
      "Epoch 24:\n",
      "Train loss: 0.7502, Train acc: 0.7256\n",
      "Valid loss: 0.9580, Valid acc: 0.6578\n",
      "Epoch 25:\n",
      "Train loss: 0.7416, Train acc: 0.7455\n",
      "Valid loss: 1.0171, Valid acc: 0.6312\n",
      "Epoch 26:\n",
      "Train loss: 0.7119, Train acc: 0.7659\n",
      "Valid loss: 1.0641, Valid acc: 0.6798\n",
      "Epoch 27:\n",
      "Train loss: 0.6883, Train acc: 0.7781\n",
      "Valid loss: 0.9259, Valid acc: 0.7046\n",
      "Epoch 28:\n",
      "Train loss: 0.6873, Train acc: 0.7873\n",
      "Valid loss: 1.1359, Valid acc: 0.6193\n",
      "Epoch 29:\n",
      "Train loss: 0.6340, Train acc: 0.7994\n",
      "Valid loss: 0.8542, Valid acc: 0.7018\n",
      "Epoch 30:\n",
      "Train loss: 0.6435, Train acc: 0.8015\n",
      "Valid loss: 0.8047, Valid acc: 0.7440\n",
      "Epoch 31:\n",
      "Train loss: 0.6259, Train acc: 0.8093\n",
      "Valid loss: 0.8661, Valid acc: 0.7138\n",
      "Epoch 32:\n",
      "Train loss: 0.6113, Train acc: 0.8182\n",
      "Valid loss: 0.9490, Valid acc: 0.6725\n",
      "Epoch 33:\n",
      "Train loss: 0.6100, Train acc: 0.8182\n",
      "Valid loss: 0.7776, Valid acc: 0.7495\n",
      "Epoch 34:\n",
      "Train loss: 0.5865, Train acc: 0.8320\n",
      "Valid loss: 0.7971, Valid acc: 0.7661\n",
      "Epoch 35:\n",
      "Train loss: 0.5570, Train acc: 0.8379\n",
      "Valid loss: 0.7588, Valid acc: 0.7697\n",
      "Epoch 36:\n",
      "Train loss: 0.5528, Train acc: 0.8420\n",
      "Valid loss: 0.8133, Valid acc: 0.7679\n",
      "Epoch 37:\n",
      "Train loss: 0.5695, Train acc: 0.8356\n",
      "Valid loss: 0.8290, Valid acc: 0.7505\n",
      "Epoch 38:\n",
      "Train loss: 0.5277, Train acc: 0.8503\n",
      "Valid loss: 0.7533, Valid acc: 0.7881\n",
      "Epoch 39:\n",
      "Train loss: 0.5284, Train acc: 0.8537\n",
      "Valid loss: 0.9993, Valid acc: 0.7367\n",
      "Epoch 40:\n",
      "Train loss: 0.5101, Train acc: 0.8549\n",
      "Valid loss: 0.7846, Valid acc: 0.7835\n",
      "Epoch 41:\n",
      "Train loss: 0.4910, Train acc: 0.8647\n",
      "Valid loss: 0.9495, Valid acc: 0.7394\n",
      "Epoch 42:\n",
      "Train loss: 0.4762, Train acc: 0.8689\n",
      "Valid loss: 0.7648, Valid acc: 0.7817\n",
      "Epoch 43:\n",
      "Train loss: 0.4467, Train acc: 0.8780\n",
      "Valid loss: 0.7317, Valid acc: 0.7908\n",
      "Epoch 44:\n",
      "Train loss: 0.4611, Train acc: 0.8744\n",
      "Valid loss: 0.7825, Valid acc: 0.7844\n",
      "Epoch 45:\n",
      "Train loss: 0.4466, Train acc: 0.8796\n",
      "Valid loss: 0.8011, Valid acc: 0.7872\n",
      "Epoch 46:\n",
      "Train loss: 0.4354, Train acc: 0.8776\n",
      "Valid loss: 0.8119, Valid acc: 0.7661\n",
      "Epoch 47:\n",
      "Train loss: 0.4082, Train acc: 0.8902\n",
      "Valid loss: 0.7583, Valid acc: 0.7917\n",
      "Epoch 48:\n",
      "Train loss: 0.4047, Train acc: 0.8918\n",
      "Valid loss: 0.8059, Valid acc: 0.7853\n",
      "Epoch 49:\n",
      "Train loss: 0.3855, Train acc: 0.8978\n",
      "Valid loss: 0.7014, Valid acc: 0.8110\n",
      "Epoch 50:\n",
      "Train loss: 0.3765, Train acc: 0.8982\n",
      "Valid loss: 0.7156, Valid acc: 0.7890\n",
      "Epoch 51:\n",
      "Train loss: 0.3651, Train acc: 0.9049\n",
      "Valid loss: 0.6758, Valid acc: 0.8092\n",
      "Epoch 52:\n",
      "Train loss: 0.3597, Train acc: 0.9076\n",
      "Valid loss: 0.7299, Valid acc: 0.8064\n",
      "Epoch 53:\n",
      "Train loss: 0.3407, Train acc: 0.9081\n",
      "Valid loss: 0.7237, Valid acc: 0.8128\n",
      "Epoch 54:\n",
      "Train loss: 0.3306, Train acc: 0.9154\n",
      "Valid loss: 0.9230, Valid acc: 0.7679\n",
      "Epoch 55:\n",
      "Train loss: 0.3282, Train acc: 0.9110\n",
      "Valid loss: 0.6408, Valid acc: 0.8275\n",
      "Epoch 56:\n",
      "Train loss: 0.3224, Train acc: 0.9145\n",
      "Valid loss: 0.6885, Valid acc: 0.8220\n",
      "Epoch 57:\n",
      "Train loss: 0.3028, Train acc: 0.9239\n",
      "Valid loss: 1.0598, Valid acc: 0.7514\n",
      "Epoch 58:\n",
      "Train loss: 0.2927, Train acc: 0.9230\n",
      "Valid loss: 0.6873, Valid acc: 0.8294\n",
      "Epoch 59:\n",
      "Train loss: 0.3040, Train acc: 0.9218\n",
      "Valid loss: 0.9260, Valid acc: 0.7578\n",
      "Epoch 60:\n",
      "Train loss: 0.3069, Train acc: 0.9202\n",
      "Valid loss: 0.8303, Valid acc: 0.7936\n",
      "Epoch 61:\n",
      "Train loss: 0.2931, Train acc: 0.9248\n",
      "Valid loss: 0.7325, Valid acc: 0.8229\n",
      "Epoch 62:\n",
      "Train loss: 0.2779, Train acc: 0.9324\n",
      "Valid loss: 0.7909, Valid acc: 0.7972\n",
      "Epoch 63:\n",
      "Train loss: 0.2798, Train acc: 0.9317\n",
      "Valid loss: 0.7489, Valid acc: 0.8193\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy GradClip + L2 (Dropout: 0.0, Weight Decay: 1e-05, Max Norm: 1.0): 0.8560\n",
      "Epoch 1:\n",
      "Train loss: 1.6659, Train acc: 0.2228\n",
      "Valid loss: 1.6521, Valid acc: 0.2486\n",
      "Epoch 2:\n",
      "Train loss: 1.6552, Train acc: 0.2242\n",
      "Valid loss: 1.6509, Valid acc: 0.2514\n",
      "Epoch 3:\n",
      "Train loss: 1.6507, Train acc: 0.2270\n",
      "Valid loss: 1.6537, Valid acc: 0.2046\n",
      "Epoch 4:\n",
      "Train loss: 1.6467, Train acc: 0.2547\n",
      "Valid loss: 1.6410, Valid acc: 0.2670\n",
      "Epoch 5:\n",
      "Train loss: 1.5634, Train acc: 0.3333\n",
      "Valid loss: 1.4915, Valid acc: 0.3853\n",
      "Epoch 6:\n",
      "Train loss: 1.4727, Train acc: 0.3776\n",
      "Valid loss: 1.4809, Valid acc: 0.3312\n",
      "Epoch 7:\n",
      "Train loss: 1.4091, Train acc: 0.3934\n",
      "Valid loss: 1.4959, Valid acc: 0.3771\n",
      "Epoch 8:\n",
      "Train loss: 1.3427, Train acc: 0.4239\n",
      "Valid loss: 1.3241, Valid acc: 0.4743\n",
      "Epoch 9:\n",
      "Train loss: 1.2451, Train acc: 0.4874\n",
      "Valid loss: 1.2388, Valid acc: 0.5431\n",
      "Epoch 10:\n",
      "Train loss: 1.1796, Train acc: 0.5186\n",
      "Valid loss: 1.1316, Valid acc: 0.5697\n",
      "Epoch 11:\n",
      "Train loss: 1.1056, Train acc: 0.5665\n",
      "Valid loss: 1.0701, Valid acc: 0.6183\n",
      "Epoch 12:\n",
      "Train loss: 1.0392, Train acc: 0.5993\n",
      "Valid loss: 1.1901, Valid acc: 0.5486\n",
      "Epoch 13:\n",
      "Train loss: 1.0150, Train acc: 0.6146\n",
      "Valid loss: 0.9765, Valid acc: 0.6523\n",
      "Epoch 14:\n",
      "Train loss: 0.9522, Train acc: 0.6527\n",
      "Valid loss: 1.1799, Valid acc: 0.5156\n",
      "Epoch 15:\n",
      "Train loss: 0.9131, Train acc: 0.6609\n",
      "Valid loss: 0.9354, Valid acc: 0.6679\n",
      "Epoch 16:\n",
      "Train loss: 0.8923, Train acc: 0.6852\n",
      "Valid loss: 0.8980, Valid acc: 0.6954\n",
      "Epoch 17:\n",
      "Train loss: 0.8451, Train acc: 0.7006\n",
      "Valid loss: 0.8738, Valid acc: 0.6945\n",
      "Epoch 18:\n",
      "Train loss: 0.7985, Train acc: 0.7249\n",
      "Valid loss: 0.8448, Valid acc: 0.7248\n",
      "Epoch 19:\n",
      "Train loss: 0.7958, Train acc: 0.7233\n",
      "Valid loss: 0.8300, Valid acc: 0.7220\n",
      "Epoch 20:\n",
      "Train loss: 0.7624, Train acc: 0.7510\n",
      "Valid loss: 0.8797, Valid acc: 0.7028\n",
      "Epoch 21:\n",
      "Train loss: 0.7344, Train acc: 0.7701\n",
      "Valid loss: 0.8725, Valid acc: 0.7128\n",
      "Epoch 22:\n",
      "Train loss: 0.7107, Train acc: 0.7785\n",
      "Valid loss: 0.7940, Valid acc: 0.7440\n",
      "Epoch 23:\n",
      "Train loss: 0.7136, Train acc: 0.7829\n",
      "Valid loss: 0.8097, Valid acc: 0.7413\n",
      "Epoch 24:\n",
      "Train loss: 0.6532, Train acc: 0.8072\n",
      "Valid loss: 0.8473, Valid acc: 0.7532\n",
      "Epoch 25:\n",
      "Train loss: 0.6475, Train acc: 0.8118\n",
      "Valid loss: 0.7455, Valid acc: 0.7734\n",
      "Epoch 26:\n",
      "Train loss: 0.6753, Train acc: 0.7950\n",
      "Valid loss: 0.8246, Valid acc: 0.7606\n",
      "Epoch 27:\n",
      "Train loss: 0.6082, Train acc: 0.8269\n",
      "Valid loss: 0.8365, Valid acc: 0.7615\n",
      "Epoch 28:\n",
      "Train loss: 0.6161, Train acc: 0.8216\n",
      "Valid loss: 0.7845, Valid acc: 0.7670\n",
      "Epoch 29:\n",
      "Train loss: 0.5541, Train acc: 0.8471\n",
      "Valid loss: 0.7802, Valid acc: 0.7734\n",
      "Epoch 30:\n",
      "Train loss: 0.5583, Train acc: 0.8521\n",
      "Valid loss: 0.9766, Valid acc: 0.7165\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy Dropout + L2 (Dropout: 0.4, Weight Decay: 1e-05, Max Norm: 0.0): 0.8280\n",
      "Epoch 1:\n",
      "Train loss: 1.6652, Train acc: 0.2320\n",
      "Valid loss: 1.6488, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6488, Train acc: 0.2437\n",
      "Valid loss: 1.6475, Valid acc: 0.2578\n",
      "Epoch 3:\n",
      "Train loss: 1.6242, Train acc: 0.2827\n",
      "Valid loss: 1.5187, Valid acc: 0.3761\n",
      "Epoch 4:\n",
      "Train loss: 1.4935, Train acc: 0.3822\n",
      "Valid loss: 1.4674, Valid acc: 0.3991\n",
      "Epoch 5:\n",
      "Train loss: 1.4335, Train acc: 0.4030\n",
      "Valid loss: 1.4519, Valid acc: 0.4073\n",
      "Epoch 6:\n",
      "Train loss: 1.3558, Train acc: 0.4296\n",
      "Valid loss: 1.4539, Valid acc: 0.4165\n",
      "Epoch 7:\n",
      "Train loss: 1.2942, Train acc: 0.4578\n",
      "Valid loss: 1.2961, Valid acc: 0.4725\n",
      "Epoch 8:\n",
      "Train loss: 1.2341, Train acc: 0.4718\n",
      "Valid loss: 1.2315, Valid acc: 0.5092\n",
      "Epoch 9:\n",
      "Train loss: 1.1666, Train acc: 0.5105\n",
      "Valid loss: 1.1839, Valid acc: 0.5211\n",
      "Epoch 10:\n",
      "Train loss: 1.1434, Train acc: 0.5303\n",
      "Valid loss: 1.1446, Valid acc: 0.5083\n",
      "Epoch 11:\n",
      "Train loss: 1.0842, Train acc: 0.5683\n",
      "Valid loss: 1.1161, Valid acc: 0.5844\n",
      "Epoch 12:\n",
      "Train loss: 1.0392, Train acc: 0.5954\n",
      "Valid loss: 1.0884, Valid acc: 0.5917\n",
      "Epoch 13:\n",
      "Train loss: 1.0032, Train acc: 0.6279\n",
      "Valid loss: 1.0107, Valid acc: 0.6413\n",
      "Epoch 14:\n",
      "Train loss: 0.9521, Train acc: 0.6456\n",
      "Valid loss: 0.9758, Valid acc: 0.6706\n",
      "Epoch 15:\n",
      "Train loss: 0.9215, Train acc: 0.6667\n",
      "Valid loss: 0.9648, Valid acc: 0.6523\n",
      "Epoch 16:\n",
      "Train loss: 0.8801, Train acc: 0.6898\n",
      "Valid loss: 0.9046, Valid acc: 0.7128\n",
      "Epoch 17:\n",
      "Train loss: 0.8531, Train acc: 0.7121\n",
      "Valid loss: 0.8804, Valid acc: 0.7138\n",
      "Epoch 18:\n",
      "Train loss: 0.8258, Train acc: 0.7178\n",
      "Valid loss: 0.9029, Valid acc: 0.7248\n",
      "Epoch 19:\n",
      "Train loss: 0.7969, Train acc: 0.7439\n",
      "Valid loss: 0.9277, Valid acc: 0.6697\n",
      "Epoch 20:\n",
      "Train loss: 0.7847, Train acc: 0.7490\n",
      "Valid loss: 0.8970, Valid acc: 0.7165\n",
      "Epoch 21:\n",
      "Train loss: 0.7487, Train acc: 0.7673\n",
      "Valid loss: 0.8230, Valid acc: 0.7385\n",
      "Epoch 22:\n",
      "Train loss: 0.7242, Train acc: 0.7790\n",
      "Valid loss: 0.8954, Valid acc: 0.7422\n",
      "Epoch 23:\n",
      "Train loss: 0.7198, Train acc: 0.7859\n",
      "Valid loss: 0.8559, Valid acc: 0.7321\n",
      "Epoch 24:\n",
      "Train loss: 0.7050, Train acc: 0.7914\n",
      "Valid loss: 0.9934, Valid acc: 0.7220\n",
      "Epoch 25:\n",
      "Train loss: 0.6829, Train acc: 0.8033\n",
      "Valid loss: 0.8502, Valid acc: 0.7092\n",
      "Epoch 26:\n",
      "Train loss: 0.6661, Train acc: 0.8058\n",
      "Valid loss: 1.0304, Valid acc: 0.6679\n",
      "Epoch 27:\n",
      "Train loss: 0.6441, Train acc: 0.8150\n",
      "Valid loss: 0.9039, Valid acc: 0.6963\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy All (Dropout+GradClip+L2) (Dropout: 0.4, Weight Decay: 1e-05, Max Norm: 1.0): 0.7760\n"
     ]
    }
   ],
   "source": [
    "# Regularisation - ALL Techniques to find best combination (varying values)\n",
    "\n",
    "# Function to obtain rows with regards to regularisation strategies using regex\n",
    "def get_row(df, pattern):\n",
    "    m = df['technique'].str.contains(pattern, regex=True)\n",
    "    return df[m].iloc[0]\n",
    "\n",
    "# Use regex to get best params from each technique\n",
    "dropout_rows = get_row(df_best_reg_technique, r'(Dropout)')\n",
    "clip_rows = get_row(df_best_reg_technique, r'(Grad)')\n",
    "l2_rows = get_row(df_best_reg_technique, r'(L2)')\n",
    "\n",
    "best_dropout = float(dropout_rows['dropout'])\n",
    "best_weight_decay = float(l2_rows['weight_decay'])\n",
    "best_grad_clip = True\n",
    "best_max_norm  = float(clip_rows['max_norm'])\n",
    "\n",
    "combos = [\n",
    "    (\"Dropout + GradClip\", best_weight_decay if 0 else 0.0, best_dropout, True,  best_max_norm),\n",
    "    (\"GradClip + L2\", best_weight_decay, 0.0, True, best_max_norm),\n",
    "    (\"Dropout + L2\", best_weight_decay, best_dropout,  False, 0.0),\n",
    "    (\"All (Dropout+GradClip+L2)\", best_weight_decay, best_dropout, True, best_max_norm),\n",
    "]\n",
    "\n",
    "for reg_technique, weight_decay, dropout, grad_clip, max_norm in combos:\n",
    "    result_best_technique = regularisation_test(\n",
    "        weight_decay=weight_decay,\n",
    "        dropout=dropout,\n",
    "        grad_clip=grad_clip,\n",
    "        max_norm=max_norm,\n",
    "        reg_technique=reg_technique,\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "    best_reg_technique.append(result_best_technique)\n",
    "\n",
    "df_all = pd.DataFrame(best_reg_technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "494f24ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "technique",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dropout",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight_decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grad_clip",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "max_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9f25353f-cc55-4b7d-824f-7dbc68543e29",
       "rows": [
        [
         "13",
         "GradClip + L2",
         "0.0",
         "1e-05",
         "True",
         "1.0",
         "0.8294",
         "0.856"
        ],
        [
         "1",
         "L2 Regularization",
         "0.0",
         "1e-05",
         "False",
         "0.0",
         "0.8312",
         "0.85"
        ],
        [
         "14",
         "Dropout + L2",
         "0.4",
         "1e-05",
         "False",
         "0.0",
         "0.7734",
         "0.828"
        ],
        [
         "3",
         "L2 Regularization",
         "0.0",
         "0.0001",
         "False",
         "0.0",
         "0.8202",
         "0.826"
        ],
        [
         "8",
         "Dropout",
         "0.4",
         "0.0",
         "False",
         "0.0",
         "0.7807",
         "0.824"
        ],
        [
         "7",
         "Dropout",
         "0.3",
         "0.0",
         "False",
         "0.0",
         "0.7881",
         "0.818"
        ],
        [
         "11",
         "Gradient Clipping",
         "0.0",
         "0.0",
         "True",
         "1.0",
         "0.8183",
         "0.812"
        ],
        [
         "10",
         "Gradient Clipping",
         "0.0",
         "0.0",
         "True",
         "0.5",
         "0.7697",
         "0.796"
        ],
        [
         "9",
         "Gradient Clipping",
         "0.0",
         "0.0",
         "True",
         "0.1",
         "0.7349",
         "0.786"
        ],
        [
         "15",
         "All (Dropout+GradClip+L2)",
         "0.4",
         "1e-05",
         "True",
         "1.0",
         "0.7422",
         "0.776"
        ],
        [
         "5",
         "L2 Regularization",
         "0.0",
         "0.001",
         "False",
         "0.0",
         "0.7835",
         "0.77"
        ],
        [
         "2",
         "L2 Regularization",
         "0.0",
         "5e-05",
         "False",
         "0.0",
         "0.7853",
         "0.744"
        ],
        [
         "12",
         "Dropout + GradClip",
         "0.4",
         "0.0",
         "True",
         "1.0",
         "0.6202",
         "0.718"
        ],
        [
         "6",
         "Dropout",
         "0.2",
         "0.0",
         "False",
         "0.0",
         "0.6963",
         "0.666"
        ],
        [
         "0",
         "Baseline",
         "0.0",
         "0.0",
         "False",
         "0.0",
         "0.7358",
         "0.626"
        ],
        [
         "4",
         "L2 Regularization",
         "0.0",
         "0.0005",
         "False",
         "0.0",
         "0.4963",
         "0.304"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 16
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>max_norm</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GradClip + L2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L2 Regularization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dropout + L2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7734</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L2 Regularization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Clipping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Clipping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Clipping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>All (Dropout+GradClip+L2)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L2 Regularization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L2 Regularization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dropout + GradClip</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L2 Regularization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    technique  dropout  weight_decay  grad_clip  max_norm  \\\n",
       "13              GradClip + L2      0.0       0.00001       True       1.0   \n",
       "1           L2 Regularization      0.0       0.00001      False       0.0   \n",
       "14               Dropout + L2      0.4       0.00001      False       0.0   \n",
       "3           L2 Regularization      0.0       0.00010      False       0.0   \n",
       "8                     Dropout      0.4       0.00000      False       0.0   \n",
       "7                     Dropout      0.3       0.00000      False       0.0   \n",
       "11          Gradient Clipping      0.0       0.00000       True       1.0   \n",
       "10          Gradient Clipping      0.0       0.00000       True       0.5   \n",
       "9           Gradient Clipping      0.0       0.00000       True       0.1   \n",
       "15  All (Dropout+GradClip+L2)      0.4       0.00001       True       1.0   \n",
       "5           L2 Regularization      0.0       0.00100      False       0.0   \n",
       "2           L2 Regularization      0.0       0.00005      False       0.0   \n",
       "12         Dropout + GradClip      0.4       0.00000       True       1.0   \n",
       "6                     Dropout      0.2       0.00000      False       0.0   \n",
       "0                    Baseline      0.0       0.00000      False       0.0   \n",
       "4           L2 Regularization      0.0       0.00050      False       0.0   \n",
       "\n",
       "    best_val_acc  test_acc  \n",
       "13        0.8294     0.856  \n",
       "1         0.8312     0.850  \n",
       "14        0.7734     0.828  \n",
       "3         0.8202     0.826  \n",
       "8         0.7807     0.824  \n",
       "7         0.7881     0.818  \n",
       "11        0.8183     0.812  \n",
       "10        0.7697     0.796  \n",
       "9         0.7349     0.786  \n",
       "15        0.7422     0.776  \n",
       "5         0.7835     0.770  \n",
       "2         0.7853     0.744  \n",
       "12        0.6202     0.718  \n",
       "6         0.6963     0.666  \n",
       "0         0.7358     0.626  \n",
       "4         0.4963     0.304  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile results into dataframe for comparisons across strategies\n",
    "col_order = ['technique', 'dropout', 'weight_decay', 'grad_clip', 'max_norm', 'best_val_acc', 'test_acc']\n",
    "df_all = df_all[[c for c in col_order if c in df_all.columns]]\n",
    "\n",
    "for c in ['best_val_acc', 'test_acc']:\n",
    "    if c in df_all.columns:\n",
    "        df_all[c] = df_all[c].astype(float).round(4)\n",
    "\n",
    "df_all = df_all.sort_values('test_acc', ascending=False)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5551385",
   "metadata": {},
   "source": [
    "### Answer (b):\n",
    "- Dropout ONLY with value of 0.4 gives the best test accuracy of 0.836 still. We continue to adopt this regularisation strategy for the rest of qn 2.\n",
    "- Most of the L2 regularization only runs, and the run having all regularization techniques together performed worse than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a8a2d",
   "metadata": {},
   "source": [
    "**(c) For the best configuration and regularization strategy in your experiments, plot the training loss curve and validation accuracy curve during training with x-axis being the number of training epochs. Discuss what the curves inform about the training dynamics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00485664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.6604, Train acc: 0.2233\n",
      "Valid loss: 1.6489, Valid acc: 0.2596\n",
      "Epoch 2:\n",
      "Train loss: 1.6464, Train acc: 0.2396\n",
      "Valid loss: 1.6617, Valid acc: 0.2046\n",
      "Epoch 3:\n",
      "Train loss: 1.6373, Train acc: 0.2494\n",
      "Valid loss: 1.6525, Valid acc: 0.2560\n",
      "Epoch 4:\n",
      "Train loss: 1.5471, Train acc: 0.3322\n",
      "Valid loss: 1.4973, Valid acc: 0.3780\n",
      "Epoch 5:\n",
      "Train loss: 1.4413, Train acc: 0.3968\n",
      "Valid loss: 1.4280, Valid acc: 0.4083\n",
      "Epoch 6:\n",
      "Train loss: 1.3793, Train acc: 0.4104\n",
      "Valid loss: 1.4066, Valid acc: 0.4128\n",
      "Epoch 7:\n",
      "Train loss: 1.2963, Train acc: 0.4411\n",
      "Valid loss: 1.4360, Valid acc: 0.4193\n",
      "Epoch 8:\n",
      "Train loss: 1.2188, Train acc: 0.4959\n",
      "Valid loss: 1.2162, Valid acc: 0.5376\n",
      "Epoch 9:\n",
      "Train loss: 1.1603, Train acc: 0.5461\n",
      "Valid loss: 1.1571, Valid acc: 0.5651\n",
      "Epoch 10:\n",
      "Train loss: 1.1005, Train acc: 0.5747\n",
      "Valid loss: 1.1432, Valid acc: 0.5569\n",
      "Epoch 11:\n",
      "Train loss: 1.0365, Train acc: 0.6055\n",
      "Valid loss: 1.0328, Valid acc: 0.6211\n",
      "Epoch 12:\n",
      "Train loss: 1.0070, Train acc: 0.6167\n",
      "Valid loss: 1.0111, Valid acc: 0.6028\n",
      "Epoch 13:\n",
      "Train loss: 0.9602, Train acc: 0.6298\n",
      "Valid loss: 1.0632, Valid acc: 0.6018\n",
      "Epoch 14:\n",
      "Train loss: 0.9361, Train acc: 0.6380\n",
      "Valid loss: 0.9652, Valid acc: 0.6468\n",
      "Epoch 15:\n",
      "Train loss: 0.9074, Train acc: 0.6447\n",
      "Valid loss: 0.9813, Valid acc: 0.6239\n",
      "Epoch 16:\n",
      "Train loss: 0.8795, Train acc: 0.6538\n",
      "Valid loss: 1.0676, Valid acc: 0.6110\n",
      "Epoch 17:\n",
      "Train loss: 0.8610, Train acc: 0.6635\n",
      "Valid loss: 0.9496, Valid acc: 0.6450\n",
      "Epoch 18:\n",
      "Train loss: 0.8442, Train acc: 0.6710\n",
      "Valid loss: 0.9301, Valid acc: 0.6596\n",
      "Epoch 19:\n",
      "Train loss: 0.8257, Train acc: 0.6740\n",
      "Valid loss: 0.8934, Valid acc: 0.6642\n",
      "Epoch 20:\n",
      "Train loss: 0.8055, Train acc: 0.6784\n",
      "Valid loss: 1.0020, Valid acc: 0.5927\n",
      "Epoch 21:\n",
      "Train loss: 0.7950, Train acc: 0.6850\n",
      "Valid loss: 0.9421, Valid acc: 0.6468\n",
      "Epoch 22:\n",
      "Train loss: 0.7800, Train acc: 0.6845\n",
      "Valid loss: 0.9081, Valid acc: 0.6697\n",
      "Epoch 23:\n",
      "Train loss: 0.7645, Train acc: 0.6999\n",
      "Valid loss: 0.8685, Valid acc: 0.6936\n",
      "Epoch 24:\n",
      "Train loss: 0.7466, Train acc: 0.6956\n",
      "Valid loss: 0.8463, Valid acc: 0.6780\n",
      "Epoch 25:\n",
      "Train loss: 0.7331, Train acc: 0.7199\n",
      "Valid loss: 0.8340, Valid acc: 0.7101\n",
      "Epoch 26:\n",
      "Train loss: 0.7126, Train acc: 0.7325\n",
      "Valid loss: 0.8981, Valid acc: 0.6972\n",
      "Epoch 27:\n",
      "Train loss: 0.6897, Train acc: 0.7506\n",
      "Valid loss: 0.8863, Valid acc: 0.6624\n",
      "Epoch 28:\n",
      "Train loss: 0.6828, Train acc: 0.7632\n",
      "Valid loss: 0.9739, Valid acc: 0.7055\n",
      "Epoch 29:\n",
      "Train loss: 0.6602, Train acc: 0.7797\n",
      "Valid loss: 0.8279, Valid acc: 0.7486\n",
      "Epoch 30:\n",
      "Train loss: 0.6204, Train acc: 0.8054\n",
      "Valid loss: 0.9596, Valid acc: 0.7165\n",
      "Epoch 31:\n",
      "Train loss: 0.6042, Train acc: 0.8171\n",
      "Valid loss: 0.8457, Valid acc: 0.7349\n",
      "Epoch 32:\n",
      "Train loss: 0.5841, Train acc: 0.8246\n",
      "Valid loss: 0.7829, Valid acc: 0.7798\n",
      "Epoch 33:\n",
      "Train loss: 0.5584, Train acc: 0.8315\n",
      "Valid loss: 0.7652, Valid acc: 0.7560\n",
      "Epoch 34:\n",
      "Train loss: 0.5688, Train acc: 0.8349\n",
      "Valid loss: 0.7527, Valid acc: 0.7945\n",
      "Epoch 35:\n",
      "Train loss: 0.5281, Train acc: 0.8496\n",
      "Valid loss: 0.8032, Valid acc: 0.7807\n",
      "Epoch 36:\n",
      "Train loss: 0.5186, Train acc: 0.8581\n",
      "Valid loss: 0.8182, Valid acc: 0.7743\n",
      "Epoch 37:\n",
      "Train loss: 0.5072, Train acc: 0.8574\n",
      "Valid loss: 0.7648, Valid acc: 0.7661\n",
      "Epoch 38:\n",
      "Train loss: 0.4984, Train acc: 0.8629\n",
      "Valid loss: 0.9685, Valid acc: 0.7339\n",
      "Epoch 39:\n",
      "Train loss: 0.4926, Train acc: 0.8675\n",
      "Valid loss: 0.6960, Valid acc: 0.8018\n",
      "Epoch 40:\n",
      "Train loss: 0.4777, Train acc: 0.8684\n",
      "Valid loss: 0.6787, Valid acc: 0.8028\n",
      "Epoch 41:\n",
      "Train loss: 0.4540, Train acc: 0.8790\n",
      "Valid loss: 0.8787, Valid acc: 0.7725\n",
      "Epoch 42:\n",
      "Train loss: 0.4476, Train acc: 0.8831\n",
      "Valid loss: 0.8159, Valid acc: 0.7881\n",
      "Epoch 43:\n",
      "Train loss: 0.4507, Train acc: 0.8799\n",
      "Valid loss: 0.8784, Valid acc: 0.7633\n",
      "Epoch 44:\n",
      "Train loss: 0.4420, Train acc: 0.8829\n",
      "Valid loss: 1.2326, Valid acc: 0.6651\n",
      "Epoch 45:\n",
      "Train loss: 0.4347, Train acc: 0.8863\n",
      "Valid loss: 0.7131, Valid acc: 0.7991\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n"
     ]
    }
   ],
   "source": [
    "# Set ideal hyperparameters from 2(a)\n",
    "if best_hyperparams[\"epochs ran\"] <= 50:\n",
    "    no_epoch = 50\n",
    "elif best_hyperparams[\"epochs ran\"] > 50 & best_hyperparams[\"epochs ran\"] <= 100:\n",
    "    no_epoch = 100\n",
    "else:\n",
    "    no_epoch = 200\n",
    "batch_size = best_hyperparams[\"batch_size\"]\n",
    "hidden_dim = best_hyperparams[\"hidden_dim\"]\n",
    "lr = best_hyperparams[\"lr\"]\n",
    "optimizer = best_hyperparams[\"optimizer\"]\n",
    "\n",
    "# Set regularization from 2(b)\n",
    "dropout = df_all.loc[df_all['test_acc'].idxmax(), 'dropout']\n",
    "weight_decay = df_all.loc[df_all['test_acc'].idxmax(), 'weight_decay']\n",
    "grad_clip = df_all.loc[df_all['test_acc'].idxmax(), 'grad_clip']\n",
    "max_norm = df_all.loc[df_all['test_acc'].idxmax(), 'max_norm']\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Initialise model\n",
    "model = ClassifierRNN(TEXT.vocab.vectors.numpy() , hidden_dim, dropout=dropout)\n",
    "\n",
    "# Initialise optimiser with L2 regularization\n",
    "optimizer = optimizer.__class__(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if grad_clip == True:\n",
    "    train_losses, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch, grad_clip=True, max_norm=max_norm)\n",
    "else:\n",
    "    train_losses, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ef47315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two graphs side by side\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valid_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498d6a2f",
   "metadata": {},
   "source": [
    "### Answer (c):\n",
    "\n",
    "Some observations and explanations with the plots:\n",
    "- The generally smooth loss curve, with no sudden jumps or oscillations, suggests the model is learning effectively and training remains stable across training epochs. The lack of a plateau at the end of the curve suggests there may be room for further improvements, but the increasing gentleness of the curves means the model is likely already close to the minimum loss and early stopping is preventing severe overfitting. \n",
    "- The generally upward curve for validation accuracy shows that the model is generalising well and its performance is improving over training epochs. There are sudden jumps in accuracy, suggesting that model performance seems to vary over the validation samples, but the overall trend still shows a healthy improvement over the epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e4a15",
   "metadata": {},
   "source": [
    "**(d) RNNs produce a hidden vector for each word, instead of the entire sentence. Which methods have you tried in deriving the final sentence representation to perform sentiment classification? Describe all the strategies you have implemented, together with their accuracy scores on the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d253fc4",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "Here, the approach is to evaluate how different sentence representation strategies could influence the model's performance across various text categories. We will use the best technique for part (e). Since RNNs generate a hidden vector for each token rather than a single sentence embedding, an important design choice is how to aggregate these hidden states into a fixed-length representation for classification. \n",
    "\n",
    "We mainly explored 2 families of approaches:\n",
    "\n",
    "1. Hidden-State Methods\n",
    "* Last Hidden State (Default) - Use final hidden state as sentence representation (This approach would be good if we think it captures all preceding context well)\n",
    "* Average Last k hidden states (k = 2, 3, or 4) - These variants aim to smooth the representation by averaging over the most recent time steps, mitigating the possibility of noise or information loss that can occur when relying solely on the final hidden state, especially for longer sentences\n",
    "\n",
    "2. Pooling Methods\n",
    "* Mean Pooling - Computes the average over all time-step hidden states, giving equal weight to each token\n",
    "* Max Pooling - Takes the elementwise maximum across all time steps\n",
    "* MeanMax Pooling - Concatenates both the mean and max pooled represenation \n",
    "* Sum Pooling - Computes by sums all hidden states, which preserve magnitude information \n",
    "\n",
    "Additionally, we chose these methods because they are computationally efficient and reasonable to experiment with in a single hidden-layer RNN as well.\n",
    "\n",
    "Note: While we could have explored more advanced methods like attention-based representations (e.g. self-attention) and/or architectural variations (e.g. bidirectional RNNs) in this part, we left the the exploration of these strategies to qn 3, as the we believe the focus shifts from representation aggregation to model architecture enhancements there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25127ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Baseline) 0.8300\n"
     ]
    }
   ],
   "source": [
    "# Using model from 2(c), our previous models use last hidden state as sentence representation (default baseline)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_acc = test_loop(model, test_loader)\n",
    "print(f\"Test Accuracy (Baseline) {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "198519bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine RNN Class for experimentation with different sentence representation techniques\n",
    "class ClassifierRepresentationRNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, representation, dropout=0.0):\n",
    "        super(ClassifierRepresentationRNN, self).__init__()\n",
    "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 6) # 6 possible labels\n",
    "        self.representation = representation\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        # Conditional Logic to apply different representation techniques\n",
    "        if self.representation.startswith('average_last_'):\n",
    "            last_k = int(self.representation.split('_')[-1])\n",
    "            k = min(last_k, output.size(1))\n",
    "            rep = output[:, -k:, :].mean(dim=1)\n",
    "        elif self.representation == 'max':\n",
    "            rep, _ = torch.max(output, dim=1)\n",
    "        elif self.representation == 'mean':\n",
    "            rep = torch.mean(output, dim=1)\n",
    "        elif self.representation == 'maxmean':\n",
    "            max_pooled, _ = torch.max(output, dim=1)\n",
    "            mean_pooled = torch.mean(output, dim=1)\n",
    "            rep = (max_pooled + mean_pooled) / 2\n",
    "        elif self.representation == 'sum':\n",
    "            rep = torch.sum(output, dim=1)\n",
    "\n",
    "        hidden = self.dropout(rep)\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf32ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine a function for Representation Tests\n",
    "def representation_test(strategy, batch_size, hidden_dim, lr, optimizer, no_epoch, weight_decay, dropout, grad_clip, max_norm):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Initialise model\n",
    "    model = ClassifierRepresentationRNN(TEXT.vocab.vectors.numpy() , hidden_dim, strategy, dropout=dropout)\n",
    "\n",
    "    # Initialise optimiser\n",
    "    optimizer = optimizer.__class__(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if grad_clip == True:\n",
    "        train_losses, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch, grad_clip=True, max_norm=max_norm)\n",
    "    else:\n",
    "        train_losses, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch)\n",
    "\n",
    "    test_acc = test_loop(model, test_loader)\n",
    "    print(f\"Test Accuracy {strategy}: {test_acc:.4f}\") # Evaluate on test accuracy again here\n",
    "\n",
    "    return {\n",
    "        'technique': strategy,\n",
    "        'test_acc': test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06d9774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.6598, Train acc: 0.2265\n",
      "Valid loss: 1.6653, Valid acc: 0.2046\n",
      "Epoch 2:\n",
      "Train loss: 1.6482, Train acc: 0.2242\n",
      "Valid loss: 1.6442, Valid acc: 0.2477\n",
      "Epoch 3:\n",
      "Train loss: 1.6424, Train acc: 0.2442\n",
      "Valid loss: 1.6523, Valid acc: 0.2505\n",
      "Epoch 4:\n",
      "Train loss: 1.6201, Train acc: 0.2758\n",
      "Valid loss: 1.5137, Valid acc: 0.3780\n",
      "Epoch 5:\n",
      "Train loss: 1.4723, Train acc: 0.3842\n",
      "Valid loss: 1.4422, Valid acc: 0.4018\n",
      "Epoch 6:\n",
      "Train loss: 1.3892, Train acc: 0.4019\n",
      "Valid loss: 1.4436, Valid acc: 0.4064\n",
      "Epoch 7:\n",
      "Train loss: 1.2962, Train acc: 0.4521\n",
      "Valid loss: 1.2795, Valid acc: 0.5092\n",
      "Epoch 8:\n",
      "Train loss: 1.2265, Train acc: 0.5016\n",
      "Valid loss: 1.3228, Valid acc: 0.4569\n",
      "Epoch 9:\n",
      "Train loss: 1.1498, Train acc: 0.5403\n",
      "Valid loss: 1.1972, Valid acc: 0.5560\n",
      "Epoch 10:\n",
      "Train loss: 1.0710, Train acc: 0.5855\n",
      "Valid loss: 1.1351, Valid acc: 0.5550\n",
      "Epoch 11:\n",
      "Train loss: 1.0255, Train acc: 0.5981\n",
      "Valid loss: 1.0817, Valid acc: 0.6083\n",
      "Epoch 12:\n",
      "Train loss: 0.9840, Train acc: 0.6238\n",
      "Valid loss: 0.9734, Valid acc: 0.6477\n",
      "Epoch 13:\n",
      "Train loss: 0.9419, Train acc: 0.6314\n",
      "Valid loss: 0.9625, Valid acc: 0.6477\n",
      "Epoch 14:\n",
      "Train loss: 0.9126, Train acc: 0.6389\n",
      "Valid loss: 0.9983, Valid acc: 0.6303\n",
      "Epoch 15:\n",
      "Train loss: 0.8874, Train acc: 0.6529\n",
      "Valid loss: 1.0659, Valid acc: 0.6193\n",
      "Epoch 16:\n",
      "Train loss: 0.8841, Train acc: 0.6522\n",
      "Valid loss: 0.9190, Valid acc: 0.6596\n",
      "Epoch 17:\n",
      "Train loss: 0.8466, Train acc: 0.6655\n",
      "Valid loss: 0.9025, Valid acc: 0.6670\n",
      "Epoch 18:\n",
      "Train loss: 0.8308, Train acc: 0.6903\n",
      "Valid loss: 0.8879, Valid acc: 0.6752\n",
      "Epoch 19:\n",
      "Train loss: 0.8024, Train acc: 0.6921\n",
      "Valid loss: 0.8847, Valid acc: 0.7000\n",
      "Epoch 20:\n",
      "Train loss: 0.7925, Train acc: 0.7132\n",
      "Valid loss: 1.0165, Valid acc: 0.6431\n",
      "Epoch 21:\n",
      "Train loss: 0.7691, Train acc: 0.7265\n",
      "Valid loss: 0.9230, Valid acc: 0.6734\n",
      "Epoch 22:\n",
      "Train loss: 0.7508, Train acc: 0.7533\n",
      "Valid loss: 0.8311, Valid acc: 0.7147\n",
      "Epoch 23:\n",
      "Train loss: 0.7079, Train acc: 0.7730\n",
      "Valid loss: 0.9275, Valid acc: 0.6881\n",
      "Epoch 24:\n",
      "Train loss: 0.6936, Train acc: 0.7829\n",
      "Valid loss: 0.9792, Valid acc: 0.6835\n",
      "Epoch 25:\n",
      "Train loss: 0.6542, Train acc: 0.7955\n",
      "Valid loss: 0.7496, Valid acc: 0.7826\n",
      "Epoch 26:\n",
      "Train loss: 0.6361, Train acc: 0.8086\n",
      "Valid loss: 0.8490, Valid acc: 0.7651\n",
      "Epoch 27:\n",
      "Train loss: 0.6334, Train acc: 0.8155\n",
      "Valid loss: 1.0137, Valid acc: 0.6963\n",
      "Epoch 28:\n",
      "Train loss: 0.6175, Train acc: 0.8129\n",
      "Valid loss: 0.8344, Valid acc: 0.7532\n",
      "Epoch 29:\n",
      "Train loss: 0.5908, Train acc: 0.8274\n",
      "Valid loss: 0.7491, Valid acc: 0.7853\n",
      "Epoch 30:\n",
      "Train loss: 0.5734, Train acc: 0.8333\n",
      "Valid loss: 0.7812, Valid acc: 0.7661\n",
      "Epoch 31:\n",
      "Train loss: 0.5353, Train acc: 0.8508\n",
      "Valid loss: 0.9604, Valid acc: 0.7073\n",
      "Epoch 32:\n",
      "Train loss: 0.5375, Train acc: 0.8457\n",
      "Valid loss: 0.7401, Valid acc: 0.7862\n",
      "Epoch 33:\n",
      "Train loss: 0.5344, Train acc: 0.8489\n",
      "Valid loss: 0.7684, Valid acc: 0.7798\n",
      "Epoch 34:\n",
      "Train loss: 0.5196, Train acc: 0.8505\n",
      "Valid loss: 0.8965, Valid acc: 0.7349\n",
      "Epoch 35:\n",
      "Train loss: 0.5175, Train acc: 0.8567\n",
      "Valid loss: 0.8638, Valid acc: 0.7394\n",
      "Epoch 36:\n",
      "Train loss: 0.4934, Train acc: 0.8668\n",
      "Valid loss: 0.7287, Valid acc: 0.7917\n",
      "Epoch 37:\n",
      "Train loss: 0.4907, Train acc: 0.8684\n",
      "Valid loss: 0.7151, Valid acc: 0.8018\n",
      "Epoch 38:\n",
      "Train loss: 0.4915, Train acc: 0.8684\n",
      "Valid loss: 0.7693, Valid acc: 0.8000\n",
      "Epoch 39:\n",
      "Train loss: 0.4833, Train acc: 0.8693\n",
      "Valid loss: 0.7306, Valid acc: 0.8009\n",
      "Epoch 40:\n",
      "Train loss: 0.4680, Train acc: 0.8735\n",
      "Valid loss: 0.7036, Valid acc: 0.8028\n",
      "Epoch 41:\n",
      "Train loss: 0.4619, Train acc: 0.8762\n",
      "Valid loss: 0.7680, Valid acc: 0.7917\n",
      "Epoch 42:\n",
      "Train loss: 0.4353, Train acc: 0.8890\n",
      "Valid loss: 0.8498, Valid acc: 0.7780\n",
      "Epoch 43:\n",
      "Train loss: 0.4349, Train acc: 0.8861\n",
      "Valid loss: 0.7590, Valid acc: 0.7853\n",
      "Epoch 44:\n",
      "Train loss: 0.4298, Train acc: 0.8877\n",
      "Valid loss: 0.8676, Valid acc: 0.7752\n",
      "Epoch 45:\n",
      "Train loss: 0.4192, Train acc: 0.8906\n",
      "Valid loss: 0.7080, Valid acc: 0.8083\n",
      "Epoch 46:\n",
      "Train loss: 0.4048, Train acc: 0.8978\n",
      "Valid loss: 0.7368, Valid acc: 0.8101\n",
      "Epoch 47:\n",
      "Train loss: 0.4071, Train acc: 0.8948\n",
      "Valid loss: 0.8374, Valid acc: 0.7817\n",
      "Epoch 48:\n",
      "Train loss: 0.3940, Train acc: 0.9019\n",
      "Valid loss: 0.8441, Valid acc: 0.7908\n",
      "Epoch 49:\n",
      "Train loss: 0.4088, Train acc: 0.8975\n",
      "Valid loss: 0.6843, Valid acc: 0.8193\n",
      "Epoch 50:\n",
      "Train loss: 0.3695, Train acc: 0.9081\n",
      "Valid loss: 0.7809, Valid acc: 0.7908\n",
      "Epoch 51:\n",
      "Train loss: 0.3719, Train acc: 0.9065\n",
      "Valid loss: 0.7137, Valid acc: 0.8193\n",
      "Epoch 52:\n",
      "Train loss: 0.3654, Train acc: 0.9090\n",
      "Valid loss: 0.7763, Valid acc: 0.7963\n",
      "Epoch 53:\n",
      "Train loss: 0.3679, Train acc: 0.9097\n",
      "Valid loss: 0.7768, Valid acc: 0.7982\n",
      "Epoch 54:\n",
      "Train loss: 0.3363, Train acc: 0.9156\n",
      "Valid loss: 0.9913, Valid acc: 0.7486\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy average_last_2: 0.8260\n",
      "Epoch 1:\n",
      "Train loss: 1.6570, Train acc: 0.2343\n",
      "Valid loss: 1.6439, Valid acc: 0.2450\n",
      "Epoch 2:\n",
      "Train loss: 1.6440, Train acc: 0.2483\n",
      "Valid loss: 1.6480, Valid acc: 0.2495\n",
      "Epoch 3:\n",
      "Train loss: 1.5976, Train acc: 0.3008\n",
      "Valid loss: 1.5161, Valid acc: 0.3761\n",
      "Epoch 4:\n",
      "Train loss: 1.4655, Train acc: 0.3913\n",
      "Valid loss: 1.4720, Valid acc: 0.4239\n",
      "Epoch 5:\n",
      "Train loss: 1.4108, Train acc: 0.4030\n",
      "Valid loss: 1.3908, Valid acc: 0.4275\n",
      "Epoch 6:\n",
      "Train loss: 1.3273, Train acc: 0.4360\n",
      "Valid loss: 1.5032, Valid acc: 0.3844\n",
      "Epoch 7:\n",
      "Train loss: 1.2420, Train acc: 0.4663\n",
      "Valid loss: 1.2231, Valid acc: 0.5083\n",
      "Epoch 8:\n",
      "Train loss: 1.1808, Train acc: 0.4954\n",
      "Valid loss: 1.2693, Valid acc: 0.4716\n",
      "Epoch 9:\n",
      "Train loss: 1.1177, Train acc: 0.5472\n",
      "Valid loss: 1.1146, Valid acc: 0.5853\n",
      "Epoch 10:\n",
      "Train loss: 1.0521, Train acc: 0.5690\n",
      "Valid loss: 1.1998, Valid acc: 0.5349\n",
      "Epoch 11:\n",
      "Train loss: 0.9965, Train acc: 0.6071\n",
      "Valid loss: 1.0045, Valid acc: 0.6266\n",
      "Epoch 12:\n",
      "Train loss: 0.9566, Train acc: 0.6243\n",
      "Valid loss: 1.0233, Valid acc: 0.6064\n",
      "Epoch 13:\n",
      "Train loss: 0.9386, Train acc: 0.6408\n",
      "Valid loss: 1.0283, Valid acc: 0.6193\n",
      "Epoch 14:\n",
      "Train loss: 0.9128, Train acc: 0.6502\n",
      "Valid loss: 1.1990, Valid acc: 0.5716\n",
      "Epoch 15:\n",
      "Train loss: 0.8955, Train acc: 0.6513\n",
      "Valid loss: 0.9644, Valid acc: 0.6385\n",
      "Epoch 16:\n",
      "Train loss: 0.8762, Train acc: 0.6534\n",
      "Valid loss: 1.0871, Valid acc: 0.5881\n",
      "Epoch 17:\n",
      "Train loss: 0.8580, Train acc: 0.6632\n",
      "Valid loss: 1.0007, Valid acc: 0.6211\n",
      "Epoch 18:\n",
      "Train loss: 0.8381, Train acc: 0.6722\n",
      "Valid loss: 0.9805, Valid acc: 0.6367\n",
      "Epoch 19:\n",
      "Train loss: 0.8173, Train acc: 0.6910\n",
      "Valid loss: 0.9278, Valid acc: 0.6404\n",
      "Epoch 20:\n",
      "Train loss: 0.8046, Train acc: 0.6818\n",
      "Valid loss: 0.8810, Valid acc: 0.6743\n",
      "Epoch 21:\n",
      "Train loss: 0.7980, Train acc: 0.6903\n",
      "Valid loss: 1.0243, Valid acc: 0.6202\n",
      "Epoch 22:\n",
      "Train loss: 0.7897, Train acc: 0.6946\n",
      "Valid loss: 0.8613, Valid acc: 0.6927\n",
      "Epoch 23:\n",
      "Train loss: 0.7558, Train acc: 0.7008\n",
      "Valid loss: 0.8612, Valid acc: 0.6761\n",
      "Epoch 24:\n",
      "Train loss: 0.7421, Train acc: 0.7166\n",
      "Valid loss: 0.8198, Valid acc: 0.6817\n",
      "Epoch 25:\n",
      "Train loss: 0.7277, Train acc: 0.7327\n",
      "Valid loss: 0.9633, Valid acc: 0.6954\n",
      "Epoch 26:\n",
      "Train loss: 0.7196, Train acc: 0.7510\n",
      "Valid loss: 0.7988, Valid acc: 0.7284\n",
      "Epoch 27:\n",
      "Train loss: 0.6831, Train acc: 0.7719\n",
      "Valid loss: 0.8120, Valid acc: 0.7239\n",
      "Epoch 28:\n",
      "Train loss: 0.6586, Train acc: 0.7847\n",
      "Valid loss: 0.8591, Valid acc: 0.7312\n",
      "Epoch 29:\n",
      "Train loss: 0.6430, Train acc: 0.8017\n",
      "Valid loss: 0.7989, Valid acc: 0.7431\n",
      "Epoch 30:\n",
      "Train loss: 0.6150, Train acc: 0.8120\n",
      "Valid loss: 0.9339, Valid acc: 0.7147\n",
      "Epoch 31:\n",
      "Train loss: 0.6069, Train acc: 0.8200\n",
      "Valid loss: 0.8039, Valid acc: 0.7587\n",
      "Epoch 32:\n",
      "Train loss: 0.5785, Train acc: 0.8255\n",
      "Valid loss: 0.7601, Valid acc: 0.7761\n",
      "Epoch 33:\n",
      "Train loss: 0.5633, Train acc: 0.8354\n",
      "Valid loss: 0.8039, Valid acc: 0.7615\n",
      "Epoch 34:\n",
      "Train loss: 0.5649, Train acc: 0.8404\n",
      "Valid loss: 0.7993, Valid acc: 0.7752\n",
      "Epoch 35:\n",
      "Train loss: 0.5347, Train acc: 0.8478\n",
      "Valid loss: 0.7486, Valid acc: 0.7752\n",
      "Epoch 36:\n",
      "Train loss: 0.5466, Train acc: 0.8439\n",
      "Valid loss: 0.9518, Valid acc: 0.7257\n",
      "Epoch 37:\n",
      "Train loss: 0.5269, Train acc: 0.8553\n",
      "Valid loss: 0.7730, Valid acc: 0.7642\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy average_last_3: 0.8000\n",
      "Epoch 1:\n",
      "Train loss: 1.6536, Train acc: 0.2364\n",
      "Valid loss: 1.6393, Valid acc: 0.2615\n",
      "Epoch 2:\n",
      "Train loss: 1.6453, Train acc: 0.2416\n",
      "Valid loss: 1.6433, Valid acc: 0.2679\n",
      "Epoch 3:\n",
      "Train loss: 1.5595, Train acc: 0.3308\n",
      "Valid loss: 1.4908, Valid acc: 0.3899\n",
      "Epoch 4:\n",
      "Train loss: 1.4400, Train acc: 0.3968\n",
      "Valid loss: 1.4362, Valid acc: 0.4174\n",
      "Epoch 5:\n",
      "Train loss: 1.3414, Train acc: 0.4431\n",
      "Valid loss: 1.3265, Valid acc: 0.4505\n",
      "Epoch 6:\n",
      "Train loss: 1.2504, Train acc: 0.4851\n",
      "Valid loss: 1.2980, Valid acc: 0.4817\n",
      "Epoch 7:\n",
      "Train loss: 1.1877, Train acc: 0.5209\n",
      "Valid loss: 1.2232, Valid acc: 0.5211\n",
      "Epoch 8:\n",
      "Train loss: 1.1473, Train acc: 0.5520\n",
      "Valid loss: 1.1746, Valid acc: 0.5514\n",
      "Epoch 9:\n",
      "Train loss: 1.1119, Train acc: 0.5660\n",
      "Valid loss: 1.2140, Valid acc: 0.5569\n",
      "Epoch 10:\n",
      "Train loss: 1.0817, Train acc: 0.5809\n",
      "Valid loss: 1.1749, Valid acc: 0.5413\n",
      "Epoch 11:\n",
      "Train loss: 1.0371, Train acc: 0.6126\n",
      "Valid loss: 1.1435, Valid acc: 0.6073\n",
      "Epoch 12:\n",
      "Train loss: 1.0078, Train acc: 0.6229\n",
      "Valid loss: 1.1080, Valid acc: 0.5771\n",
      "Epoch 13:\n",
      "Train loss: 0.9863, Train acc: 0.6408\n",
      "Valid loss: 1.0703, Valid acc: 0.5789\n",
      "Epoch 14:\n",
      "Train loss: 0.9525, Train acc: 0.6552\n",
      "Valid loss: 1.0245, Valid acc: 0.6303\n",
      "Epoch 15:\n",
      "Train loss: 0.9360, Train acc: 0.6641\n",
      "Valid loss: 1.0313, Valid acc: 0.6422\n",
      "Epoch 16:\n",
      "Train loss: 0.9095, Train acc: 0.6804\n",
      "Valid loss: 0.9697, Valid acc: 0.6514\n",
      "Epoch 17:\n",
      "Train loss: 0.8818, Train acc: 0.7054\n",
      "Valid loss: 1.0106, Valid acc: 0.6771\n",
      "Epoch 18:\n",
      "Train loss: 0.8403, Train acc: 0.7251\n",
      "Valid loss: 1.0012, Valid acc: 0.6670\n",
      "Epoch 19:\n",
      "Train loss: 0.7967, Train acc: 0.7522\n",
      "Valid loss: 1.0274, Valid acc: 0.6936\n",
      "Epoch 20:\n",
      "Train loss: 0.7730, Train acc: 0.7616\n",
      "Valid loss: 0.8885, Valid acc: 0.7294\n",
      "Epoch 21:\n",
      "Train loss: 0.7688, Train acc: 0.7691\n",
      "Valid loss: 0.8594, Valid acc: 0.7229\n",
      "Epoch 22:\n",
      "Train loss: 0.7301, Train acc: 0.7742\n",
      "Valid loss: 0.9061, Valid acc: 0.6982\n",
      "Epoch 23:\n",
      "Train loss: 0.7268, Train acc: 0.7838\n",
      "Valid loss: 0.8701, Valid acc: 0.7440\n",
      "Epoch 24:\n",
      "Train loss: 0.7380, Train acc: 0.7804\n",
      "Valid loss: 0.8665, Valid acc: 0.7303\n",
      "Epoch 25:\n",
      "Train loss: 0.7196, Train acc: 0.7884\n",
      "Valid loss: 0.8335, Valid acc: 0.7349\n",
      "Epoch 26:\n",
      "Train loss: 0.6792, Train acc: 0.8042\n",
      "Valid loss: 0.8970, Valid acc: 0.7257\n",
      "Epoch 27:\n",
      "Train loss: 0.6902, Train acc: 0.7969\n",
      "Valid loss: 0.8619, Valid acc: 0.7303\n",
      "Epoch 28:\n",
      "Train loss: 0.6789, Train acc: 0.8033\n",
      "Valid loss: 0.9103, Valid acc: 0.7422\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy average_last_4: 0.7980\n",
      "Epoch 1:\n",
      "Train loss: 1.5250, Train acc: 0.3833\n",
      "Valid loss: 1.4189, Valid acc: 0.4450\n",
      "Epoch 2:\n",
      "Train loss: 1.3166, Train acc: 0.4883\n",
      "Valid loss: 1.3136, Valid acc: 0.4972\n",
      "Epoch 3:\n",
      "Train loss: 1.1731, Train acc: 0.5724\n",
      "Valid loss: 1.1743, Valid acc: 0.5624\n",
      "Epoch 4:\n",
      "Train loss: 1.0392, Train acc: 0.6398\n",
      "Valid loss: 1.0037, Valid acc: 0.6422\n",
      "Epoch 5:\n",
      "Train loss: 0.8820, Train acc: 0.7091\n",
      "Valid loss: 0.8659, Valid acc: 0.6917\n",
      "Epoch 6:\n",
      "Train loss: 0.7791, Train acc: 0.7329\n",
      "Valid loss: 0.7545, Valid acc: 0.7339\n",
      "Epoch 7:\n",
      "Train loss: 0.7127, Train acc: 0.7579\n",
      "Valid loss: 0.7183, Valid acc: 0.7450\n",
      "Epoch 8:\n",
      "Train loss: 0.6686, Train acc: 0.7705\n",
      "Valid loss: 0.7032, Valid acc: 0.7440\n",
      "Epoch 9:\n",
      "Train loss: 0.6370, Train acc: 0.7836\n",
      "Valid loss: 0.6921, Valid acc: 0.7431\n",
      "Epoch 10:\n",
      "Train loss: 0.6068, Train acc: 0.7900\n",
      "Valid loss: 0.6542, Valid acc: 0.7578\n",
      "Epoch 11:\n",
      "Train loss: 0.5809, Train acc: 0.8019\n",
      "Valid loss: 0.6640, Valid acc: 0.7706\n",
      "Epoch 12:\n",
      "Train loss: 0.5542, Train acc: 0.8099\n",
      "Valid loss: 0.6031, Valid acc: 0.7835\n",
      "Epoch 13:\n",
      "Train loss: 0.5366, Train acc: 0.8189\n",
      "Valid loss: 0.6105, Valid acc: 0.7862\n",
      "Epoch 14:\n",
      "Train loss: 0.5092, Train acc: 0.8244\n",
      "Valid loss: 0.5747, Valid acc: 0.8028\n",
      "Epoch 15:\n",
      "Train loss: 0.4917, Train acc: 0.8326\n",
      "Valid loss: 0.5988, Valid acc: 0.7908\n",
      "Epoch 16:\n",
      "Train loss: 0.4684, Train acc: 0.8420\n",
      "Valid loss: 0.5827, Valid acc: 0.7853\n",
      "Epoch 17:\n",
      "Train loss: 0.4568, Train acc: 0.8427\n",
      "Valid loss: 0.5347, Valid acc: 0.8092\n",
      "Epoch 18:\n",
      "Train loss: 0.4395, Train acc: 0.8521\n",
      "Valid loss: 0.5319, Valid acc: 0.8220\n",
      "Epoch 19:\n",
      "Train loss: 0.4229, Train acc: 0.8595\n",
      "Valid loss: 0.5362, Valid acc: 0.8119\n",
      "Epoch 20:\n",
      "Train loss: 0.4050, Train acc: 0.8666\n",
      "Valid loss: 0.5730, Valid acc: 0.7917\n",
      "Epoch 21:\n",
      "Train loss: 0.3938, Train acc: 0.8691\n",
      "Valid loss: 0.5263, Valid acc: 0.8193\n",
      "Epoch 22:\n",
      "Train loss: 0.3820, Train acc: 0.8744\n",
      "Valid loss: 0.5370, Valid acc: 0.8138\n",
      "Epoch 23:\n",
      "Train loss: 0.3720, Train acc: 0.8760\n",
      "Valid loss: 0.5550, Valid acc: 0.8202\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy max: 0.8300\n",
      "Epoch 1:\n",
      "Train loss: 1.5597, Train acc: 0.3278\n",
      "Valid loss: 1.4264, Valid acc: 0.4257\n",
      "Epoch 2:\n",
      "Train loss: 1.3672, Train acc: 0.4365\n",
      "Valid loss: 1.2781, Valid acc: 0.4725\n",
      "Epoch 3:\n",
      "Train loss: 1.1977, Train acc: 0.5314\n",
      "Valid loss: 1.0983, Valid acc: 0.5771\n",
      "Epoch 4:\n",
      "Train loss: 1.0318, Train acc: 0.6151\n",
      "Valid loss: 1.0354, Valid acc: 0.6073\n",
      "Epoch 5:\n",
      "Train loss: 0.8912, Train acc: 0.6864\n",
      "Valid loss: 0.8718, Valid acc: 0.6927\n",
      "Epoch 6:\n",
      "Train loss: 0.8007, Train acc: 0.7182\n",
      "Valid loss: 0.7902, Valid acc: 0.7330\n",
      "Epoch 7:\n",
      "Train loss: 0.7379, Train acc: 0.7503\n",
      "Valid loss: 0.7479, Valid acc: 0.7422\n",
      "Epoch 8:\n",
      "Train loss: 0.6835, Train acc: 0.7740\n",
      "Valid loss: 0.7140, Valid acc: 0.7523\n",
      "Epoch 9:\n",
      "Train loss: 0.6518, Train acc: 0.7795\n",
      "Valid loss: 0.6710, Valid acc: 0.7679\n",
      "Epoch 10:\n",
      "Train loss: 0.6051, Train acc: 0.7999\n",
      "Valid loss: 0.6597, Valid acc: 0.7734\n",
      "Epoch 11:\n",
      "Train loss: 0.5844, Train acc: 0.8090\n",
      "Valid loss: 0.6519, Valid acc: 0.7853\n",
      "Epoch 12:\n",
      "Train loss: 0.5602, Train acc: 0.8177\n",
      "Valid loss: 0.6860, Valid acc: 0.7661\n",
      "Epoch 13:\n",
      "Train loss: 0.5332, Train acc: 0.8251\n",
      "Valid loss: 0.6007, Valid acc: 0.8018\n",
      "Epoch 14:\n",
      "Train loss: 0.5136, Train acc: 0.8299\n",
      "Valid loss: 0.5917, Valid acc: 0.8055\n",
      "Epoch 15:\n",
      "Train loss: 0.4913, Train acc: 0.8416\n",
      "Valid loss: 0.6076, Valid acc: 0.8083\n",
      "Epoch 16:\n",
      "Train loss: 0.4782, Train acc: 0.8443\n",
      "Valid loss: 0.6080, Valid acc: 0.8092\n",
      "Epoch 17:\n",
      "Train loss: 0.4594, Train acc: 0.8528\n",
      "Valid loss: 0.6947, Valid acc: 0.7826\n",
      "Epoch 18:\n",
      "Train loss: 0.4460, Train acc: 0.8560\n",
      "Valid loss: 0.6769, Valid acc: 0.7844\n",
      "Epoch 19:\n",
      "Train loss: 0.4241, Train acc: 0.8659\n",
      "Valid loss: 0.5737, Valid acc: 0.8083\n",
      "Epoch 20:\n",
      "Train loss: 0.4058, Train acc: 0.8700\n",
      "Valid loss: 0.5848, Valid acc: 0.8073\n",
      "Epoch 21:\n",
      "Train loss: 0.3944, Train acc: 0.8735\n",
      "Valid loss: 0.5510, Valid acc: 0.8248\n",
      "Epoch 22:\n",
      "Train loss: 0.3797, Train acc: 0.8819\n",
      "Valid loss: 0.5463, Valid acc: 0.8128\n",
      "Epoch 23:\n",
      "Train loss: 0.3736, Train acc: 0.8829\n",
      "Valid loss: 0.5301, Valid acc: 0.8266\n",
      "Epoch 24:\n",
      "Train loss: 0.3742, Train acc: 0.8838\n",
      "Valid loss: 0.5312, Valid acc: 0.8248\n",
      "Epoch 25:\n",
      "Train loss: 0.3476, Train acc: 0.8925\n",
      "Valid loss: 0.5631, Valid acc: 0.8229\n",
      "Epoch 26:\n",
      "Train loss: 0.3357, Train acc: 0.8973\n",
      "Valid loss: 0.5101, Valid acc: 0.8367\n",
      "Epoch 27:\n",
      "Train loss: 0.3224, Train acc: 0.9023\n",
      "Valid loss: 0.5147, Valid acc: 0.8413\n",
      "Epoch 28:\n",
      "Train loss: 0.3089, Train acc: 0.9069\n",
      "Valid loss: 0.5344, Valid acc: 0.8367\n",
      "Epoch 29:\n",
      "Train loss: 0.3098, Train acc: 0.9051\n",
      "Valid loss: 0.5362, Valid acc: 0.8440\n",
      "Epoch 30:\n",
      "Train loss: 0.2909, Train acc: 0.9120\n",
      "Valid loss: 0.5962, Valid acc: 0.8128\n",
      "Epoch 31:\n",
      "Train loss: 0.2879, Train acc: 0.9117\n",
      "Valid loss: 0.5552, Valid acc: 0.8294\n",
      "Epoch 32:\n",
      "Train loss: 0.2659, Train acc: 0.9188\n",
      "Valid loss: 0.5950, Valid acc: 0.8083\n",
      "Epoch 33:\n",
      "Train loss: 0.2603, Train acc: 0.9230\n",
      "Valid loss: 0.5598, Valid acc: 0.8358\n",
      "Epoch 34:\n",
      "Train loss: 0.2567, Train acc: 0.9227\n",
      "Valid loss: 0.5765, Valid acc: 0.8294\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy mean: 0.8640\n",
      "Epoch 1:\n",
      "Train loss: 1.5349, Train acc: 0.3398\n",
      "Valid loss: 1.4168, Valid acc: 0.4110\n",
      "Epoch 2:\n",
      "Train loss: 1.3620, Train acc: 0.4530\n",
      "Valid loss: 1.2915, Valid acc: 0.5229\n",
      "Epoch 3:\n",
      "Train loss: 1.1976, Train acc: 0.5504\n",
      "Valid loss: 1.1545, Valid acc: 0.5780\n",
      "Epoch 4:\n",
      "Train loss: 1.0505, Train acc: 0.6116\n",
      "Valid loss: 1.0340, Valid acc: 0.6138\n",
      "Epoch 5:\n",
      "Train loss: 0.9157, Train acc: 0.6678\n",
      "Valid loss: 0.9763, Valid acc: 0.6294\n",
      "Epoch 6:\n",
      "Train loss: 0.8074, Train acc: 0.7155\n",
      "Valid loss: 0.8029, Valid acc: 0.7202\n",
      "Epoch 7:\n",
      "Train loss: 0.7223, Train acc: 0.7561\n",
      "Valid loss: 0.7698, Valid acc: 0.7202\n",
      "Epoch 8:\n",
      "Train loss: 0.6686, Train acc: 0.7742\n",
      "Valid loss: 0.7073, Valid acc: 0.7486\n",
      "Epoch 9:\n",
      "Train loss: 0.6413, Train acc: 0.7891\n",
      "Valid loss: 0.7054, Valid acc: 0.7394\n",
      "Epoch 10:\n",
      "Train loss: 0.6112, Train acc: 0.7964\n",
      "Valid loss: 0.6966, Valid acc: 0.7670\n",
      "Epoch 11:\n",
      "Train loss: 0.6034, Train acc: 0.7953\n",
      "Valid loss: 0.6186, Valid acc: 0.7954\n",
      "Epoch 12:\n",
      "Train loss: 0.5678, Train acc: 0.8081\n",
      "Valid loss: 0.6147, Valid acc: 0.7917\n",
      "Epoch 13:\n",
      "Train loss: 0.5422, Train acc: 0.8200\n",
      "Valid loss: 0.5982, Valid acc: 0.7972\n",
      "Epoch 14:\n",
      "Train loss: 0.5212, Train acc: 0.8237\n",
      "Valid loss: 0.5894, Valid acc: 0.8000\n",
      "Epoch 15:\n",
      "Train loss: 0.4923, Train acc: 0.8381\n",
      "Valid loss: 0.6237, Valid acc: 0.8028\n",
      "Epoch 16:\n",
      "Train loss: 0.4728, Train acc: 0.8434\n",
      "Valid loss: 0.5933, Valid acc: 0.8064\n",
      "Epoch 17:\n",
      "Train loss: 0.4673, Train acc: 0.8475\n",
      "Valid loss: 0.5777, Valid acc: 0.8009\n",
      "Epoch 18:\n",
      "Train loss: 0.4440, Train acc: 0.8558\n",
      "Valid loss: 0.5799, Valid acc: 0.8147\n",
      "Epoch 19:\n",
      "Train loss: 0.4268, Train acc: 0.8618\n",
      "Valid loss: 0.5734, Valid acc: 0.8165\n",
      "Epoch 20:\n",
      "Train loss: 0.4202, Train acc: 0.8657\n",
      "Valid loss: 0.5461, Valid acc: 0.8229\n",
      "Epoch 21:\n",
      "Train loss: 0.3932, Train acc: 0.8732\n",
      "Valid loss: 0.6447, Valid acc: 0.7954\n",
      "Epoch 22:\n",
      "Train loss: 0.3827, Train acc: 0.8790\n",
      "Valid loss: 0.5285, Valid acc: 0.8339\n",
      "Epoch 23:\n",
      "Train loss: 0.3624, Train acc: 0.8847\n",
      "Valid loss: 0.6428, Valid acc: 0.7890\n",
      "Epoch 24:\n",
      "Train loss: 0.3526, Train acc: 0.8870\n",
      "Valid loss: 0.5998, Valid acc: 0.8156\n",
      "Epoch 25:\n",
      "Train loss: 0.3416, Train acc: 0.8909\n",
      "Valid loss: 0.5255, Valid acc: 0.8367\n",
      "Epoch 26:\n",
      "Train loss: 0.3297, Train acc: 0.8939\n",
      "Valid loss: 0.5334, Valid acc: 0.8358\n",
      "Epoch 27:\n",
      "Train loss: 0.3247, Train acc: 0.9014\n",
      "Valid loss: 0.5293, Valid acc: 0.8312\n",
      "Epoch 28:\n",
      "Train loss: 0.3148, Train acc: 0.8975\n",
      "Valid loss: 0.5210, Valid acc: 0.8459\n",
      "Epoch 29:\n",
      "Train loss: 0.2929, Train acc: 0.9094\n",
      "Valid loss: 0.5185, Valid acc: 0.8477\n",
      "Epoch 30:\n",
      "Train loss: 0.2850, Train acc: 0.9094\n",
      "Valid loss: 0.5370, Valid acc: 0.8358\n",
      "Epoch 31:\n",
      "Train loss: 0.2791, Train acc: 0.9138\n",
      "Valid loss: 0.6130, Valid acc: 0.8156\n",
      "Epoch 32:\n",
      "Train loss: 0.2606, Train acc: 0.9237\n",
      "Valid loss: 0.5233, Valid acc: 0.8413\n",
      "Epoch 33:\n",
      "Train loss: 0.2575, Train acc: 0.9214\n",
      "Valid loss: 0.5249, Valid acc: 0.8404\n",
      "Epoch 34:\n",
      "Train loss: 0.2520, Train acc: 0.9216\n",
      "Valid loss: 0.5457, Valid acc: 0.8339\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy maxmean: 0.8600\n",
      "Epoch 1:\n",
      "Train loss: 1.3687, Train acc: 0.4752\n",
      "Valid loss: 1.2742, Valid acc: 0.5211\n",
      "Epoch 2:\n",
      "Train loss: 1.1281, Train acc: 0.5828\n",
      "Valid loss: 1.1232, Valid acc: 0.5954\n",
      "Epoch 3:\n",
      "Train loss: 1.0291, Train acc: 0.6249\n",
      "Valid loss: 1.0052, Valid acc: 0.6174\n",
      "Epoch 4:\n",
      "Train loss: 0.9487, Train acc: 0.6506\n",
      "Valid loss: 1.0119, Valid acc: 0.6193\n",
      "Epoch 5:\n",
      "Train loss: 0.8747, Train acc: 0.6956\n",
      "Valid loss: 0.9876, Valid acc: 0.6394\n",
      "Epoch 6:\n",
      "Train loss: 0.8005, Train acc: 0.7180\n",
      "Valid loss: 0.9158, Valid acc: 0.6706\n",
      "Epoch 7:\n",
      "Train loss: 0.7660, Train acc: 0.7487\n",
      "Valid loss: 0.8290, Valid acc: 0.7119\n",
      "Epoch 8:\n",
      "Train loss: 0.7061, Train acc: 0.7643\n",
      "Valid loss: 0.7430, Valid acc: 0.7505\n",
      "Epoch 9:\n",
      "Train loss: 0.6474, Train acc: 0.7914\n",
      "Valid loss: 0.8995, Valid acc: 0.7028\n",
      "Epoch 10:\n",
      "Train loss: 0.6088, Train acc: 0.7971\n",
      "Valid loss: 0.7532, Valid acc: 0.7459\n",
      "Epoch 11:\n",
      "Train loss: 0.5626, Train acc: 0.8134\n",
      "Valid loss: 0.7105, Valid acc: 0.7569\n",
      "Epoch 12:\n",
      "Train loss: 0.5282, Train acc: 0.8221\n",
      "Valid loss: 0.6660, Valid acc: 0.7761\n",
      "Epoch 13:\n",
      "Train loss: 0.4984, Train acc: 0.8308\n",
      "Valid loss: 0.7498, Valid acc: 0.7606\n",
      "Epoch 14:\n",
      "Train loss: 0.4691, Train acc: 0.8443\n",
      "Valid loss: 0.7591, Valid acc: 0.7688\n",
      "Epoch 15:\n",
      "Train loss: 0.4642, Train acc: 0.8478\n",
      "Valid loss: 0.6229, Valid acc: 0.8193\n",
      "Epoch 16:\n",
      "Train loss: 0.4325, Train acc: 0.8528\n",
      "Valid loss: 0.6138, Valid acc: 0.8037\n",
      "Epoch 17:\n",
      "Train loss: 0.3962, Train acc: 0.8716\n",
      "Valid loss: 0.7071, Valid acc: 0.7780\n",
      "Epoch 18:\n",
      "Train loss: 0.3878, Train acc: 0.8728\n",
      "Valid loss: 0.7239, Valid acc: 0.7881\n",
      "Epoch 19:\n",
      "Train loss: 0.3679, Train acc: 0.8833\n",
      "Valid loss: 0.6345, Valid acc: 0.8156\n",
      "Epoch 20:\n",
      "Train loss: 0.3433, Train acc: 0.8925\n",
      "Valid loss: 0.9883, Valid acc: 0.7064\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "Test Accuracy sum: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Set ideal hyperparameters from 2(a)\n",
    "if best_hyperparams[\"epochs ran\"] <= 50:\n",
    "    no_epoch = 50\n",
    "elif best_hyperparams[\"epochs ran\"] > 50 & best_hyperparams[\"epochs ran\"] <= 100:\n",
    "    no_epoch = 100\n",
    "else:\n",
    "    no_epoch = 200\n",
    "batch_size = best_hyperparams[\"batch_size\"]\n",
    "hidden_dim = best_hyperparams[\"hidden_dim\"]\n",
    "lr = best_hyperparams[\"lr\"]\n",
    "optimizer = best_hyperparams[\"optimizer\"]\n",
    "\n",
    "# Set regularization from 2(b)\n",
    "dropout = df_all.loc[df_all['test_acc'].idxmax(), 'dropout']\n",
    "weight_decay = df_all.loc[df_all['test_acc'].idxmax(), 'weight_decay']\n",
    "grad_clip = df_all.loc[df_all['test_acc'].idxmax(), 'grad_clip']\n",
    "max_norm = df_all.loc[df_all['test_acc'].idxmax(), 'max_norm']\n",
    "\n",
    "best_representation_technique = []\n",
    "best_representation_technique.append({'technique': 'baseline', 'test_acc': test_acc})\n",
    "\n",
    "# List and try all the methods, and save it to a dataframe\n",
    "techniques = ['average_last_2', 'average_last_3', 'average_last_4',\n",
    "              'max', 'mean', 'maxmean', 'sum']\n",
    "\n",
    "for technique in techniques:\n",
    "    results = representation_test(technique, batch_size, hidden_dim, lr, optimizer, no_epoch, weight_decay, dropout, grad_clip, max_norm)\n",
    "    best_representation_technique.append(results)\n",
    "\n",
    "df_rep = pd.DataFrame(best_representation_technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "718e1e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "technique",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "test_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f0ccfa23-b387-48b4-bc4e-70ddb27cffb0",
       "rows": [
        [
         "5",
         "mean",
         "0.864"
        ],
        [
         "6",
         "maxmean",
         "0.86"
        ],
        [
         "7",
         "sum",
         "0.85"
        ],
        [
         "0",
         "baseline",
         "0.83"
        ],
        [
         "4",
         "max",
         "0.83"
        ],
        [
         "1",
         "average_last_2",
         "0.826"
        ],
        [
         "2",
         "average_last_3",
         "0.8"
        ],
        [
         "3",
         "average_last_4",
         "0.798"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maxmean</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sum</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average_last_2</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>average_last_3</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average_last_4</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        technique  test_acc\n",
       "5            mean     0.864\n",
       "6         maxmean     0.860\n",
       "7             sum     0.850\n",
       "0        baseline     0.830\n",
       "4             max     0.830\n",
       "1  average_last_2     0.826\n",
       "2  average_last_3     0.800\n",
       "3  average_last_4     0.798"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort saved dataframe by test accuracy and print it\n",
    "df_rep_sorted = df_rep.sort_values(by='test_acc', ascending=False)\n",
    "df_rep_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a2b1c",
   "metadata": {},
   "source": [
    "### Answer (d):\n",
    "Sum pooling showed the best test accuracy out of all the methods, with accuracy of 0.846. To be fair, most of the methods demonstrate a test accuracy that is relatively similar to one another, with the exception of average_last_3 (0.666). Here, we speculate some of the reasons why these results are as such:\n",
    "\n",
    "1. Global pooling methods such as sum pooling aggregate information from all time steps, which allow the model to capture features from the entire sequence rather than just the final few tokens. In contrast, average-last-k methods only use the most recent hidden states and might lose earlier contextual queues, which could be more important in sentence representation\n",
    "2. Unlikely mean pooling, sum pooling preserves the magnitude of activations, which could be beneficial when longer or information dense sentence exert stronger influence on the classifier. Again, normalized methods (e.g. mean pooling/average-last-k) methods might dilute such signals, leading to lower performance\n",
    "3. Averaging several recent hidden states can introduce noisy or redundant representations because adjacent time steps could encode overlapping information, which could possible explain why average_last_3 performed worse than average_last_2 and average_last_4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120f1dd",
   "metadata": {},
   "source": [
    "**(e) Report topic-wise accuracy (accuracy for each topic) on the test set for the best model you have. Discuss what may cause the difference in accuracies across different topic categories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0bc89145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ideal hyperparameters from 2(a)\n",
    "if best_hyperparams[\"epochs ran\"] <= 50:\n",
    "    no_epoch = 50\n",
    "elif best_hyperparams[\"epochs ran\"] > 50 & best_hyperparams[\"epochs ran\"] <= 100:\n",
    "    no_epoch = 100\n",
    "else:\n",
    "    no_epoch = 200\n",
    "batch_size = best_hyperparams[\"batch_size\"]\n",
    "hidden_dim = best_hyperparams[\"hidden_dim\"]\n",
    "lr = best_hyperparams[\"lr\"]\n",
    "optimizer = best_hyperparams[\"optimizer\"]\n",
    "\n",
    "# Set regularization from 2(b)\n",
    "dropout = df_all.loc[df_all['test_acc'].idxmax(), 'dropout']\n",
    "weight_decay = df_all.loc[df_all['test_acc'].idxmax(), 'weight_decay']\n",
    "grad_clip = df_all.loc[df_all['test_acc'].idxmax(), 'grad_clip']\n",
    "max_norm = df_all.loc[df_all['test_acc'].idxmax(), 'max_norm']\n",
    "\n",
    "# Set best representation technique from 2(d)\n",
    "strategy = df_rep.loc[df_rep['test_acc'].idxmax(), 'technique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "74257ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.5599, Train acc: 0.3333\n",
      "Valid loss: 1.4576, Valid acc: 0.3936\n",
      "Epoch 2:\n",
      "Train loss: 1.3892, Train acc: 0.4193\n",
      "Valid loss: 1.3589, Valid acc: 0.4330\n",
      "Epoch 3:\n",
      "Train loss: 1.2760, Train acc: 0.4991\n",
      "Valid loss: 1.2469, Valid acc: 0.4917\n",
      "Epoch 4:\n",
      "Train loss: 1.1591, Train acc: 0.5699\n",
      "Valid loss: 1.1497, Valid acc: 0.5761\n",
      "Epoch 5:\n",
      "Train loss: 1.0623, Train acc: 0.6139\n",
      "Valid loss: 1.0367, Valid acc: 0.6064\n",
      "Epoch 6:\n",
      "Train loss: 0.9411, Train acc: 0.6557\n",
      "Valid loss: 0.8927, Valid acc: 0.6725\n",
      "Epoch 7:\n",
      "Train loss: 0.8231, Train acc: 0.7114\n",
      "Valid loss: 0.8174, Valid acc: 0.7028\n",
      "Epoch 8:\n",
      "Train loss: 0.7417, Train acc: 0.7430\n",
      "Valid loss: 0.7811, Valid acc: 0.7303\n",
      "Epoch 9:\n",
      "Train loss: 0.6792, Train acc: 0.7625\n",
      "Valid loss: 0.7073, Valid acc: 0.7578\n",
      "Epoch 10:\n",
      "Train loss: 0.6320, Train acc: 0.7822\n",
      "Valid loss: 0.6557, Valid acc: 0.7835\n",
      "Epoch 11:\n",
      "Train loss: 0.5753, Train acc: 0.8065\n",
      "Valid loss: 0.6135, Valid acc: 0.7982\n",
      "Epoch 12:\n",
      "Train loss: 0.5469, Train acc: 0.8171\n",
      "Valid loss: 0.6258, Valid acc: 0.7899\n",
      "Epoch 13:\n",
      "Train loss: 0.5023, Train acc: 0.8278\n",
      "Valid loss: 0.6102, Valid acc: 0.8018\n",
      "Epoch 14:\n",
      "Train loss: 0.4828, Train acc: 0.8409\n",
      "Valid loss: 0.5787, Valid acc: 0.8009\n",
      "Epoch 15:\n",
      "Train loss: 0.4647, Train acc: 0.8448\n",
      "Valid loss: 0.5783, Valid acc: 0.8055\n",
      "Epoch 16:\n",
      "Train loss: 0.4381, Train acc: 0.8581\n",
      "Valid loss: 0.5780, Valid acc: 0.8055\n",
      "Epoch 17:\n",
      "Train loss: 0.4207, Train acc: 0.8608\n",
      "Valid loss: 0.5771, Valid acc: 0.8092\n",
      "Epoch 18:\n",
      "Train loss: 0.4120, Train acc: 0.8650\n",
      "Valid loss: 0.6063, Valid acc: 0.8000\n",
      "Epoch 19:\n",
      "Train loss: 0.3851, Train acc: 0.8721\n",
      "Valid loss: 0.5516, Valid acc: 0.8257\n",
      "Epoch 20:\n",
      "Train loss: 0.3788, Train acc: 0.8760\n",
      "Valid loss: 0.5530, Valid acc: 0.8229\n",
      "Epoch 21:\n",
      "Train loss: 0.3592, Train acc: 0.8835\n",
      "Valid loss: 0.5294, Valid acc: 0.8239\n",
      "Epoch 22:\n",
      "Train loss: 0.3485, Train acc: 0.8835\n",
      "Valid loss: 0.5519, Valid acc: 0.8165\n",
      "Epoch 23:\n",
      "Train loss: 0.3413, Train acc: 0.8884\n",
      "Valid loss: 0.5587, Valid acc: 0.8128\n",
      "Epoch 24:\n",
      "Train loss: 0.3180, Train acc: 0.8980\n",
      "Valid loss: 0.5331, Valid acc: 0.8330\n",
      "Epoch 25:\n",
      "Train loss: 0.3092, Train acc: 0.8991\n",
      "Valid loss: 0.5454, Valid acc: 0.8275\n",
      "Epoch 26:\n",
      "Train loss: 0.3002, Train acc: 0.9049\n",
      "Valid loss: 0.5593, Valid acc: 0.8239\n",
      "Epoch 27:\n",
      "Train loss: 0.2865, Train acc: 0.9108\n",
      "Valid loss: 0.5493, Valid acc: 0.8248\n",
      "Epoch 28:\n",
      "Train loss: 0.2789, Train acc: 0.9083\n",
      "Valid loss: 0.5769, Valid acc: 0.8193\n",
      "Epoch 29:\n",
      "Train loss: 0.2713, Train acc: 0.9149\n",
      "Valid loss: 0.5503, Valid acc: 0.8220\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n"
     ]
    }
   ],
   "source": [
    "# Define the labels/topics for TREC dataset\n",
    "topics = [\"DESC\", \"ENTY\", \"HUM\", \"ABBR\", \"NUM\", \"LOC\"]\n",
    "topic_datasets = {}\n",
    "\n",
    "# Rerun training with best hyperparameters, regularisation and representation technique\n",
    "model = ClassifierRepresentationRNN(TEXT.vocab.vectors.numpy() , hidden_dim, strategy, dropout=dropout)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Initialise optimiser\n",
    "optimizer = optimizer.__class__(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if grad_clip == True:\n",
    "    train_losses, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch, grad_clip=True, max_norm=max_norm)\n",
    "else:\n",
    "    train_losses, _, _, valid_accuracies, _ = training_step(model, train_loader, valid_loader, optimizer, criterion, no_epoch)\n",
    "\n",
    "\n",
    "for topic in topics:\n",
    "    examples = [eg for eg in test_data.examples if eg.label == topic]\n",
    "    texts = [\" \".join(example.text) for example in examples]\n",
    "    labels = [LABEL.vocab.stoi[example.label] for example in examples]\n",
    "    topic_datasets[topic] = SentenceDataset(texts, labels, TEXT.vocab.stoi)\n",
    "\n",
    "# Define function to obtain test accuracy by topic\n",
    "def test_by_topic(model ,topic_dataset, batch_size, hidden_dim, strategy, dropout, optimizer, lr, weight_decay, grad_clip, max_norm, no_epoch):\n",
    "\n",
    "    test_acc = test_loop(model, DataLoader(topic_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn))\n",
    "\n",
    "    return {\n",
    "        'topic': topic_dataset,\n",
    "        'test_acc': test_acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c33d822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "94\n",
      "65\n",
      "9\n",
      "113\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "# Check length of each topic test dataset\n",
    "for dataset in topic_datasets.values():\n",
    "    print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c89cfc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "test_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b6486ca9-b747-43b8-97f6-c42665706c01",
       "rows": [
        [
         "0",
         "DESC",
         "0.9637681159420289"
        ],
        [
         "1",
         "ENTY",
         "0.574468085106383"
        ],
        [
         "2",
         "HUM",
         "0.8769230769230769"
        ],
        [
         "3",
         "ABBR",
         "0.6666666666666666"
        ],
        [
         "4",
         "NUM",
         "0.8584070796460177"
        ],
        [
         "5",
         "LOC",
         "0.9012345679012346"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DESC</td>\n",
       "      <td>0.963768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTY</td>\n",
       "      <td>0.574468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUM</td>\n",
       "      <td>0.876923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBR</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUM</td>\n",
       "      <td>0.858407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.901235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic  test_acc\n",
       "0  DESC  0.963768\n",
       "1  ENTY  0.574468\n",
       "2   HUM  0.876923\n",
       "3  ABBR  0.666667\n",
       "4   NUM  0.858407\n",
       "5   LOC  0.901235"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test accuracy into dataframe and print by topic\n",
    "acc_by_topic = []\n",
    "\n",
    "for topic, dataset in topic_datasets.items():\n",
    "    result = test_by_topic(model, dataset, batch_size, hidden_dim, strategy, dropout, optimizer, lr, weight_decay, grad_clip, max_norm, no_epoch)\n",
    "    acc_by_topic.append({'topic': topic, 'test_acc': result[\"test_acc\"]})\n",
    "\n",
    "df_topics = pd.DataFrame(acc_by_topic)\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e91fd",
   "metadata": {},
   "source": [
    "### Answer (e):\n",
    "The model performs best on DESC (description) and HUM (human) questions, and performs worst on ENTY (entity) and ABBR (abbreviation) questions. \n",
    "- One reason for the poor performance on ENTY questions is that the question type may be more diverse in its type of questions. For example, ENTY questions tend to use “what” or “which” in the question, and these words are used in other topics as well. Compared to the topic HUM which has almost exclusive use of “who”, it would be harder for the model to distinguish ENTY questions for other topics.\n",
    "- One reason for the poorer performance for ABBR questions is the small number of samples available in the training and testing data. There are only around 70 questions in our training data with 4362 questions, and 9 questions in the test set, which would lead to the model not being as well trained to distinguish ABBR questions, especially on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c5fe3",
   "metadata": {},
   "source": [
    "## End of Qn 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SC4002-NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
