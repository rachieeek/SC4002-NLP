{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f38925a",
   "metadata": {},
   "source": [
    "# Setup & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de2b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import torch\n",
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed = 0):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(888)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn as nn\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233d1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_artifacts():\n",
    "    # Load previously saved artifacts from Part 1\n",
    "\n",
    "    LOAD_PREPARED = True  \n",
    "    if LOAD_PREPARED:\n",
    "        bundle = torch.load(\"trec_artifacts.pt\", map_location=\"cpu\")\n",
    "\n",
    "\n",
    "        TEXT = data.Field(**bundle[\"text_field_kwargs\"])\n",
    "        LABEL = data.LabelField(**bundle[\"label_field_kwargs\"])\n",
    "\n",
    "        fields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "\n",
    "        def rebuild(dataset_blob):\n",
    "            examples = [\n",
    "                data.Example.fromlist([item[\"tokens\"], item[\"label\"]], fields)\n",
    "                for item in dataset_blob\n",
    "            ]\n",
    "            return data.Dataset(examples, fields)\n",
    "\n",
    "        train_data = rebuild(bundle[\"train_examples\"])\n",
    "        valid_data = rebuild(bundle[\"valid_examples\"])\n",
    "        test_data  = rebuild(bundle[\"test_examples\"])\n",
    "\n",
    "        for ds in (train_data, valid_data, test_data):\n",
    "            ds.sort_key = lambda ex: len(ex.text)\n",
    "\n",
    "        TEXT.build_vocab([])\n",
    "        TEXT.vocab.itos = bundle[\"text_vocab_itos\"]\n",
    "        unk_token = TEXT.unk_token\n",
    "        if unk_token not in TEXT.vocab.itos:\n",
    "            raise ValueError(\"UNK token missing from serialized vocabulary.\")\n",
    "        unk_index = TEXT.vocab.itos.index(unk_token)\n",
    "        TEXT.vocab.stoi = defaultdict(lambda: unk_index,\n",
    "                                    {tok: i for i, tok in enumerate(TEXT.vocab.itos)})\n",
    "        TEXT.vocab.vectors = bundle[\"text_vocab_vectors\"]\n",
    "\n",
    "        LABEL.build_vocab([])\n",
    "        LABEL.vocab.itos = bundle[\"label_vocab_itos\"]\n",
    "        LABEL.vocab.stoi = {tok: i for i, tok in enumerate(LABEL.vocab.itos)}\n",
    "\n",
    "\n",
    "\n",
    "        pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "        train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "            (train_data, valid_data, test_data),\n",
    "            batch_size=bundle[\"batch_size\"],\n",
    "            sort_within_batch=True,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        print(\"Artifacts loaded.\")\n",
    "        return (bundle, TEXT, LABEL,\n",
    "                train_data, valid_data, test_data,\n",
    "                train_iter, valid_iter, test_iter,\n",
    "                pretrained_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359302d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts loaded.\n"
     ]
    }
   ],
   "source": [
    "(bundle, TEXT, LABEL,\n",
    " train_data, valid_data, test_data,\n",
    " train_iter, valid_iter, test_iter,\n",
    " pretrained_embeddings) = load_artifacts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd7f48",
   "metadata": {},
   "source": [
    "## From 2e.\n",
    "| Topic | Test Accuracy |\n",
    "|-------|--------------|\n",
    "| DESC  | 0.934783     |\n",
    "| **ENTY**  | **0.648936**     |\n",
    "| HUM   | 0.907692     |\n",
    "| **ABBR**  | **0.333333**     |\n",
    "| NUM   | 0.946903     |\n",
    "| LOC   | 0.876543     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d6f5b",
   "metadata": {},
   "source": [
    "## Weakest topics:\n",
    "1. ABBR (33.3%): Small number of samples available in the training and testing data.\n",
    "2. ENTY (64.9%): Diverse questions, overlapping patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b931bfa",
   "metadata": {},
   "source": [
    "## Design 1: Data Augmentation\n",
    "\n",
    "In this strategy to tackle the scarcity of ABBR samples and the diverse wording of ENTY, more ABBR and ENTY samples are synthesised using Easy Data Augmentation (EDA) without external dependencies. This would expose the model to more instances of ABBR and ENTY samples during training. \n",
    "\n",
    "Upon exploration of the dataset, it has been noticed that ABBR samples only comprised of 1.5% of the training data. \n",
    "To reduce imbalance, we have taken a conservative approach to increase ABBR and ENTY data samples by 3  and 1.5 times respectively. In the training dataset, the number of ABBR data increased from 66 samples to 198 samples (3x) while the number of ENTY data samples increased from 984 samples to 1,476 samples (1.5x)\n",
    "\n",
    "To ensure a fair evaluation, the RNN model of part 2 was retrained on the oversampled training dataset with the optimal hyperparameters obtained from part 2. Rather than continuing training from the previously saved model, retraining isolates the effect of oversampling and ensures that improvements can be attributed to the data balancing strategy rather than additional fine-tuning on a pre-trained model.\n",
    "\n",
    "To test this design, the ClassifierRepresentationRNN model from (2e) with the optimal hyperparameters derived from Part 2 will be used and topic wise accuracy results will be compared to the ones in 2e. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e88c95",
   "metadata": {},
   "source": [
    "### Optimal Hyperparameters: \n",
    "- Learning Rate: 0.0001\n",
    "- Optimizer: Adam\n",
    "- Batch Size: 64\n",
    "- Hidden Dimension: 256\n",
    "- Dropout: 0.4\n",
    "- Pooling: Max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80db5289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling: Counter({'HUM': 1000, 'ENTY': 984, 'DESC': 906, 'NUM': 739, 'LOC': 667, 'ABBR': 66})\n"
     ]
    }
   ],
   "source": [
    "label_counts = Counter([ex.label for ex in train_data.examples])\n",
    "print(\"Before oversampling:\", label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee64057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transpose from [seq_len, batch] -> [batch, seq_len]\n",
    "def extract_batch(batch):\n",
    "    if isinstance(batch.text, (tuple, list)):\n",
    "        text = batch.text[0] \n",
    "    else:\n",
    "        text = batch.text\n",
    "    \n",
    "    labels = batch.label\n",
    "    if text.dim() == 2 and text.size(0) != labels.size(0):\n",
    "        text = text.transpose(0, 1)\n",
    "    \n",
    "    return text, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61746d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BucketIterator with batch_size=64\n",
      "Train batches: 73\n",
      "Valid batches: 18\n",
      "Test batches: 8\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# IMPT: Rerun cell below after data augmentation to recreate the BucketIterator with the augmented data before training\n",
    "# Recreate iterators with desired batch size\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"Using BucketIterator with batch_size={BATCH_SIZE}\")\n",
    "print(f\"Train batches: {len(train_iter)}\")\n",
    "print(f\"Valid batches: {len(valid_iter)}\")\n",
    "print(f\"Test batches: {len(test_iter)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912fe51a",
   "metadata": {},
   "source": [
    "## Data Augmentation: Easy Data Augmentation (EDA) Methodology\n",
    "\n",
    "EDA was applied to generate synthetic examples to increase sample size and diversity of training data, specifically ABBR and ENTY samples. The following EDA techniques were used: \n",
    "\n",
    "- Random Swap (rand_swap): Randomly select 2 tokens in a sentence and swap position for model to learn that position of words can vary without changing the overall meaning of the sample. \n",
    "\n",
    "- Random Deletion (rand_delete): Each token has a probability (p) of being deleted. This introduces noise or missing words that occurs in natural language. \n",
    "\n",
    "- Predefined templates: ENTY and ABBR templates are created with placeholders. New samples are generated using the structured question templates with the placeholder slots being filled with words from the dictionary of words created. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a07fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_swap(tokens, k=1):\n",
    "    tokens = tokens[:] \n",
    "    L = len(tokens)\n",
    "    for _ in range(k):\n",
    "        if L < 2: break\n",
    "        i, j = random.sample(range(L), 2)\n",
    "        tokens[i], tokens[j] = tokens[j], tokens[i]\n",
    "    return tokens\n",
    "\n",
    "def rand_delete(tokens, p=0.1):\n",
    "    keep = [t for t in tokens if random.random() > p]\n",
    "    return keep if len(keep) >= 3 else tokens\n",
    "\n",
    "def eda_augment(tokens, swaps=1, del_p=0.1):\n",
    "    x = rand_swap(tokens, swaps)\n",
    "    x = rand_delete(x, del_p)\n",
    "    return x\n",
    "\n",
    "# ---- ENTY templates ----\n",
    "ENTY_TEMPLATES = [\n",
    "    [\"what\", \"is\", \"the\", \"{category}\", \"of\", \"{item}\",\"?\"],\n",
    "    [\"which\", \"{object}\", \"is\", \"known\", \"for\", \"{desc}\",\"?\"],\n",
    "    [\"what\", \"{thing}\", \"is\", \"used\", \"for\", \"{desc}\",\"?\"]\n",
    "]\n",
    "ENTY_SLOTS = {\n",
    "    \"category\": [\"type\", \"class\", \"category\"],\n",
    "    \"thing\": [\"device\", \"vehicle\", \"instrument\", \"tool\"],\n",
    "    \"item\": [\"quartz\", \"sushi\", \"python\", \"sahara\", \"euro\",\n",
    "          \"mars\", \"oak\", \"bitcoin\", \"cello\", \"tulip\"],\n",
    "    \"object\": [\"river\", \"planet\", \"currency\", \"instrument\",\n",
    "            \"continent\", \"metal\", \"festival\", \"element\"],\n",
    "    \"desc\": [\"navigation\", \"measuring time\", \"heat insulation\", \"data transfer\",\n",
    "            \"communication\", \"transportation\", \"electric conduction\"],\n",
    "\n",
    "}\n",
    "\n",
    "def make_enty_samples(n):\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        tmpl = random.choice(ENTY_TEMPLATES)\n",
    "        filled = []\n",
    "        for tok in tmpl:\n",
    "            if tok.startswith(\"{\") and tok.endswith(\"}\"):\n",
    "                key = tok[1:-1]\n",
    "                filled.append(random.choice(ENTY_SLOTS[key]))\n",
    "            else:\n",
    "                filled.append(tok)\n",
    "        outs.append(filled)\n",
    "    return outs\n",
    "\n",
    "# ---- ABBR template augmentation ----\n",
    "ABBR_BANK = [\n",
    "    (\"NASA\", \"National Aeronautics and Space Administration\"),\n",
    "    (\"NATO\", \"North Atlantic Treaty Organization\"),\n",
    "    (\"CPU\", \"Central Processing Unit\"),\n",
    "    (\"GPU\", \"Graphics Processing Unit\"),\n",
    "    (\"UNESCO\", \"United Nations Educational, Scientific and Cultural Organization\"),\n",
    "    (\"FBI\", \"Federal Bureau of Investigation\"),\n",
    "    (\"AI\", \"Artificial Intelligence\"),\n",
    "    (\"EU\", \"European Union\"),\n",
    "]\n",
    "ABBR_TEMPLATES = [\n",
    "    [\"what\", \"does\", \"{abbr}\", \"stand\", \"for\",\"?\"],\n",
    "    [\"what\", \"is\", \"the\", \"full\", \"form\", \"of\", \"{abbr}\",\"?\"],\n",
    "    [\"expand\", \"{abbr}\",\".\"],\n",
    "    [\"{abbr}\", \"stands\", \"for\", \"what\",\"?\"]\n",
    "]\n",
    "\n",
    "def make_abbr_samples(n):\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        abbr, _full = random.choice(ABBR_BANK)\n",
    "        tmpl = random.choice(ABBR_TEMPLATES)\n",
    "        filled = [abbr if t == \"{abbr}\" else t for t in tmpl]\n",
    "        filled = eda_augment(filled, swaps=1, del_p=0.0)\n",
    "        outs.append(filled)\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10285137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before augmentation: Counter({'HUM': 1000, 'ENTY': 984, 'DESC': 906, 'NUM': 739, 'LOC': 667, 'ABBR': 66})\n",
      "After augmentation : Counter({'ENTY': 1134, 'HUM': 1000, 'DESC': 906, 'NUM': 739, 'LOC': 667, 'ABBR': 198})\n"
     ]
    }
   ],
   "source": [
    "fields_list = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "label_itos  = LABEL.vocab.itos\n",
    "label_stoi  = LABEL.vocab.stoi\n",
    "\n",
    "print(\"Before augmentation:\", Counter([ex.label for ex in train_data.examples]))\n",
    "\n",
    "ABBR_STR = \"ABBR\"\n",
    "ENTY_STR = \"ENTY\"\n",
    "\n",
    "enty_new_tokens = make_enty_samples(n=150) \n",
    "abbr_new_tokens = make_abbr_samples(n=66*2)\n",
    "\n",
    "def tokens_to_examples(list_of_token_lists, label_str):\n",
    "    examples = []\n",
    "    for toks in list_of_token_lists:\n",
    "        ex = data.Example.fromlist([toks, label_str], fields_list)\n",
    "        examples.append(ex)\n",
    "    return examples\n",
    "\n",
    "enty_examples = tokens_to_examples(enty_new_tokens, ENTY_STR)\n",
    "abbr_examples = tokens_to_examples(abbr_new_tokens, ABBR_STR)\n",
    "\n",
    "train_data.examples.extend(enty_examples)\n",
    "train_data.examples.extend(abbr_examples)\n",
    "random.shuffle(train_data.examples)\n",
    "train_data.sort_key = lambda ex: len(ex.text)\n",
    "\n",
    "print(\"After augmentation :\", Counter([ex.label for ex in train_data.examples]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653c1b0",
   "metadata": {},
   "source": [
    "#### Classifier Representation RNN Model from Part 2 & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e048dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierRepresentationRNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, representation, dropout=0.0):\n",
    "        super(ClassifierRepresentationRNN, self).__init__()\n",
    "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 6) # 6 possible labels\n",
    "        self.representation = representation\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        # Conditional Logic to apply different representation techniques\n",
    "        if self.representation.startswith('average_last_'):\n",
    "            last_k = int(self.representation.split('_')[-1])\n",
    "            k = min(last_k, output.size(1))\n",
    "            rep = output[:, -k:, :].mean(dim=1)\n",
    "        elif self.representation == 'max':\n",
    "            rep, _ = torch.max(output, dim=1)\n",
    "        elif self.representation == 'mean':\n",
    "            rep = torch.mean(output, dim=1)\n",
    "        elif self.representation == 'maxmean':\n",
    "            max_pooled, _ = torch.max(output, dim=1)\n",
    "            mean_pooled = torch.mean(output, dim=1)\n",
    "            rep = (max_pooled + mean_pooled) / 2\n",
    "        elif self.representation == 'sum':\n",
    "            rep = torch.sum(output, dim=1)\n",
    "        else:\n",
    "            # Default: use last hidden state\n",
    "            rep = hidden[-1]\n",
    "\n",
    "        hidden = self.dropout(rep)\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training, evaluation, and testing loops\n",
    "def train_loop(model, iterator, optimizer, criterion, grad_clip=False, max_norm=1.0):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_examples = 0, 0, 0\n",
    "    \n",
    "    for batch in iterator:\n",
    "        texts, labels = extract_batch(batch)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip:\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total_examples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    avg_correct = total_correct / total_examples\n",
    "    return avg_loss, avg_correct\n",
    "\n",
    "def eval_loop(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_examples = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            texts, labels = extract_batch(batch)\n",
    "            # texts and labels are already on DEVICE\n",
    "            \n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_examples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    avg_correct = total_correct / total_examples\n",
    "    return avg_loss, avg_correct\n",
    "\n",
    "def test_loop(model, iterator):\n",
    "    model.eval()\n",
    "    total_correct, total_examples = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            texts, labels = extract_batch(batch)\n",
    "            outputs = model(texts)\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_examples += labels.size(0)\n",
    "\n",
    "    acc = total_correct / total_examples\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f60a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopper to prevent overfitting\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.max_validation_acc = float('-inf')\n",
    "\n",
    "    def early_stop(self, validation_acc):\n",
    "        if validation_acc > self.max_validation_acc + self.min_delta:\n",
    "            self.max_validation_acc = validation_acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa48a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture metrics and print training results per epoch\n",
    "def training_step(model, train_iter, valid_iter, optimizer, criterion, num_epochs, grad_clip=False, max_norm=1.0):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    early_stopper = EarlyStopper(patience=5, min_delta=0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Reinitialize epoch for BucketIterator\n",
    "        train_iter.init_epoch()\n",
    "        valid_iter.init_epoch()\n",
    "        \n",
    "        train_loss, train_acc = train_loop(model, train_iter, optimizer, criterion, grad_clip=grad_clip, max_norm=max_norm)\n",
    "        valid_loss, valid_acc = eval_loop(model, valid_iter, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}\")\n",
    "        print(f\"Valid loss: {valid_loss:.4f}, Valid acc: {valid_acc:.4f}\")\n",
    "\n",
    "        if early_stopper.early_stop(valid_acc):\n",
    "            print(\"Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\")\n",
    "            no_epochs = epoch+1\n",
    "            break\n",
    "\n",
    "        no_epochs = epoch+1\n",
    "\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies, no_epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753f9a8",
   "metadata": {},
   "source": [
    "#### Hyperparameters Obtained from Hyperparameters Tuning in Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c5ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "  Learning Rate: 0.0001\n",
      "  Batch Size: 64\n",
      "  Hidden Dimension: 256\n",
      "  Dropout: 0.4\n",
      "  Pooling: max\n",
      "  Max Epochs: 50\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters (best params from assignment)\n",
    "LR = 0.0001\n",
    "HIDDEN_DIM = 256\n",
    "DROPOUT = 0.4\n",
    "POOLING = 'max'\n",
    "NUM_EPOCHS = 50  # Max epochs (early stopping will stop earlier if needed)\n",
    "\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"  Learning Rate: {LR}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Hidden Dimension: {HIDDEN_DIM}\")\n",
    "print(f\"  Dropout: {DROPOUT}\")\n",
    "print(f\"  Pooling: {POOLING}\")\n",
    "print(f\"  Max Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2541ee",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664fe53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on cpu\n"
     ]
    }
   ],
   "source": [
    "model = ClassifierRepresentationRNN(\n",
    "    embedding_matrix=pretrained_embeddings.numpy(),\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    representation=POOLING,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Initialize optimizer (Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model initialized on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5237885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.6950, Train acc: 0.2670\n",
      "Valid loss: 1.6176, Valid acc: 0.2881\n",
      "Epoch 2:\n",
      "Train loss: 1.5772, Train acc: 0.3798\n",
      "Valid loss: 1.5527, Valid acc: 0.3495\n",
      "Epoch 3:\n",
      "Train loss: 1.4543, Train acc: 0.4640\n",
      "Valid loss: 1.4884, Valid acc: 0.3734\n",
      "Epoch 4:\n",
      "Train loss: 1.2783, Train acc: 0.5435\n",
      "Valid loss: 1.2904, Valid acc: 0.5202\n",
      "Epoch 5:\n",
      "Train loss: 1.0521, Train acc: 0.6471\n",
      "Valid loss: 1.0044, Valid acc: 0.6431\n",
      "Epoch 6:\n",
      "Train loss: 0.8308, Train acc: 0.7323\n",
      "Valid loss: 0.8374, Valid acc: 0.7055\n",
      "Epoch 7:\n",
      "Train loss: 0.6873, Train acc: 0.7888\n",
      "Valid loss: 0.7321, Valid acc: 0.7376\n",
      "Epoch 8:\n",
      "Train loss: 0.6102, Train acc: 0.8198\n",
      "Valid loss: 0.6967, Valid acc: 0.7514\n",
      "Epoch 9:\n",
      "Train loss: 0.5324, Train acc: 0.8478\n",
      "Valid loss: 0.6444, Valid acc: 0.7670\n",
      "Epoch 10:\n",
      "Train loss: 0.4698, Train acc: 0.8671\n",
      "Valid loss: 0.6109, Valid acc: 0.7817\n",
      "Epoch 11:\n",
      "Train loss: 0.4169, Train acc: 0.8844\n",
      "Valid loss: 0.6278, Valid acc: 0.7697\n",
      "Epoch 12:\n",
      "Train loss: 0.3919, Train acc: 0.8938\n",
      "Valid loss: 0.5969, Valid acc: 0.7899\n",
      "Epoch 13:\n",
      "Train loss: 0.3525, Train acc: 0.9081\n",
      "Valid loss: 0.5693, Valid acc: 0.7835\n",
      "Epoch 14:\n",
      "Train loss: 0.3264, Train acc: 0.9130\n",
      "Valid loss: 0.5444, Valid acc: 0.7945\n",
      "Epoch 15:\n",
      "Train loss: 0.2954, Train acc: 0.9246\n",
      "Valid loss: 0.5481, Valid acc: 0.7991\n",
      "Epoch 16:\n",
      "Train loss: 0.3400, Train acc: 0.9087\n",
      "Valid loss: 0.5438, Valid acc: 0.8046\n",
      "Epoch 17:\n",
      "Train loss: 0.2579, Train acc: 0.9365\n",
      "Valid loss: 0.5405, Valid acc: 0.8028\n",
      "Epoch 18:\n",
      "Train loss: 0.2392, Train acc: 0.9406\n",
      "Valid loss: 0.5208, Valid acc: 0.8009\n",
      "Epoch 19:\n",
      "Train loss: 0.2296, Train acc: 0.9444\n",
      "Valid loss: 0.5191, Valid acc: 0.8138\n",
      "Epoch 20:\n",
      "Train loss: 0.2127, Train acc: 0.9466\n",
      "Valid loss: 0.5109, Valid acc: 0.8202\n",
      "Epoch 21:\n",
      "Train loss: 0.1954, Train acc: 0.9537\n",
      "Valid loss: 0.5247, Valid acc: 0.8000\n",
      "Epoch 22:\n",
      "Train loss: 0.1792, Train acc: 0.9593\n",
      "Valid loss: 0.5194, Valid acc: 0.8119\n",
      "Epoch 23:\n",
      "Train loss: 0.1716, Train acc: 0.9591\n",
      "Valid loss: 0.5073, Valid acc: 0.8073\n",
      "Epoch 24:\n",
      "Train loss: 0.1565, Train acc: 0.9627\n",
      "Valid loss: 0.5286, Valid acc: 0.8110\n",
      "Epoch 25:\n",
      "Train loss: 0.1458, Train acc: 0.9686\n",
      "Valid loss: 0.5239, Valid acc: 0.8202\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "\n",
      "Training completed after 25 epochs\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_losses, train_accuracies, valid_losses, valid_accuracies, epochs_ran = training_step(\n",
    "    model=model,\n",
    "    train_iter=train_iter,\n",
    "    valid_iter=valid_iter,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    grad_clip=False,\n",
    "    max_norm=1.0\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed after {epochs_ran} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6353454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for per-topic accuracy evaluation\n",
    "def topic_eval_loop_rnn(model, iterator, label_vocab, device):\n",
    "    model.eval()\n",
    "    n = len(label_vocab.itos)\n",
    "    correct = [0] * n\n",
    "    total = [0] * n\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            texts, labels = extract_batch(batch)\n",
    "            outputs = model(texts)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            for p, y in zip(preds.tolist(), labels.tolist()):\n",
    "                total[y] += 1\n",
    "                correct[y] += int(p == y)\n",
    "    \n",
    "    per_topic = {}\n",
    "    for idx, lab in enumerate(label_vocab.itos):\n",
    "        per_topic[lab] = float('nan') if total[idx] == 0 else correct[idx] / total[idx]\n",
    "    \n",
    "    return per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff58029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic-wise accuracy for ABBR and ENTY Samples:\n",
      "  ENTY: 0.7872\n",
      "  ABBR: 0.8889\n"
     ]
    }
   ],
   "source": [
    "test_acc = test_loop(model, test_iter)\n",
    "topic_acc = topic_eval_loop_rnn(model, test_iter, LABEL.vocab, device=DEVICE)\n",
    "print(\"Topic-wise accuracy for ABBR and ENTY Samples:\")\n",
    "for k, v in topic_acc.items():\n",
    "    if k in (\"ABBR\", \"ENTY\"):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa257f",
   "metadata": {},
   "source": [
    "After applying EDA techniques, there was a significant improvement in topic-wise accuracy for ABBR and ENTY samples. The accuracy rate for ENTY increased from 0.6489 to 0.7872 while for ABBR, accuracy increased from 0.3333 to 0.8889.\n",
    "\n",
    "In the case ENTY class, this improvement shows the effectiveness of EDA in helping the model learn the linguistic nuances associated with ENTY recognition. As for ABBR, the significant increase in accuracy rate shows that the lack of samples in the original data was a limiting factor during model training. However, it is important to interpret this result with caution as the test set only contained 9 ABBR samples. Therefore, a single additional correct prediction can lead to a more than 10% increase in accuracy. Nonetheless, this result still highlights that the effectiveness of using EDA to enhance the model's understanding of the ABBR samples, which were previously underrepresented. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec569f7",
   "metadata": {},
   "source": [
    "# Design 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba97fa",
   "metadata": {},
   "source": [
    "## Model-side Strategy: Class-weighted Loss\n",
    "\n",
    "In the original TREC dataset, there is a strong class imbalance in categories such as ABBR, causing the trained model to perform poorly in topic-specific accuracy rates as the model would learn to be biased towards majority classes. \n",
    "\n",
    "Instead of modifying the dataset, a model focused strategy would be to make the loss function cost sensitive by introducing class-weighted loss. This would mean that misclassifying rare classes will incur a larger penalty than if a majority class is misclassified. \n",
    "\n",
    "To achieve this, class weights are introduced to the loss function. Class weights are inversely proportional to its frequency. The rest of the model architecture and hyperparameters from Part 2 remain unchanged, ensuring a fair comparison with the base RNN model used in 2e. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cf3874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts loaded.\n"
     ]
    }
   ],
   "source": [
    "# Reload original data (without data augmentation)\n",
    "(bundle, TEXT, LABEL,\n",
    " train_data, valid_data, test_data,\n",
    " train_iter, valid_iter, test_iter,\n",
    " pretrained_embeddings) = load_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd185619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BucketIterator with batch_size=64\n",
      "Train batches: 69\n",
      "Valid batches: 18\n",
      "Test batches: 8\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"Using BucketIterator with batch_size={BATCH_SIZE}\")\n",
    "print(f\"Train batches: {len(train_iter)}\")\n",
    "print(f\"Valid batches: {len(valid_iter)}\")\n",
    "print(f\"Test batches: {len(test_iter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d75d77be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([ 4.3620,  4.4329,  4.8146,  5.9026,  6.5397, 66.0909])\n"
     ]
    }
   ],
   "source": [
    "train_label_ids = [LABEL.vocab.stoi[ex.label] for ex in train_data.examples]\n",
    "\n",
    "counts = Counter(train_label_ids)\n",
    "num_classes = len(LABEL.vocab)\n",
    "total = sum(counts.values())\n",
    "\n",
    "# inverse-frequency weights\n",
    "weights = []\n",
    "for i in range(num_classes):\n",
    "    w = total / max(1, counts[i])\n",
    "    weights.append(w)\n",
    "\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to(DEVICE)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "criterion_weighted = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf112242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/_dd4c0bn1ws10nbrwf6ls6hc0000gn/T/ipykernel_82377/3286407227.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train loss: 1.7174, Train acc: 0.2359\n",
      "Valid loss: 1.6209, Valid acc: 0.3193\n",
      "Epoch 2:\n",
      "Train loss: 1.5735, Train acc: 0.3553\n",
      "Valid loss: 1.5386, Valid acc: 0.4257\n",
      "Epoch 3:\n",
      "Train loss: 1.4633, Train acc: 0.4507\n",
      "Valid loss: 1.4340, Valid acc: 0.4743\n",
      "Epoch 4:\n",
      "Train loss: 1.3177, Train acc: 0.5360\n",
      "Valid loss: 1.2817, Valid acc: 0.5367\n",
      "Epoch 5:\n",
      "Train loss: 1.1329, Train acc: 0.6041\n",
      "Valid loss: 1.0813, Valid acc: 0.6486\n",
      "Epoch 6:\n",
      "Train loss: 0.9295, Train acc: 0.7050\n",
      "Valid loss: 0.8930, Valid acc: 0.7339\n",
      "Epoch 7:\n",
      "Train loss: 0.7949, Train acc: 0.7572\n",
      "Valid loss: 0.8059, Valid acc: 0.7459\n",
      "Epoch 8:\n",
      "Train loss: 0.6943, Train acc: 0.7886\n",
      "Valid loss: 0.7624, Valid acc: 0.7413\n",
      "Epoch 9:\n",
      "Train loss: 0.6065, Train acc: 0.8219\n",
      "Valid loss: 0.6664, Valid acc: 0.7945\n",
      "Epoch 10:\n",
      "Train loss: 0.5463, Train acc: 0.8379\n",
      "Valid loss: 0.6429, Valid acc: 0.7972\n",
      "Epoch 11:\n",
      "Train loss: 0.4738, Train acc: 0.8597\n",
      "Valid loss: 0.5976, Valid acc: 0.8101\n",
      "Epoch 12:\n",
      "Train loss: 0.4293, Train acc: 0.8741\n",
      "Valid loss: 0.5622, Valid acc: 0.8064\n",
      "Epoch 13:\n",
      "Train loss: 0.3713, Train acc: 0.8998\n",
      "Valid loss: 0.5512, Valid acc: 0.8257\n",
      "Epoch 14:\n",
      "Train loss: 0.3442, Train acc: 0.9044\n",
      "Valid loss: 0.5256, Valid acc: 0.8239\n",
      "Epoch 15:\n",
      "Train loss: 0.3140, Train acc: 0.9147\n",
      "Valid loss: 0.5042, Valid acc: 0.8330\n",
      "Epoch 16:\n",
      "Train loss: 0.2917, Train acc: 0.9221\n",
      "Valid loss: 0.5166, Valid acc: 0.8257\n",
      "Epoch 17:\n",
      "Train loss: 0.2718, Train acc: 0.9253\n",
      "Valid loss: 0.5119, Valid acc: 0.8239\n",
      "Epoch 18:\n",
      "Train loss: 0.2630, Train acc: 0.9255\n",
      "Valid loss: 0.4981, Valid acc: 0.8321\n",
      "Epoch 19:\n",
      "Train loss: 0.2433, Train acc: 0.9342\n",
      "Valid loss: 0.4975, Valid acc: 0.8349\n",
      "Epoch 20:\n",
      "Train loss: 0.2235, Train acc: 0.9411\n",
      "Valid loss: 0.4811, Valid acc: 0.8431\n",
      "Epoch 21:\n",
      "Train loss: 0.2009, Train acc: 0.9514\n",
      "Valid loss: 0.4949, Valid acc: 0.8312\n",
      "Epoch 22:\n",
      "Train loss: 0.1844, Train acc: 0.9560\n",
      "Valid loss: 0.4745, Valid acc: 0.8495\n",
      "Epoch 23:\n",
      "Train loss: 0.1755, Train acc: 0.9583\n",
      "Valid loss: 0.4658, Valid acc: 0.8477\n",
      "Epoch 24:\n",
      "Train loss: 0.1722, Train acc: 0.9569\n",
      "Valid loss: 0.4813, Valid acc: 0.8376\n",
      "Epoch 25:\n",
      "Train loss: 0.1564, Train acc: 0.9633\n",
      "Valid loss: 0.4612, Valid acc: 0.8550\n",
      "Epoch 26:\n",
      "Train loss: 0.1533, Train acc: 0.9631\n",
      "Valid loss: 0.4607, Valid acc: 0.8495\n",
      "Epoch 27:\n",
      "Train loss: 0.1396, Train acc: 0.9668\n",
      "Valid loss: 0.4991, Valid acc: 0.8349\n",
      "Epoch 28:\n",
      "Train loss: 0.1466, Train acc: 0.9638\n",
      "Valid loss: 0.4504, Valid acc: 0.8615\n",
      "Epoch 29:\n",
      "Train loss: 0.1212, Train acc: 0.9734\n",
      "Valid loss: 0.4458, Valid acc: 0.8615\n",
      "Epoch 30:\n",
      "Train loss: 0.1097, Train acc: 0.9748\n",
      "Valid loss: 0.4902, Valid acc: 0.8505\n",
      "Epoch 31:\n",
      "Train loss: 0.1027, Train acc: 0.9778\n",
      "Valid loss: 0.4801, Valid acc: 0.8523\n",
      "Epoch 32:\n",
      "Train loss: 0.1184, Train acc: 0.9718\n",
      "Valid loss: 0.5201, Valid acc: 0.8431\n",
      "Epoch 33:\n",
      "Train loss: 0.0918, Train acc: 0.9810\n",
      "Valid loss: 0.4814, Valid acc: 0.8523\n",
      "Early Stopping Triggered! No Improvements to Validation Accuracy within Patience.\n",
      "\n",
      "Training completed after 33 epochs\n"
     ]
    }
   ],
   "source": [
    "model_w = ClassifierRepresentationRNN(\n",
    "    embedding_matrix=TEXT.vocab.vectors,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    representation=POOLING,\n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_w.parameters(), lr=1e-4)\n",
    "\n",
    "train_losses, train_accuracies, valid_losses, valid_accuracies, epochs_ran = training_step(\n",
    "    model=model_w,\n",
    "    train_iter=train_iter,\n",
    "    valid_iter=valid_iter,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    grad_clip=False,\n",
    "    max_norm=1.0\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed after {epochs_ran} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f68ad169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Test Accuracy: 0.8860\n",
      "Topic-wise accuracy for ABBR and ENTY Samples:\n",
      "  ENTY: 0.6809\n",
      "  ABBR: 0.6667\n"
     ]
    }
   ],
   "source": [
    "test_acc = test_loop(model_w,test_iter)\n",
    "print(f\"Overall Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "topic_acc = topic_eval_loop_rnn(model_w, test_iter, LABEL.vocab, device=DEVICE)\n",
    "print(\"Topic-wise accuracy for ABBR and ENTY Samples:\")\n",
    "for k, v in topic_acc.items():\n",
    "    if k in (\"ABBR\", \"ENTY\"):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2340588",
   "metadata": {},
   "source": [
    "After applying the class-weighted cross-entropy loss, the model had a noticeable improvement in the accuracy of ABBR and ENTY, which were the weaker topics. The accuracy of ENTY and ABBR increased from 0.6489 to 0.6809 and 0.3333 to 0.6667.\n",
    "\n",
    "Although class-weighted loss mainly targets highly underrepresented classes, ENTY still benefitted from this strategy as ENTY occurs less frequently than the dominant categories. On the other hand, for ABBR, the improvement was more significant, with its accuracy rate doubling. This highlights that the cost-sensitive training was effective in addressing the data imbalance. Hence, class-weighted loss is a practical approach to enhance performance of models when it comes to underrepresented classes without modifying the dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755d375",
   "metadata": {},
   "source": [
    "# Design 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6258a1",
   "metadata": {},
   "source": [
    "# Model-side Strategy: Multi-Task RNN: \n",
    "\n",
    "Rather than training separate models for each task, a multi-task RNN is trained to perform multiple related tasks simultaneously. In this model architecure, the model performs 2 related classification tasks simultaneously: \n",
    "1. Main task: Predict the topic label\n",
    "2. Auxiliary Task: A simpler task that helps the main task generalise better. \n",
    "Since we are targeting the topics ABBR and ENTY, the auxiliary task is designed to make the model more aware of these categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8552ef2",
   "metadata": {},
   "source": [
    "#### Auxiliary Tasks:\n",
    "\n",
    "Each sample can have additional binary indicators: \n",
    "- is_ABBR = 1 if the label is ABBR, otherwise = 0\n",
    "- is_ENTY = 1 if the label is ENTY, otherwise = 0\n",
    "\n",
    "During training of the model, the model learns these 3 objectives simultaneously: \n",
    "- Main: Predict topic \n",
    "- Auxiliary: Predict is_ABBR\n",
    "- Auxiliary: Predict is_ENTY\n",
    "\n",
    "Since main task is a multi-class classification, cross entropy loss is used. As for the auxiliary tasks, they are binary classification, thus binary cross entropy loss is used. During training, the gradients from all 3 tasks jointly updates the shared encoder as the total loss is a weighted combination of all 3 tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8410d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierRNNMultiTask(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, representation=\"max\", dropout=0.4, num_classes=6):\n",
    "        super().__init__()\n",
    "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float),\n",
    "            freeze=False\n",
    "        )\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.representation = representation\n",
    "        \n",
    "        # main classifier\n",
    "        self.fc_main = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        # auxiliary heads: is ABBR? is ENTY?\n",
    "        self.fc_abbr = nn.Linear(hidden_dim, 1)\n",
    "        self.fc_enty = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        emb = self.embedding(x)             # [B, L, E]\n",
    "        output, hidden = self.rnn(emb)      # output: [B, L, H]\n",
    "        \n",
    "        if self.representation == \"mean\":\n",
    "            rep = output.mean(dim=1)\n",
    "        elif self.representation == \"max\":\n",
    "            rep, _ = output.max(dim=1)\n",
    "        else:\n",
    "            rep = hidden[-1]                # last hidden\n",
    "        \n",
    "        rep = self.dropout(rep)\n",
    "        return rep\n",
    "\n",
    "    def forward(self, x):\n",
    "        rep = self.encode(x)                # [B, H]\n",
    "        logits_main = self.fc_main(rep)     # [B, C]\n",
    "        logit_abbr = self.fc_abbr(rep).squeeze(-1)  # [B]\n",
    "        logit_enty = self.fc_enty(rep).squeeze(-1)  # [B]\n",
    "        return logits_main, logit_abbr, logit_enty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7cc9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_idx = LABEL.vocab.stoi[\"ABBR\"]\n",
    "enty_idx = LABEL.vocab.stoi[\"ENTY\"]\n",
    "\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def multitask_loss(logits_main, logit_abbr, logit_enty, targets):\n",
    "    loss_main = criterion_ce(logits_main, targets)\n",
    "    \n",
    "    # build binary targets\n",
    "    target_abbr = (targets == abbr_idx).float()\n",
    "    target_enty = (targets == enty_idx).float()\n",
    "    \n",
    "    loss_abbr = bce(logit_abbr, target_abbr)\n",
    "    loss_enty = bce(logit_enty, target_enty)\n",
    "    \n",
    "    # weight auxiliaries (tune lambdas; start small)\n",
    "    return loss_main + 0.5 * loss_abbr + 0.5 * loss_enty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "980269cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multitask_rnn(\n",
    "    model,\n",
    "    train_iter,\n",
    "    valid_iter,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    patience=5,\n",
    "    grad_clip=True,\n",
    "    max_norm=1.0,\n",
    "    save_path=\"rnn_multitask_best.pt\"\n",
    "):\n",
    "    best_val_acc = -1.0\n",
    "    wait = 0\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch in train_iter:\n",
    "            texts, labels = extract_batch_multitaskRNN(batch, device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits_main, logit_abbr, logit_enty = model(texts)\n",
    "\n",
    "            loss = multitask_loss(logits_main, logit_abbr, logit_enty, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip:\n",
    "                clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = logits_main.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_examples += labels.size(0)\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss = total_loss / max(1, num_batches)\n",
    "        train_acc = total_correct / max(1, total_examples)\n",
    "\n",
    "        # ---- VALIDATION (main task only) ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_examples = 0\n",
    "        val_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_iter:\n",
    "                texts, labels = extract_batch_multitaskRNN(batch, device)\n",
    "                logits_main, logit_abbr, logit_enty = model(texts)\n",
    "\n",
    "                loss_main = criterion_ce(logits_main, labels)\n",
    "                val_loss += loss_main.item()\n",
    "\n",
    "                preds = logits_main.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_examples += labels.size(0)\n",
    "                val_batches += 1\n",
    "\n",
    "        val_loss /= max(1, val_batches)\n",
    "        val_acc = val_correct / max(1, val_examples)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # ---- EARLY STOPPING ----\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            wait = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return history, best_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ffa8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_batch_multitaskRNN(batch, device):\n",
    "    # batch.text can be [seq_len, batch] or (text, lengths)\n",
    "    if isinstance(batch.text, (tuple, list)):\n",
    "        text = batch.text[0]\n",
    "    else:\n",
    "        text = batch.text\n",
    "\n",
    "    labels = batch.label\n",
    "\n",
    "    # If shape is [seq_len, batch], transpose to [batch, seq_len]\n",
    "    if text.dim() == 2 and text.size(0) != labels.size(0):\n",
    "        text = text.transpose(0, 1)\n",
    "\n",
    "    return text.to(device), labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c38a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/_dd4c0bn1ws10nbrwf6ls6hc0000gn/T/ipykernel_82377/1378855307.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(embedding_matrix, dtype=torch.float),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 2.2417 | Train Acc: 0.2270 | Val Loss: 1.6174 | Val Acc: 0.3055\n",
      "Epoch 02 | Train Loss: 1.9290 | Train Acc: 0.3157 | Val Loss: 1.5507 | Val Acc: 0.3881\n",
      "Epoch 03 | Train Loss: 1.8180 | Train Acc: 0.4211 | Val Loss: 1.4424 | Val Acc: 0.5174\n",
      "Epoch 04 | Train Loss: 1.6751 | Train Acc: 0.5135 | Val Loss: 1.3168 | Val Acc: 0.5385\n",
      "Epoch 05 | Train Loss: 1.4889 | Train Acc: 0.5963 | Val Loss: 1.1922 | Val Acc: 0.6101\n",
      "Epoch 06 | Train Loss: 1.2268 | Train Acc: 0.6992 | Val Loss: 0.9726 | Val Acc: 0.6881\n",
      "Epoch 07 | Train Loss: 1.0312 | Train Acc: 0.7547 | Val Loss: 0.8711 | Val Acc: 0.7211\n",
      "Epoch 08 | Train Loss: 0.9042 | Train Acc: 0.7925 | Val Loss: 0.8148 | Val Acc: 0.7248\n",
      "Epoch 09 | Train Loss: 0.8120 | Train Acc: 0.8200 | Val Loss: 0.7007 | Val Acc: 0.7606\n",
      "Epoch 10 | Train Loss: 0.7636 | Train Acc: 0.8255 | Val Loss: 0.6666 | Val Acc: 0.7596\n",
      "Epoch 11 | Train Loss: 0.6858 | Train Acc: 0.8526 | Val Loss: 0.6618 | Val Acc: 0.7651\n",
      "Epoch 12 | Train Loss: 0.6372 | Train Acc: 0.8636 | Val Loss: 0.6692 | Val Acc: 0.7578\n",
      "Epoch 13 | Train Loss: 0.5976 | Train Acc: 0.8728 | Val Loss: 0.6430 | Val Acc: 0.7697\n",
      "Epoch 14 | Train Loss: 0.5710 | Train Acc: 0.8801 | Val Loss: 0.5688 | Val Acc: 0.8037\n",
      "Epoch 15 | Train Loss: 0.5268 | Train Acc: 0.8927 | Val Loss: 0.6096 | Val Acc: 0.7807\n",
      "Epoch 16 | Train Loss: 0.4985 | Train Acc: 0.8998 | Val Loss: 0.5865 | Val Acc: 0.7807\n",
      "Epoch 17 | Train Loss: 0.4697 | Train Acc: 0.9074 | Val Loss: 0.5715 | Val Acc: 0.7982\n",
      "Epoch 18 | Train Loss: 0.4495 | Train Acc: 0.9129 | Val Loss: 0.5733 | Val Acc: 0.7908\n",
      "Epoch 19 | Train Loss: 0.4241 | Train Acc: 0.9133 | Val Loss: 0.5180 | Val Acc: 0.8183\n",
      "Epoch 20 | Train Loss: 0.4187 | Train Acc: 0.9202 | Val Loss: 0.5257 | Val Acc: 0.8239\n",
      "Epoch 21 | Train Loss: 0.3698 | Train Acc: 0.9292 | Val Loss: 0.5728 | Val Acc: 0.8055\n",
      "Epoch 22 | Train Loss: 0.3535 | Train Acc: 0.9347 | Val Loss: 0.5196 | Val Acc: 0.8257\n",
      "Epoch 23 | Train Loss: 0.3487 | Train Acc: 0.9331 | Val Loss: 0.5215 | Val Acc: 0.8220\n",
      "Epoch 24 | Train Loss: 0.3022 | Train Acc: 0.9468 | Val Loss: 0.5040 | Val Acc: 0.8394\n",
      "Epoch 25 | Train Loss: 0.2866 | Train Acc: 0.9505 | Val Loss: 0.5154 | Val Acc: 0.8385\n",
      "Epoch 26 | Train Loss: 0.2936 | Train Acc: 0.9459 | Val Loss: 0.5202 | Val Acc: 0.8349\n",
      "Epoch 27 | Train Loss: 0.2867 | Train Acc: 0.9473 | Val Loss: 0.4983 | Val Acc: 0.8303\n",
      "Epoch 28 | Train Loss: 0.2467 | Train Acc: 0.9567 | Val Loss: 0.5097 | Val Acc: 0.8385\n",
      "Epoch 29 | Train Loss: 0.2378 | Train Acc: 0.9592 | Val Loss: 0.4788 | Val Acc: 0.8459\n",
      "Epoch 30 | Train Loss: 0.2103 | Train Acc: 0.9647 | Val Loss: 0.5317 | Val Acc: 0.8312\n",
      "Epoch 31 | Train Loss: 0.2021 | Train Acc: 0.9688 | Val Loss: 0.5034 | Val Acc: 0.8404\n",
      "Epoch 32 | Train Loss: 0.1885 | Train Acc: 0.9702 | Val Loss: 0.5090 | Val Acc: 0.8459\n",
      "Epoch 33 | Train Loss: 0.1826 | Train Acc: 0.9704 | Val Loss: 0.5296 | Val Acc: 0.8468\n",
      "Epoch 34 | Train Loss: 0.1737 | Train Acc: 0.9711 | Val Loss: 0.5065 | Val Acc: 0.8440\n",
      "Epoch 35 | Train Loss: 0.1549 | Train Acc: 0.9768 | Val Loss: 0.5682 | Val Acc: 0.8339\n",
      "Epoch 36 | Train Loss: 0.1493 | Train Acc: 0.9766 | Val Loss: 0.5041 | Val Acc: 0.8514\n",
      "Epoch 37 | Train Loss: 0.1535 | Train Acc: 0.9757 | Val Loss: 0.5248 | Val Acc: 0.8477\n",
      "Epoch 38 | Train Loss: 0.1411 | Train Acc: 0.9782 | Val Loss: 0.4997 | Val Acc: 0.8541\n",
      "Epoch 39 | Train Loss: 0.1280 | Train Acc: 0.9787 | Val Loss: 0.5487 | Val Acc: 0.8431\n",
      "Epoch 40 | Train Loss: 0.1278 | Train Acc: 0.9785 | Val Loss: 0.5314 | Val Acc: 0.8450\n",
      "Epoch 41 | Train Loss: 0.1187 | Train Acc: 0.9796 | Val Loss: 0.5425 | Val Acc: 0.8514\n",
      "Epoch 42 | Train Loss: 0.1008 | Train Acc: 0.9842 | Val Loss: 0.5285 | Val Acc: 0.8514\n",
      "Epoch 43 | Train Loss: 0.0989 | Train Acc: 0.9851 | Val Loss: 0.5449 | Val Acc: 0.8477\n",
      "Early stopping triggered.\n",
      "Best Val Acc (Multi-task): 0.8541284403669724\n"
     ]
    }
   ],
   "source": [
    "model_mt = ClassifierRNNMultiTask(\n",
    "    embedding_matrix=TEXT.vocab.vectors,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    representation=POOLING, \n",
    "    dropout=DROPOUT,\n",
    "    num_classes=len(LABEL.vocab)\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_mt.parameters(), lr=LR)\n",
    "\n",
    "history_mt, best_val_acc_mt = train_multitask_rnn(\n",
    "    model=model_mt,\n",
    "    train_iter=train_iter,\n",
    "    valid_iter=valid_iter,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=DEVICE,\n",
    "    patience=5,\n",
    "    grad_clip=True,\n",
    "    max_norm=1.0,\n",
    "    save_path=\"rnn_multitask_best.pt\"\n",
    ")\n",
    "\n",
    "print(\"Best Val Acc (Multi-task):\", best_val_acc_mt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f99fb108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Multi-task RNN): 0.8840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/_dd4c0bn1ws10nbrwf6ls6hc0000gn/T/ipykernel_82377/1378855307.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(embedding_matrix, dtype=torch.float),\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_examples = 0\n",
    "\n",
    "# Reload best model for evaluation\n",
    "best_mt = ClassifierRNNMultiTask(\n",
    "    embedding_matrix=TEXT.vocab.vectors,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    representation=POOLING,\n",
    "    dropout=DROPOUT,\n",
    "    num_classes=len(LABEL.vocab)\n",
    ").to(DEVICE)\n",
    "\n",
    "best_mt.load_state_dict(torch.load(\"rnn_multitask_best.pt\", map_location=DEVICE))\n",
    "best_mt.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "        texts, labels = extract_batch_multitaskRNN(batch, DEVICE)\n",
    "        logits_main, logit_abbr, logit_enty = best_mt(texts)\n",
    "        preds = logits_main.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_examples += labels.size(0)\n",
    "\n",
    "test_acc = total_correct / max(1, total_examples)\n",
    "print(f\"Test Accuracy (Multi-task RNN): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7412038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic-wise Test Accuracy (Multi-task RNN):\n",
      " ENTY: 0.8191\n",
      " ABBR: 0.7778\n"
     ]
    }
   ],
   "source": [
    "correct = defaultdict(int)\n",
    "total = defaultdict(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "        texts, labels = extract_batch_multitaskRNN(batch, DEVICE)\n",
    "        logits_main, _, _ = best_mt(texts)\n",
    "        preds = logits_main.argmax(dim=1)\n",
    "\n",
    "        for p, y in zip(preds.tolist(), labels.tolist()):\n",
    "            lab = LABEL.vocab.itos[y]\n",
    "            total[lab] += 1\n",
    "            if p == y:\n",
    "                correct[lab] += 1\n",
    "\n",
    "print(\"Topic-wise Test Accuracy (Multi-task RNN):\")\n",
    "for lab in LABEL.vocab.itos:\n",
    "    if total[lab] > 0:\n",
    "        acc = correct[lab] / total[lab]\n",
    "        if lab in (\"ABBR\", \"ENTY\"):\n",
    "            print(f\"{lab:>5}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb942f22",
   "metadata": {},
   "source": [
    "The multi-task RNN with auxiliary binary classification heads (is_ABBR and is_ENTY) demonstrated significant improvement. The topic-wise test accuracy increased to 0.8191 for ENTY and 0.7778 for ABBR, compared to the baseline accuracy of 0.6489 and 0.3333 for ENTY and ABBR respectively. \n",
    "\n",
    "The improvement for the topic ENTY suggests that the auxiliary heads helped the model to disambiguate ENTY-type questions, which often overlap in structure with other categories due to its diverse phrasing. As for ABBR, the muti-task RNN helped to reduce the effect of data imbalance, allowing model to be more sensitive to the underrepressented class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4002-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
